[{"path":"index.html","id":"delighted-to-have-you-welcome-to","chapter":"Delighted to have you!Welcome to:","heading":"Delighted to have you!Welcome to:","text":"guide tackle data preprocessing (various steps obtain “clean ready” dataset using e.g., dplyr), data visualization (using ggplot2), data analysis (linear regression, analysis variance, structural equation modelling), using R RStudio.already go activities, may noticed involve several steps, may taken surprise. received data file, inspect … find far usable. data reordered, variables transformed, certain entries removed. ’s lot look figure . time, data file finally ready go. However, realize beginning, fun yet start.functional Wi-Fi connection, steps documented online. Thing , abundance information scattered far wide across internet. Additionally, may unaware certain possibilities, leaving without “quality life improving” tips tricks.Drawing experience R, want help providing explanations, demonstrations, sharing tips tricks. also want raise awareness many possibilities R offers. aware something possible, can explore .begin, want briefly note two points. First, R allows different personal styles. Different code can lead result, ways intuitive others might intuitive . Second, guide made “beginner” R users mind, occasionally contains information advanced users. Keep mind explain relatively basic code early parts. later sections, progressively reduce explanations “basics” focus topic hand.","code":""},{"path":"index.html","id":"what-to-expect","chapter":"Delighted to have you!Welcome to:","heading":"What to expect","text":"guide tackle following aspects.Loading different types data files. ’ll start brief reminder R packages set working directory demonstrating open variety files .csv .sas.Loading different types data files. ’ll start brief reminder R packages set working directory demonstrating open variety files .csv .sas.Sharing communicating work others. section seem jump ahead slightly, sooner learn R projects notably simplify sharing data files R scripts, better. Additionally, provide short introduction making dynamic (online) reports using R Markdown enhance transparency reproducibility.Sharing communicating work others. section seem jump ahead slightly, sooner learn R projects notably simplify sharing data files R scripts, better. Additionally, provide short introduction making dynamic (online) reports using R Markdown enhance transparency reproducibility.Data preprocessing (dplyr) descriptive calculations. Learn perform various computations shape clean data, using traditional methods modern dplyr approach.Data preprocessing (dplyr) descriptive calculations. Learn perform various computations shape clean data, using traditional methods modern dplyr approach.Data visualization (ggplot2). Learn plot show data - one powerful skills, humble opinion. , introduce flexible toolbox provided ggplot2 package, helping unleash inner artist.Data visualization (ggplot2). Learn plot show data - one powerful skills, humble opinion. , introduce flexible toolbox provided ggplot2 package, helping unleash inner artist.Reliability, confirmatory exploratory factor analysis. Learn indication “closely” questionnaire items relate related one another (Cronbach’s alpha McDonald’s Omega). addition, ’ll show techniques used evaluate whether data “can explained” (deemed ) underlying constructs.Reliability, confirmatory exploratory factor analysis. Learn indication “closely” questionnaire items relate related one another (Cronbach’s alpha McDonald’s Omega). addition, ’ll show techniques used evaluate whether data “can explained” (deemed ) underlying constructs.Basic regression analysis (lm, glm, lmer) model assumptions. Learn model straight lines, basic linear regression mixed-effects (multilevel) linear regression. addition, check several assumptions (linear) regression including distribution residuals homoscedasticity.Basic regression analysis (lm, glm, lmer) model assumptions. Learn model straight lines, basic linear regression mixed-effects (multilevel) linear regression. addition, check several assumptions (linear) regression including distribution residuals homoscedasticity.ANOVA MANOVA. section focuses linear regression categorical variables comparisons group means. Learn create various contrasts (beyond treatment sum contrasts) test questions hypotheses.ANOVA MANOVA. section focuses linear regression categorical variables comparisons group means. Learn create various contrasts (beyond treatment sum contrasts) test questions hypotheses.Mediation analysis. Sometimes want know relation effect occurs. section learn fit structural equation models test mediation moderated mediation models using lavaan. addition, ’ll show visualize results mediation analysis plotting path diagrams.Mediation analysis. Sometimes want know relation effect occurs. section learn fit structural equation models test mediation moderated mediation models using lavaan. addition, ’ll show visualize results mediation analysis plotting path diagrams.Missing data multiple imputation. Data can go missing due variety reasons ignored. last part, provide approaches deal missing values inspect patterns missingness. Lastly, provide step--step guide multiple imputation using mice package.Missing data multiple imputation. Data can go missing due variety reasons ignored. last part, provide approaches deal missing values inspect patterns missingness. Lastly, provide step--step guide multiple imputation using mice package.","code":""},{"path":"index.html","id":"packages-and-r-version","chapter":"Delighted to have you!Welcome to:","heading":"Packages and R version","text":"demonstrations guide done using R version 4.3.2 RStudio version 2023.12.0+369.\nfollowing packages used throughout guide:","code":""},{"path":"loading-datafiles.html","id":"loading-datafiles","chapter":"1 Loading datafiles","heading":"1 Loading datafiles","text":"short section, start something seemingly small fundamental load data files, preprocess, visualize, analyze contents. Fortunately, R provides several ways load (create) data files. certain types data files .sav extension (SPSS), need load R packages. quick reminder:","code":"\n  \n# The classic way to install a package:\n  install.packages(\"car\") # or whatever package you want\n\n  # Alternatively look at your R-studio screen. Look at the left window -> packages -> install\n  # This \"package window\" can also be used to deactivate/activate/remove/update packages\n\n# Let's load some packages (using code lines). The old way is to do:\n  library(car)\n  library(ggplot2)\n  library(dplyr)\n    #... too exhausting \n\n# An alternative is the pacman package\n  library(pacman)\n  p_load(car,ggplot2,dplyr,effectsize) # bonus: it will auto-install any packages if this was not done previously "},{"path":"loading-datafiles.html","id":"working-directory","chapter":"1 Loading datafiles","heading":"1.1 Working directory","text":"open data file, need tell R find . RStudio can import data set point click (top right window “Environment”). course may become tedious want load multiple data sets. Alternatively, R code, use working directory. Personally highly recommend use R projects (see chapter 2) sake illustration provide quick recap working directory.","code":"\n# Getting/Setting the working directory (henceforth abbreviated as \"WD\")\n# Without R projects and manually:\n  getwd() # Which will output the WD of the location where R the script was activated (i.e., where you opened it)\n\n# The WD can also be set. For example to a variable I arbitrarily name \"myWD\"\n  myWD = \"C:/Users/Gillian\" \n  \n# Now suppose I want to load a data file (a .csv extended file) located on my desktop put in a folder called \"folder\".\n  # I could do something like this:\n  myWD = \"C:/Users/Gillian/desktop/folder\"\n  library(stringr) # Will use this package to glue strings together, and to replace them (just to demonstrate that this is possible) \n  mydatafile = read.csv(str_glue(mycurrentWD,\"/thedatafile.csv\"))\n  \n  # Suppose there is a second dataset in a subfolder\n  mydatafile = read.csv(str_glue(mycurrentWD,\"/subfolder/thedatafile.csv\"))\n  \n  # Suppose there is a dataset in another folder on the desktop and I refuse to set another WD\n  mydatafile = read.csv(str_replace(mycurrentWD,\"folder\",\"anotherfolder/thedatafile.csv\"))\n                      "},{"path":"loading-datafiles.html","id":"loading-different-types-of-data-files","chapter":"1 Loading datafiles","heading":"1.2 Loading different types of data files","text":"","code":"\n# Example 1: open a file without telling R the file extension\n    Mydata = read.table(file.choose(), header = TRUE, sep=\",\", dec=\".\")\n      # -> With this code I say: let me manually find a folder on my computer, the first row in that file contains the columnnames, data are separated by a \",\" and a decimal is noted as a \".\"   \n      # -> the above could work to open a csv file.\n    \n# Example 2 csv file:\n    Mydata = read.csv(\"datafile.csv\", na.string=c(\"\",\"NA\",\"NaN\"))\n      # -> Optionally I told R that empty cells, cells with \"NA\", and cells with \"NaN\" should be read as NA in your datafile (not administered, empty)\n   \n# Example 3 spss file (.sav)\n    mydata = haven::read_sav(\"datafile.sav\")\n    # -> You will need the package \"haven\"\n    # -> Here I used a function of the above package without loading it (only works if you have installed the package)\n    # -> Of course, feel free to load packages (library(haven))\n  \n# Example 4: xlsx file (i.e., your typical excel file)\n    Library(readxl)\n    Mydata=read_excel(\"datafile.xlsx\")"},{"path":"loading-datafiles.html","id":"loading-multiple-files-same-extension-at-once","chapter":"1 Loading datafiles","heading":"1.3 Loading multiple files (same extension) at once","text":"Suppose multiple data files conducting study. one data file per participant test subject. want merge individual data files one big data set. case, make folder put data files . open R tell list files (.e., put every file one another) file extension. example specifically made csv-files.","code":"\n      temp_data=list.files(\"folder_with_files/\", pattern=\"*.csv\", full.names=TRUE)\n      \n      # Now we can \"glue\" everything together:\n      Mydata = do.call(rbind, lapply(temp_data, function(x) read.csv(x, stringsAsFactors = FALSE)))"},{"path":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown.html","id":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown","chapter":"2 Communicate with others: a quick glance at R projects and R markdown","heading":"2 Communicate with others: a quick glance at R projects and R markdown","text":"","code":""},{"path":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown.html","id":"r-projects","chapter":"2 Communicate with others: a quick glance at R projects and R markdown","heading":"2.1 R projects","text":"finally loaded data file , got next parts, processed analyzed . One day someone (likely colleague) works similar project wants make corrections code. ask share data file R code. Inspect following R code line. inconvenient colleague?Unless ’re close person can always use computer, likely different file location working directory computer. Thus, need adjust R code. Sometime later, send version R script. computer, adjust R code. computer crashes, get new one, need adjust R code.efficient.Fortunately, can create folder computer, let’s call “My_Project”, put R project . Whenever click R project, working directory automatically update location project. can now move data files scripts folder (subfolders) send colleague. turn, can put folder wherever want without adjust R code.Open R Studio click blue cube (top right corner).prompt window New Existing directory. “New Directory”, create new folder R project inside. want project folder “My_Project” desktop (“etc.” = location desktop):“Existing Directory”, R project placed desired location without creating extra (sub)folders. create folder “My_Project” desktop:Navigate R project folder. also made new R script put folderClick R project see following window. Note “Files” window now contains project R script. window automatically update put new files folders, working directory always equal location project.Files window (bottom left corner) click R script add data files. Instead calling data file using “C:/…”, can now simply call name, provided file location project.put data files separate folders, simply need include :","code":"\n myfile = read.csv(\"Users/Gillian/folder/datafile.csv\", na.string=c(\"\",\"NA\",\"NaN\"))"},{"path":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown.html","id":"r-markdown-brief","chapter":"2 Communicate with others: a quick glance at R projects and R markdown","heading":"2.2 R Markdown (brief)","text":"know exchange data files materials using R projects. However, often want share work without requiring audience run code scratch. address need, R Markdown makes easy create share reports (pdf, Word, HTML, Powerpoint format) can contain steps analysis, plots, . Thus, handy tool promotes transparency reproducibility.Beyond reports, R Markdown extra capabilities. example, guide created combining multiple R Markdown documents (using R bookdown). Now, explaining file format making dynamic documents full detail much. Instead, briefly go basics give “behind scenes” look.R Studio go empty paper symbol (New File) (top right corner) click R Markdown. following window pops .can define document title, author, date. info can changed later can left empty. Concerning Output format, can choose PDF Word documents personally prefer HTML supports plots (see part data visualization). following default screen appears.? Let’s start top\ndefault see something like :\nbelieve less self-explanatory. advice change date : “2025-03-16” date automatically updates time knit document.\nNow HTML documents can add extra customization options including table content, . Behold following example.\nintroduce table contents, make “float” stays present scrolling , include 4-level headings. Next, may wondering included something yeti haddock highlights. “yeti”, refers one many themes (others include: “darkly”, “cerulean”, “journal”, “spacelab”,) determine appearance HTML document. Haddock refers highlight style sets appearance R syntax (others include:“tango”,“espresso”,“zenburn”,“kate”, ). Next, figure settings. say want figures (plots) generated inside Markdown document height width 3 inches. Finally, number_section: TRUE, want automatically add numbered sections.Now, type R document without R code. include R code (code chunks often referred ), can use key combination Alt + Ctrl + .text, outside R code chunks, already noticed can put text bold italics? can also include hyper links just click word sentence (click ) brought web page.can also add bullet pointsbullet point one\nfirst sub point\nsecond sub point\nfirst sub sub point\nsecond sub sub point\nthird sub sub point\n\nfirst sub pointsecond sub point\nfirst sub sub point\nsecond sub sub point\nthird sub sub point\nfirst sub sub pointsecond sub sub pointthird sub sub pointOr can something like thisfirstsecond ()can add multiple headings document","code":""},{"path":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown.html","id":"a-heading-level-two","chapter":"2 Communicate with others: a quick glance at R projects and R markdown","heading":"A heading (level two)","text":"","code":""},{"path":"communicate-with-others-a-quick-glance-at-r-projects-and-r-markdown.html","id":"another-heading-level-three","chapter":"2 Communicate with others: a quick glance at R projects and R markdown","heading":"Another heading (level three)","text":"add images like (see ). see.\n, provides good basis start creating R Markdown documents realize scratched surface. finish R Markdown document, next potentially final step Knit document pressing combination: Ctrl + Shift + K.","code":""},{"path":"data-cleaning-and-descriptive-statistics.html","id":"data-cleaning-and-descriptive-statistics","chapter":"3 Data cleaning and descriptive statistics","heading":"3 Data cleaning and descriptive statistics","text":"Opening data files one thing, preprocessing (“cleaning”) something else entirely. may need restructure data, change variable values, compute new ones, merge datasets, .Fortunately, data fluid. can changed. reshaped. remade.requires understanding access different parts dataset, perform mathematical calculations R, recode variables, . brief overview, introduce dplyr package - personal favorite mine - simplifies preprocessing/cleaning.part covering:access different parts dataset R. includes navigate extract certain rows columns dataset.mathematical computations R including standard deviation kurtosis. addition, show get multiple descriptive statistics multiple variables one code line. also show easily make correlation matrix.Important functions dplyr package. explain demonstrate variety functions commonly use data processing toolbox mutate left_join.Ending demonstration data preprocessing/cleaning raw dataset scratch.","code":""},{"path":"data-cleaning-and-descriptive-statistics.html","id":"access-different-parts-of-a-dataset","chapter":"3 Data cleaning and descriptive statistics","heading":"3.1 Access different parts of a dataset","text":"Let’s start demonstration refresher basics. examples , generate dataset using data.frame() function. values dataset generated random, set seed run, generated data identical.","code":"\nset.seed(123) # Note, the number can be anything (but the results will be different )\n\nmydata = data.frame(\n  participant = c(1:5), # generate the values 1 to 5 (1,2,3,4,5)\n  scores = runif(5, 0,100), # generate 5 values (from a uniform distribution) between 0 and 100\n  gender = c(\"male\",\"female\",\"male\",\"female\",\"female\")\n)"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"viewing-the-data","chapter":"3 Data cleaning and descriptive statistics","heading":"3.1.1 Viewing the data","text":"Now made dataset, ’ll briefly show view data RStudio allows different ways . code:Next writing code, can also click datasets (Environment, top right corner). dataset shown separate window (similar View() code).\nshown image , “view window” allows quickly track changes. want can use view window outside R**. Also practical, can check specific entries dataset using filter option (temporarily) rearrange data ascending descending order quickly check highest lowest score.","code":"\n  mydata\n  head(mydata) # shows the first 10 entries of a dataset\n  View(mydata) # Prompts the dataset in a separate window\n# TEMPORARILY filter values, TEMPORARILY rearrange values, see changes in real-time, ... "},{"path":"data-cleaning-and-descriptive-statistics.html","id":"several-examples","chapter":"3 Data cleaning and descriptive statistics","heading":"3.1.2 Several examples","text":"dataset consists rows columns. referring , R first look rows columns. example, dataset[1,2] output value cross point first row second column (28.75775). Let’s learn example.Insight required compute novel variables filter data. However, mentioned earlier, packages dplyr ease majority work. remains one obstacle move dplyr. preprocessing/cleaning data, might transform variables compute new ones. Thus, knowledge concerning math calculations essential.briefly show different (basic) math calculations make correlation matrix R. Although note different ways .","code":"\n  # If I want to see the first row of all columns:\n  mydata[1,] # Again rows are on the left of the comma (columns on the right)\n\n  # If I want to see rows 1 to 3 of all columns:\n  mydata[1:3,]\n\n  # If I want to see rows 1,2, and 5 of all columns:\n  mydata[c(1:2, 5),] # Here I have to use a \"c\" vector \n\n# Same goes for the columns. I can mention the column number (in my example 1= participant, 2= scores, 3=gender) \n  \n  # I want to see column 1 and 3 but by calling them by name instead their column number\n  mydata[,c(\"participant\", \"gender\")]\n\n  # If you want to see one column. In R you can also ask it like this:\n  mydata$gender\n\n  # If I want to see the value at column 2, row 3:\n  mydata[3,2]\n\n  # If I want to change the above value and add the value of row 5 and column 2\n  mydata[3,2] = mydata[3,2] + mydata[5,2]\n # Suppose I want to look at certain values. For example, I want to look at scores but only from females:\n  mydata$scores[mydata$gender==\"female\"] # Within the column scores, search for scores that \"row-wise\"   corresponds with \"female\"\n  \n  # Suppose I want to look at scores from females who have a score of at least 85\n  # In other words: look to scores with condition \"female\" who have a \"score>=85\"\n  mydata$scores[mydata$gender==\"female\" & mydata$scores>=85]\n\n  # I want to look at scores from females and from participant 1 (a male)\n  # \"female\" OR \"participant == 1\"\n  mydata$scores[mydata$gender==\"female\" | mydata$participant==1]\n  \n  \n  # One final example, I want to look at scores from females with a score of above 90, males with a score below 30, and participant 3\n  # \"female AND score>90\", \"male AND score<30\"\n  mydata$scores[c(mydata$gender==\"female\" & mydata$scores>90) |\n              c(mydata$gender==\"male\" & mydata$scores<30) |\n                mydata$participant ==3\n              ]"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"mathematical-calculations-in-r","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2 Mathematical calculations in R","text":"","code":"\n# Defining a new dataset (with the same name)\nset.seed(0209)\nmydata = data.frame(v1 = runif(10,1,10),\n                     v2 = runif(10,1,10),\n                     v3 = runif(10,1,10))"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"sum","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2.1 Sum","text":"","code":"\n  # Take the sum across all values of column v1\n  sum(mydata$v1)\n  \n  # Take the sum row-wise (from v1 to v2) of each row\n  rowSums(mydata)\n    # Note, as expected, you get 10 outcomes.\n  \n  # Do the same but OUTPUT only the results of rows 1 to 3, 5, and 9 to 10\n  rowSums(mydata)[c(1:3,5,9:10)]\n  \n  # Do the same but now CALCULATE and OUTPUT the \"row wise sum\" of v1 and 3\n  rowSums(mydata[,c(\"v1\",\"v3\")])[c(1:3,5,9:10)]\n  \n  # Compute the sum of values in column v2 and then do the same in column v3 \n  colSums(mydata[,c(\"v2\",\"v3\")])\n  \n  # Do the same but use only rows 5 and 7\n  colSums(mydata[c(5,7),\n               c(\"v2\",\"v3\")]\n          )\n    # Quick note, I don't need to stay on the same line. To my knowledge, you can start a \"new line\" with \",\" \"+/- etc.\" and brackets so that you provide R some expected \"continuation\" of the code.\n  "},{"path":"data-cleaning-and-descriptive-statistics.html","id":"average","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2.2 Average","text":"","code":"\n  # Take the mean of column v1\n  mean(mydata$v1)\n  \n  # take the mean rowwise\n  rowMeans(mydata)\n  \n  # Take the mean column wise but only using odd rows from v1 and v2 \n  colMeans(mydata)"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"variance-standard-deviation-and-correlations","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2.3 Variance, standard deviation, and correlations","text":"","code":"\n  # variance\n  var(mydata$v1)\n\n  # standard deviation\n  sd(mydata$v1)\n  \n  # (bivariate) correlations\n  cor(mydata$v1, mydata$v3)\n  cor(mydata$v1, mydata$v3, method=\"spearman\")  \n  cor(mydata$v1, mydata$v3, method=\"kendall\")  "},{"path":"data-cleaning-and-descriptive-statistics.html","id":"other-calculations-and-the-describe-function","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2.4 Other calculations and the describe function(!)","text":"use describe function psych package quick overview","code":"\n  # range\n  range(mydata$v1)\n  \n  # min/max (value)\n  min(mydata$v1)\n  max(mydata$v1)\n  \n  # Centering and standardizing\n  scale(mydata$v1, center=TRUE, scale=FALSE) # will mean center variables\n  scale(mydata$v1, center=TRUE, scale=TRUE) # will standardize variables\n  \n  # skewness and kurtosis (using the e1071 package)\n  e1071::skewness(mydata$v1)\n  e1071::kurtosis(mydata$v1)\nlibrary(psych)\ndescribe(mydata)\ndescribe(mydata[,c(\"v1\",\"v3\")]) # If you want to use it for specific variables"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"what-if-there-are-missing-values","chapter":"3 Data cleaning and descriptive statistics","heading":"3.2.5 What if there are missing values?","text":"turns , taking sum, mean, correlation, among things, output NA apply methods. Therefore, illustrate correct issue:","code":"\n  mini_data = data.frame(a = round(runif(30,1,10)),\n                         b = round(runif(30,1,10))\n  )\n  mini_data[1:2,1]=NA\n  mini_data[2:3,2]=NA\n  \n  sum(mini_data$a) # NA\n  rowSums(mini_data) # Only the last value is not NA\n  cor(mini_data$a, mini_data$b) # NA\n  \n# To let the above functions ignore NA's (but proceed with caution, do the outcomes make sense in your individual specific case?)\n  sum(mini_data$a, na.rm=TRUE) # remove the NA (\"ignore it\")\n  rowSums(mini_data, na.rm=TRUE) \n  \n  # With correlations we have to use different code:\n  cor(mini_data$a, mini_data$b, use = \"complete.obs\") # Will apply listwise deletion (delete rows containing NA's)\n  cor(mini_data$a, mini_data$b, use = \"pairwise.complete.obs\") # Will apply pairwise deletion (delete cases/cells containing NA's)\n    # In this example the result will remain the same irrespective from listwise or pairwise deletion"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"correlation-matrices-and-visualisation","chapter":"3 Data cleaning and descriptive statistics","heading":"3.3 Correlation matrices and visualisation","text":"often appreciated show correlations relevant variables dataset (personalliy, frequently spot papers social behavioral disciplines). purpose create new dataset variables “taken ” multivariate normal distribution correlations variables prespecified. transparency show made dataset (case ’re interested).Now, plethora packages available visualize correlations. ’ll point relatively recent one corrtable. package makes easy create save correlation matrix provided frequentist p-value significance indications (“significance stars”). dataset, want correlations variables. However, want smaller subset variables, extract variables first separate dataset use smaller dataset create correlation matrix.Note get significance stars. want specific p-values matrix can use e.g., cor_pmat() function ggcorrplot package.","code":"\n# OPTIONAL, just if your interested in how to create a correlated dataset\n  library(MASS)  \n\n# Using the MASS package I will create a dataset based on a multivariate normal distribution. To create one I need the following ingredients: the mean of the variables I want to generate and their variance covariance matrix\n  \n  # the mean (determined by me)\n  set.seed(123)\n  a_mean = 6\n  b_mean = 8\n  c_mean = 3\n  d_mean = 5\n\n  # the standard deviation for the variance covariance matrix (determined by me)\n  a_sd = 0.8 \n  b_sd = 3\n  c_sd = 0.4\n  d_sd = 1.5\n  \n  # Correlations between variables (determined by me)\n  cor_ab = -0.2\n  cor_ac = 0.3\n  cor_ad = 0.5\n  cor_bc = 0.7\n  cor_bd = -0.25\n  cor_cd = 0.15\n\n  # Variance-covariance matrix\n  sigma=matrix(\n    c(a_sd^2, a_sd*b_sd*cor_ab, a_sd*c_sd*cor_ac, a_sd*d_sd*cor_ad,\n      b_sd*a_sd*cor_ab, b_sd^2, b_sd*c_sd*cor_bc, b_sd*d_sd*cor_bd,\n      c_sd*a_sd*cor_ac, c_sd*b_sd*cor_bc, c_sd^2, c_sd*d_sd*cor_cd,\n      d_sd*a_sd*cor_ad, d_sd*b_sd*cor_bd, d_sd*c_sd*cor_cd, d_sd^2),\n    4,4\n  )\n  \n  # The above variance-covariance matrix can also be made using the lazyCov() function from the rockchalk package\n  library(rockchalk)\n  sigma = lazyCov(Rho = c(cor_ab, cor_ac, cor_ad, cor_bc, cor_bd, cor_cd),\n          Sd = c(a_sd, b_sd, c_sd, d_sd)\n  )\n  \n  # Our correlations can be retrieved from our \"sigma\" object:\n  round(cov2cor(sigma),2)\n#>      [,1]  [,2] [,3]  [,4]\n#> [1,]  1.0 -0.20 0.30  0.50\n#> [2,] -0.2  1.00 0.70 -0.25\n#> [3,]  0.3  0.70 1.00  0.15\n#> [4,]  0.5 -0.25 0.15  1.00\n  \n  \n  # Now we can create the dataset, I want 100 values per variable\n  n = 100\n  \n  corr_data = as.data.frame(\n    mvrnorm(n=n, mu=c(a_mean,b_mean,c_mean,d_mean), Sigma = sigma, empirical = TRUE)\n  )\n  names(corr_data) = c(\"a\",\"b\",\"c\",\"d\")\n\n  new_correlation_matrix = corrtable::correlation_matrix(corr_data) # your correlations accompanied with the significance stars\n  new_correlation_matrix[upper.tri(new_correlation_matrix)]=\"\" # Remove the upper part, so we get the typical triangle shape\n  new_correlation_matrix = as.data.frame(new_correlation_matrix)\n  \n  # Or we can do the above in one step and save it to a csv file (to copy-paste it in Words)\n  corrtable::save_correlation_matrix(df=corr_data,file=\"data_files/corr_matrix.csv\",digits=3,use=\"lower\")\n  library(ggcorrplot)\n  mycorr_pvalues = round(cor_pmat(corr_data),3) "},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-a-more-modern-approach-to-shape-data-.","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4 Dplyr, a more modern approach to shape data (!).","text":"finally arrive dplyr package. package contains variety functions ease data preprocessing/cleaning. purpose guide, go functions frequently use adventures data analysis. hungry , highly recommend look following cheat sheet (click ).various examples , use fabricated dataset. Next dplyr package, use stringr package (simplifying operations strings/“text” variables) readxl package (load fabricated dataset)","code":"\npacman::p_load(dplyr,stringr,readxl)\nmydata = read_xlsx(\"data_files/mydata.xlsx\")"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-filter","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.1 Dplyr: Filter","text":"Let’s start filter “filters” entries (row-wise). question data (row-wise) want keep data want exclude. -note, dplyr, can something called “pipelining” noted adding %>% code. Pipelining allows various calculations functions code line. instead \n\n\n…\ncan keep code line, chaining functions/calculations together (shown later examples demonstration end).","code":"\n\n  # Suppose you want to only SHOW/KEEP rows that have a \"1\" in the variable \"cond\" (filtering out the rest)\n  mydata %>% filter(cond==1) \n  # Notice the \"%>%\" to start pipelining. Here I tell R in the dataset \"mydata\" to filter... \n\n  # Show rows containing condition 1 and from participant 5\n  mydata %>% filter(cond==1, participant==5) \n  \n  # Keep rows from participants 1 to 5\n  \n  mydata %>% filter(participant %in% c(1:5)) \n    # I recommend using %in% instead of only c(1:5) \n    # As the name suggests %in% implies \"in range of ...\". Here, in (range of) values of 1 to 5.\n  \n  # Keep all rows EXCEPT THOSE CONTAINING participant 4\n  mydata %>% filter(!participant ==4) \n    # Notice the \"!\" this mean NOT or in this context DO NOT KEEP/KICK OUT ...\n  \n  # Keep rows from participants 1, 3, and 5 EXCEPT THOSE containing a rt of 0.245\n  mydata %>% filter(participant %in% c(1,3,5), !rt==\"0.245\" ) \n    # Note that rt is written as a character (hence \"\")\n  \n  # Exclude rows containing NA's (Not Administered, empty cells) in q_2\n  mydata %>% filter(!is.na(q_2))\n  \n  # Keep rows that contain the characters: \"sagree\" (to get \"disagree\" & \"heavily disagree\") in q_1.\n  mydata %>% filter(str_detect(q_1,\"sagree\"))\n    # For this you can use the stringr package "},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-select","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.2 Dplyr: Select","text":"Similar filter, select exclude columns/variables go “column-wise” instead row-wise.","code":"\n  # Select (KEEP) columns q_1 and r_2\n  mydata %>% select(q_1, r_2 )\n  \n  # Select the columns whose name has/contains a \"q\" character (we can't use stringr here)\n  mydata %>% select(contains(\"q\"))\n  \n  # DO NOT select (EXCLUDE) column names ending with \"ge\", beginning with an \"r\", and containing the characters \"ond\".\n  # Exlude rows containing participant 3\n  mydata %>% select(-ends_with(\"ge\"), -starts_with(\"r\"), -contains(\"ond\")) %>% filter(!participant ==3)\n    # Note the beauty of PIPELINING '%>%', I chain SELECT and FILTER on the same code line\n    # Note that I use \"-\" in SELECT instead of the \"!\" that I use in FILTER\n    # Why? From personal experience, using \"!\" in SELECT does not always yield the intended results\n    \n  # Alternatively, we could also use only one \"-\" in the above code:\n    mydata %>% select(-c(  ends_with(\"ge\"), starts_with(\"r\"), contains(\"ond\")  )) %>%\n      filter(!participant ==3)\n    # Note that I add some unnecessary \"spaces\" in the c() part. This is just for clarity, you can add as much of these spaces as you want without repercussion"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-mutate","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.3 Dplyr: Mutate","text":"Now can include exclude certain columns rows, want start transforming variables. dplyr language mutate . beauty mutate, can multiple mutations one go.Watch use across combination another function uses variables simultaneously (rowMeans rowSums)! , across works variables “one time”. Luckily, can easily fixed knowing place across.final example","code":"\n  \n  # Suppose I want to create a novel variable containing the natural logarithm of the variable \"rt\". I do NOT want to overwrite the original \"rt\" variable\n  # Since rt is a character (and not a number) I will FIRST transform/mutate it from character to numeric and THEN compute the natural logarithm\n  mydata %>% mutate(rt_log = as.numeric(rt), rt_log = log(rt) ) \n  \n  \n  # I will now permanently (because mydata = mydata %>% ...) set rt to be a number (all code up til now were temporarily)\n  mydata = mydata %>% mutate(rt = as.numeric(rt))\n  \n  # You can also transform all variables into a specific type, here transform all numeric variables to \"factor\"\n  mydata %>% mutate_if(is.numeric,as.factor)\n\n  \n  # For the next example, suppose you questionnaire items (noted by a \"q\" in the variable name). Suppose you want to add 2 to each of these items (but temporarily). Here we can use \"across\" as will be explained below\n  mydata %>% mutate(across(starts_with(\"q\"),\n                                    ~. + 2 ) )\n    \n    # In this context, \"across\" can be translated as \"in each\". For each variable starting with \"q\", we add \"~\" to indicate that the following function should be applied. Next, The dot represents the variable itself (which starts with \"q\"). In summary. Across (in each) variable starting with \"q\", do the following: add 2 to each variable (starting with \"q\").\n  \n  # Important detail, across tends to \"apply the following\", one variable at a time, and not simultaneously. So pay attention with certain function (such as rowMeans), as explained below.\n# Lets take the row-wise average score of all variables starting with \"q\" (ignoring empty variables)\n# HOWEVER, doing it wrong first (so expect an error)\n  mydata %>% mutate(average_score=across(starts_with(\"q\")), ~ rowMeans(., na.rm=TRUE)) \n    \n    # Why this error in the case of rowMeans? Well, rowMeans is function that works with all variables SIMULTANEOUSLY (since it is an average). This can be fixed by putting \"across\" within rowMeans. So pay attention were you put across and all will be fine.\n      mydata = mydata %>% mutate(average_score=rowMeans(across(starts_with(\"q\")),na.rm=TRUE))\n    # Similar example but a \"bit more advanced\". Say we want to have a sum score across variables starting with \"q\". However, now we want to set this sum score to NA (empty/not administered) if at least ONE value is NA/missing (row-wise).\n  mydata %>% mutate(na_count=rowSums(is.na(across(starts_with(\"q\")))),\n                             average_score=ifelse(na_count>=1, NA, average_score)\n  )"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"recoding-questionnaire-items","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.3.1 (Re)coding (questionnaire) items","text":"surveys often need (re)code responses (like agree totally disagree), giving numerical value. Fortunately, mutate function versatile regard well. One way use versatile ifelse function within mutate (see straightforward approach afterwards). short, first need specify condition (e.g., item scored “agree”), specify done (item given value …), finally indicate value given . Lets give “easy” exampleLooks straightforward right? However, suppose five response categories:follows logic (…, …, else …) lot brackets… unnecessary case. speak ill ifelse() function, flexible numerous situations. Fortunately context, exist straightforward alternative: recode. recode can give text (“agree”) numerical value, value (2) textual value. Let us redo example change text numbers, back.","code":"\n  # If the variable q_1 is scored as \"heavily disagree\", give it value a 1, else give it a value of 0\n  mydata %>% mutate(q_1 = ifelse(q_1==\"heavily disagree\", 1, 0)       )\n  mydata %>% mutate(q_1 = ifelse(\n    q_1==\"heavily disagree\", 1, ifelse(\n      q_1== \"disagree\", 2, ifelse(\n        q_1==\"neutral\", 3, ifelse(\n          q_1==\"agree\", 4, 5\n        )\n      )\n    )\n  )\n)\n # Take again the example with five response categories. \n # Lets recode text to numbers:\n  \n  mydata = mydata %>% mutate(\n    q_1 = recode(q_1,\n      'heavily disagree' = 1,\n      'disagree' = 2,\n      'neutral' = 3,\n      'agree' = 4,\n      'heavily agree' = 5\n    ))\n\n  # Lets change it back from numbers to text\n  mydata %>% mutate(\n  q_1 = recode(q_1,\n  '1'  = \"heavily disagree\",\n  '2' = \"disagree\",\n  '3'  = \"neutral\",\n  '4'  = \"agree\",\n  '5'  = \"heavily agree\"\n  ))\n  \n  # Lets recode from text to numbers in all variables starting with \"q\".\n  # I will apply these changes permanently to my dataset (mydata = mydata %>% ...)\n  mydata = mydata %>% mutate(across(starts_with(\"q\"),\n                             ~ recode(.,\n                                      'heavily disagree' = 1,\n                                      'disagree' = 2,\n                                      'neutral' = 3,\n                                      'agree' =  4,\n                                      'heavily agree' = 5)\n                             ))"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-arrange","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.4 Dplyr: Arrange","text":"Arrange data ascending descending order based value alphabetical order.","code":"\n\n  # Arrange reaction time (rt) from lowest value ascending to highest\n  mydata %>% arrange(rt)\n  \n  # Arrange rt from highest value descending to lowest\n  mydata %>% arrange(desc(rt))\n  \n  # Arrange on both age and rt\n  mydata %>% arrange(age,rt)"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-group_by-and-summarize","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.5 Dplyr: Group_by and Summarize","text":"Suppose want compute something like sum mean, per “cluster variable” per participant, per condition, per plant animal species… can grouping summarizing , create tinier dataset including desired computation(s). First need define “grouping/cluster” variables. need indicate want per cluster variable. illustration, suppose want average per participant.","code":"\n\ntempdata = data.frame(\n  participant = rep(c(1:3), each = 3),\n  score = c(1,2,3, 4,5,6, 7,8,9)\n)\n\ngroup_by(participant) %>% summarize(average_per_participant = mean(score) )\n  \n  # Suppose we want to compute the mean and sd for rt per participant.\n  mydata %>% group_by(participant) %>% summarize(aggr_rt=mean(rt), sd_rt=sd(rt)) \n    # Again, note that the output is a seperate dataset\n    # If you want, we can \"glue\" our freshly computed mean and standard deviation to each corresponding participant\n    # Below, a sneak peak on how to do the above (WITHOUT SAVING THE \"NEW SMALLER DATASET\" FIRST).  \n  mydata %>% group_by(participant) %>%\n    summarize(aggr_rt=mean(rt), sd_rt=sd(rt)) %>%\n   left_join(mydata)"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"dplyr-join","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.6 Dplyr: Join","text":"demonstrated , obtained smaller dataset can glued original one desired. glueing datasets often can come handy. example, suppose ran experiment obtain two separate data files: one experiment one demographics participant. Say want test main effect variable moderated demographic, need merge data files one dataset.exist different types join() inner_join, right_join. Personally, mainly use left_join() since straightforward. idea put two datasets function e.g., left_join(dataset_1, dataset_2). find variables datasets share, variables share name type (numeric character). identifying shared called “key variables”, glue “non-shared” variables. example left_join(), glue data_set 2 data_set 1 (second argument “dataset_2” left argument “dataset_1). visual example:\nadvice, joining, always check whether amount variables original dataset stayed . Sometimes (unbeknownst ) duplicates empty values (coded NA) variables. may lead left_join returning values. check encounter problem. also help make sure second dataset (one glued main one) small possible (withholding necessary information) group_by summarize help. , small example left_join, last one move “live” demonstration data preprocessing.","code":"\n\n  # Say we want to \"join/glue\" the aggregated rt and sd from the previous code exaple to the main dataset \n  data_aggr = mydata %>% group_by(participant) %>% summarize(aggr_rt=mean(rt), sd_rt=sd(rt)) \n  left_join(mydata, data_aggr)"},{"path":"data-cleaning-and-descriptive-statistics.html","id":"practical-example-data-shapingcleaning","chapter":"3 Data cleaning and descriptive statistics","heading":"3.4.7 Practical example data shaping/cleaning","text":"first encounter dplyr, different functions might overwhelming. understand.personally, find appealing dplyr “chaining” different functions (pipelining) allowing multiple things , made data preproccesing R scripts general, less chaotic . Yes, %>% %>% … can lead behemoths code may seem intimidating first. everything new, beginning can feel akward. Perhaps example, things become clearer.conclude section, demonstrate complete example scratch, integrating learned dplyr far (plus new elements added along way). made two raw datasets: main dataset (mydata_prac.xlsx) smaller one (mydata_prac_add.csv). nutshell following preprocessing steps:\n1. Check data\n2. Recode/rename/transform/create variables\n3. Join datasets\n4. Create preprocessed dataset","code":"\n############################\n# Preprocessing example    #\n############################  \nlibrary(pacman)\np_load(dplyr,stringr,corrtable,readxl, haven)\noptions(scipen=999)\nset.seed(54321)  \n\n##\n# Load data file and inspect data\n##  \n  \n  mydata = read_xlsx(\"data_files/mydata_prac.xlsx\")\n  View(mydata)\n  \n  # -> So far so good. However, one participant shows no data so here I decide to delete this one (filter it out)\n  mydata = mydata %>% filter(!participant==11)\n  \n  # -> Ok so now I should have 10 partipants, let's quickly check. \n  length(unique(mydata$participant)) \n  \n##\n#  Recode variables\n##\n  \n  # Items \"q\" need to be recoded to values (heavily disagree = 1 ; heavily agree = 5)\n  mydata = mydata %>% mutate(across(starts_with(\"q_\"),\n                                   ~ recode(.,'heavily disagree' = 1,\n                                             'disagree' = 2,\n                                             'neutral' = 3,\n                                             'agree' = 4,\n                                             'heavily agree' = 5)\n                                    ))\n  \n  # Turns out question q_1 and q_2 need to be REVERSED code\n  mydata = mydata %>% mutate(across(starts_with(\"q_\") & !ends_with(\"3\"),\n                                    ~ abs(.-6)))\n    # -> note !ends_with = does NOT end with; abs take the absolute value otherwise I end up with negative values.                              \n                                    \n  View(mydata) # Check your data                            \n\n###  \n#   Rename and transform variables  \n###\n  \n  # First off the \"age\" variable was misnamed and should be called \"date_of_birth\"\n  # Similarly, \"q_3\" is actually \"r_4\"\n  # rt is not a character but should be coded as a numerical value. Participant should be coded as a factor\n  mydata = mydata %>% rename(birth_date=age, r_4 = q_3) %>%\n    mutate(rt = as.numeric(rt), participant = as.factor(participant))\n\n    # -> Note that the dataset reads as r_4; r_1; r_2; r_3\n    # -> This may trigger someone so lets quickly change the order\n    # The current column number 7 (\"r_4\") needs to placed last:\n  mydata = mydata[,c(1:6,8:10,7)] # from \"participant\" to \"q_2\", from \"r_1\" to \"r_3\", \"r_4\" \n  \n###  \n#   Compute new variables\n###  \n  \n  # Moving on, I will create a variable \"participant_age\" which is the difference in time between the variable \"birth_date\" and a certain date (say the first of April 2023)\n  # I will use the packages anytime and lubridate \n  pacman::p_load(anytime,lubridate)\n  mydata = mydata %>% mutate(age =time_length(\n    interval(\n      as.Date(anytime(birth_date)),\n      as.Date(\"2023-04-01\")  # Note, has to be in YYYY/MM/DD format.\n    ),\n    unit =\"year\" # To get the difference in years\n  )\n  )\n  \n  # Next, I wish to compute the row-wise averages of the \"q_\" variables as well ass the \"r_\" variables. BUT I don't want to have the average (set to an empty value) if only one item was filled in (row-wise)\n  # Essentially, we have to base whether or not to average based on the sum of NA (a.k.a. empty values) per row\n  # In other technical words: if our the condition is met (the sum of NA's per row is 1 or lower), compute the mean (ignore NA's)\n  mydata = mydata %>% mutate(\n    q_scale = ifelse(rowSums(across(starts_with(\"q_\"), ~is.na(.)))<=1,\n                     rowMeans(across(starts_with(\"q_\")),na.rm=TRUE),NA\n    ),\n    r_scale = ifelse(rowSums(across(starts_with(\"r_\"), ~is.na(.)))<=1,\n                     rowMeans(across(starts_with(\"r_\")),na.rm=TRUE),NA\n    )\n  )\n    # Again be mindfull of where to put across.\n    # Check your data\n    View(mydata) \n    \n      # It worked... but some ages are set to zero. Transform 'em to NA\n      mydata = mydata %>% mutate(age = ifelse( age==0,NA, age))\n      \n      # It is a good thing we frequently check our data :-)\n\n  # Next, PER PARTICIPANT, I want the average rt and the average of the freshly created \"q_scale\" and the \"r_scale\" (ignore NA).\n  # In addition, I want to grand-mean center the average rt per participant.\n  # For the first part, we can use the group_by() and summarize() combo. We could join the created miniature dataset with the main one to grand-mean center.\n  # I could glue datasets using left_join()... but in this example, I will \"pipeline\" all functions without \"breaking the chain\"\n  # To keep the chain intact, I will have to use right_join()\n  # You see, after \"summarizing\" the dataset, a miniature dataset will be created. From that moment, if you pipeline further, you will be using that miniature dataset. Now, with right_join(), you tell R: \"use the first dataset (i.e., the miniature dataset) to glue it to the second one (i.e., our original dataset), which is exactly what we want to preserve the chain\n  \n  mydata = mydata %>% mutate(rt = as.numeric(rt)) %>% group_by(participant) %>% summarize(  rt_average_part = mean(rt,na.rm = TRUE),\n                                                                                        q_average_part = mean(q_scale,na.rm = TRUE),\n                                                                                        r_average_part = mean(r_scale,na.rm = TRUE)  ) %>%\n  right_join(mydata) %>% \n  mutate(rt_grand_mean = scale(mydata$rt, center = TRUE, scale = FALSE) )\n\n  # Check. your. data.\n  View(mydata)\n\n###  \n#   Merge datasets\n###    \n  \n  # Let's wrap it up. Glue the \"mydata_prac_add.csv\" to the main one and recode gender into words (1 = female, 2 = male)\n  mydata = left_join(mydata, read.csv(\"data_files/mydata_prac_add.csv\") %>% mutate(gender = ifelse(gender == 1,\"female\",\"male\")) )\n  \n  # You know what to do\n  View(mydata)\n  \n  # Everything looks fine, save the \"clean\" dataset in a \"clean\" datafile.\n  write.csv(mydata,\"data_files/mydata_prac_finished.csv\") \n  \n  # Done."},{"path":"data-visualisation.html","id":"data-visualisation","chapter":"4 Data visualisation","heading":"4 Data visualisation","text":"Humans highly visual creatures, exploit . Visual depictions distribution trends data appealing eye, times may tell us bunch p-values like. Data visualization strong point R covered variety packages. package choice?ggplot2.ggplot package allows (copious customization possibilities), can provide aesthetically-pleasing plots, can plot various things including graphs can interact real-time”.\nmight suspect, visual chapter. go :basics ggplot2. ’ll go aspects aes() part (aesthetics) arguments put .Simple demonstration plot variety graphs nice “additions” . restrain histograms (normal distribution indication), density plots, box plots, (split) violin plots, bar graphs, pie charts, scatter plots. heed much attention aesthetics professional look plots, part covered next.depth customization make professional beautiful. Demonstrating adjust important elements canvas graphs (text elements, colors, sizes, hide things, …) combine plots cowplot package. illustrated two “advanced” examples also address issues might expect.Interactive graphs. ideal R Markdown reports (HTML output style), multiple cluster units (like participants species something), want look change time.","code":""},{"path":"data-visualisation.html","id":"the-language-of-ggplot","chapter":"4 Data visualisation","heading":"4.1 The language of ggplot","text":"Similar pipes specific functions dplyr, ggplot language. Lets quickly familiarize. Everything starts following code: dataset %>% ggplot(aes() ) without pipelining ggplot(data= dataset, aes()). ggplot() part draw empty canvas add elements like lines, bars, points, etc.aes() part, stands aesthetics, define characteristics things want draw, like values x-axis, values y-axis, color, text, . However, characteristics put within aes() always based dataset. words, need something (values text) data plot, put aes(), , put outside. Say following data:want plot cross points y crosses x. course values x-axis y-axis need taken dataset . need put aes(), outside .actually define two aesthetics, one within ggplot() /one within geom_point(). difference aes() within ggplot() apply defined characteristics drawings (lets’ call global aesthetics).aes() within geom_point() apply stuff drawing (call local aesthetics), points case. good know global aesthetics can overridden local aesthetics (demonstrated later ) lines, bars, point can colored differently.Moving . Assume want color every point red. can without “referring” dataset, therefore put outside aes()However, want give points different color based group variable dataset? Indeed, need put within aesthetic.end part, let prove local aesthetic can override global one. points blue:","code":"\npacman::p_load(dplyr, ggplot2)\nset.seed(1)\nexample_dataset = data.frame(\n  group = factor(c(1,2,3)),\n  x = round(runif(3,1,10),0),\n  y = round(runif(3,1,10),0) \n)\nexample_dataset %>% ggplot(aes(x=x, y=y)) + geom_point()\nexample_dataset %>% ggplot() + geom_point(aes(x=x, y=y))\nexample_dataset %>% ggplot(aes(x=x, y=y)) + geom_point(color=\"red\")\nexample_dataset %>% ggplot(aes(x=x, y=y, color=group)) + geom_point()\nexample_dataset %>% ggplot(aes(x=x, y=y, color=group)) + geom_point(color=\"blue\")"},{"path":"data-visualisation.html","id":"plotting-various-graphs.","chapter":"4 Data visualisation","heading":"4.2 Plotting various graphs.","text":"Now fun part, ggplot allows plot various graphs many customization options. demonstrate important customization possibilities, show R code output variety common graphs (e.g., histograms bar graphs) well less common ones. purpose use custom dataset provided R three species flowers.","code":"\nmydata = iris"},{"path":"data-visualisation.html","id":"histogram","chapter":"4 Data visualisation","heading":"4.2.1 Histogram","text":"Starting classics.","code":"\n  # Suppose we want to have black contours and a white fill color\n  mydata %>% ggplot(aes(x=Sepal.Length)) + geom_histogram(fill = \"white\", color =\"black\",bins=20)"},{"path":"data-visualisation.html","id":"density-plots","chapter":"4 Data visualisation","heading":"4.2.2 Density plots","text":"can also put density plot histogram. Note histogram shows counts values within given range density plot shows proportion. consequence, share y-axis, need fix using following argument (y = ..density..).","code":"\n  # Blue fill color (i.e., the area covering by the density plot) and making it transparent\n  mydata %>% ggplot(aes(x=Sepal.Length )) + geom_density(fill =\"blue3\", alpha =0.50)\n  \n  # Histogram: black contour, blue fill, a bit of transparency \n  # Density plot: yellow fill, a high degree of transparency\n    # In addition:\n    # A vertical black line indicating the mean of Sepal length\n    # A vertical red line indicating the median of sepal Length\n\n  mydata %>% ggplot(aes(x=Sepal.Length )) + geom_histogram(aes(y =..density..),fill=\"blue\", color = \"black\", alpha = 0.7) +\n    geom_density( fill = \"yellow\", alpha = 0.3) +\n    geom_vline(aes(xintercept = mean(Sepal.Length)), color=\"black\") +\n    geom_vline(aes(xintercept = median(Sepal.Length)), color=\"red\")"},{"path":"data-visualisation.html","id":"adding-a-normal-distribution-indication","chapter":"4 Data visualisation","heading":"4.2.2.1 Adding a normal distribution indication","text":"software SPSS get reference normal distribution plotting histograms. default R . can use stat_function() draw line depict variable look like variable normally distributed. Now, normal distribution made two parameters: mean standard deviation. Therefore, must tell stat_function use mean standard deviation variable. Moreover, need use previous trick y =..density..","code":"\n  # Histogram: black contours, white fill color\n  # A Line showing the normal distribution colored in blue\n    # Additionally:\n    # A black slightly transparent line indicating the mean \n    # Two dashed slightly transparent red lines indicating +/- 1SD from the mean \n    # Adjust the titles: plot title = \"Histogram; x-axis= \"Sepal width\"; y-axis= \"Frequency\" \n\nmydata %>% ggplot(aes(x=Sepal.Width)) + geom_histogram(aes(y=..density..),fill = \"white\", color =\"black\") +\n  stat_function(fun=dnorm, args=list(mean=mean(mydata$Sepal.Width), sd=sd(mydata$Sepal.Width)),color=\"blue\") +\n  geom_vline(aes(xintercept = mean(Sepal.Width)), alpha = 0.8, color =\"black\") +\n  geom_vline(aes(xintercept = mean(Sepal.Width) - sd(Sepal.Width) ), linetype =\"dotted\", alpha = 0.8, color =\"black\") +\n  geom_vline(aes(xintercept = mean(Sepal.Width) + sd(Sepal.Width) ), linetype =\"dotted\", alpha = 0.8, color =\"black\") +\n  ggtitle(\"Histogram\") + xlab(\"Sepal width\") + ylab(\"Frequency\") "},{"path":"data-visualisation.html","id":"violin-plots","chapter":"4 Data visualisation","heading":"4.2.3 Violin plots","text":"personal favorite mine, music ears. violin may bit exotic allow explain. can described mirrored distribution plot. box plot put top , resemble violin. major strength violin , hybrid, combines advantages box plot (median/mean, quartiles,…) density plot (detailed distribution). Suppose want compare petal length across flower species:","code":"\n  # Violin plot: fill color per species; the mean is added in the box plots (using stat_summary)\n  mydata %>% ggplot(aes(y=Sepal.Length, x = Species, fill = Species)) +\n    geom_violin() +\n    geom_boxplot(color=\"black\", alpha = 0.75) + stat_summary(func = mean)"},{"path":"data-visualisation.html","id":"split-violin-plots","chapter":"4 Data visualisation","heading":"4.2.4 Split violin plots","text":"One unfortunate part violin plots redundancy mirrored distributions. One half enough. Luckily, packages like introdataviz made easy differentiate right/left side (top/part shown ). Suppose can categorize flowers young old. Per species make one side violin reflecting young flowers, reflecting old ones. must note (yet) install introdataviz “basic way”. use devtools package:","code":"\n# devtools::install_github(\"psyteachr/introdataviz\")\nlibrary(introdataviz)\n### Split-violin plot\n  # Give a fill color per age group\n  # Getting tired of the standard colors that R will use? Tell R the colors you want (we will do it manually) \n  # Plot a transparent split-violin plot\n    # Here I will R to NOT trim the end points (just an aesthetical consideration)\n  # Plot a transparent box plot\n  # Add a dot to represent the mean\n    # Use position dodge to adjust where this dot will be placed\n  # Flip the plot (90 degrees to the left)\n  \n\nmydata %>% mutate(age = rep(c(\"young\",\"old\"),times=75)) %>%\n  ggplot(aes(y = Sepal.Length, x = Species, fill = age)) +\n  scale_fill_manual(values = c(\"royalblue\", \"gold1\")) +\n  geom_split_violin(alpha = 0.5, trim = FALSE) + \n  geom_boxplot(color=\"black\", alpha = 0.75, width = 0.2) +\n  stat_summary(fun = mean, position = position_dodge(0.15), color=\"black\") +\n  coord_flip()"},{"path":"data-visualisation.html","id":"bar-graphs","chapter":"4 Data visualisation","heading":"4.2.5 Bar graphs","text":"","code":"\n# Bar plot (counting occurennces of a given letter)\n  # Plot a white transparent bar plot COUNTING the amount of letters in the dataset \ndata.frame(letters = c(rep(c(\"a\"), each=10),  rep(c(\"b\"), each=7), rep(c(\"c\"), each=15),\n                       rep(c(\"d\"), each=3),  rep(c(\"e\"), each=7))) %>%\n  ggplot(aes(x=letters)) +\n  geom_bar(color=\"black\", fill=\"white\", alpha = 0.75) \n\n\n# Bar plot (showing the VALUES of the letter counts)\n# Plot a white transparent bar plot \"identifying the values\" and showing them\n  # Note, instead of geom_bar(stat = \"identity\") we could use geom_col \ndata.frame(letters = c(rep(c(\"a\"), each=10),  rep(c(\"b\"), each=7), rep(c(\"c\"), each=15),\n                       rep(c(\"d\"), each=3),  rep(c(\"e\"), each=7))) %>%\n  group_by(letters) %>% count() %>%\n  ggplot(aes(x = letters, y = n)) +\n  geom_bar(stat = \"identity\", color=\"black\", fill=\"white\", alpha = 0.75)"},{"path":"data-visualisation.html","id":"piecharts","chapter":"4 Data visualisation","heading":"4.2.6 Piecharts","text":"knowledge, function like geom_pie within ggplot. Instead, pie-charts actually take form bar graphs (identity type) trough coord_polar function bars take circular shape.","code":"\n# Pie-chart\n  # Plot a bar plot (\"identity\") with a fill color per letter\n  # Transform to a circle (coord_polar)\n  # add percentages as text on the pie-chart\n    # To do so, in the our dataset we can add a variable depicting the percentage\n        # To the percentage value I will add a \"%\" sign\n  # Use the \"Dark2\" palette to adjust fill color \ndata.frame(letters = c(rep(c(\"a\"), each=10),  rep(c(\"b\"), each=7), rep(c(\"c\"), each=15),\n                       rep(c(\"d\"), each=3),  rep(c(\"e\"), each=7))) %>%\n  group_by(letters) %>% count() %>% mutate(letters=as.factor(letters)) %>% ungroup() %>%\n  mutate(percentage = as.character(  round(n/sum(n)*100,1)  ),\n         percentage = paste0(percentage,\"%\")) %>%\n  ggplot(aes(y=n, x=\"\", fill = letters)) +\n  geom_bar(stat=\"identity\", color=\"black\", alpha = 0.75) +\n  coord_polar(\"y\") +\n  geom_text(aes(label = percentage), color = \"white\",size = 2, position = position_stack(vjust = 0.5)) +\n  theme_void() +\n  scale_fill_brewer(palette=\"Dark2\")"},{"path":"data-visualisation.html","id":"scatter-plots","chapter":"4 Data visualisation","heading":"4.2.7 Scatter plots","text":"Suppose want visually inspect lower higher values petal length go higher lower values sepal length. example ,split plot (containing flower species canvas) three separate ones using facet_wrap() ease looking species separately.","code":"\n  # Scatter plot: colored per species and separated by species\n  mydata %>% ggplot(aes(y=Petal.Length, x = Sepal.Length, color = Species)) +\n    geom_point() +\n    facet_wrap(~Species) +\n    ggtitle(\"Scatter plot\") +\n    xlab(\"Sepal length\") +\n    ylab(\"Petal length\")"},{"path":"data-visualisation.html","id":"adding-a-regression-line","chapter":"4 Data visualisation","heading":"4.2.7.1 Adding a regression line","text":"Say want quickly inspect whether can “forcefully” draw diagonal linear line petal sepal length (first indication linear relation). can employ geom_smooth() function regress line provide spread around (95% confidence interval default changeable). Lets add one plot . Note line per species separately.can prove geom_smooth() simple linear behind scenes. just need quickly extract parameters linear regression (spoilers next chapter). simplicity lets focus species “Setosa”.\nTa-da:Now, geom_smooth can also used quickly inspect patterns data. example, lets use default “LOESS” argument draw straight line rather “loosely” follow data (.e., using local averaging “rolls” mean across x-axis). result resemble pasta al dente. also hide 95% confidence interval","code":"\nmydata %>% ggplot(aes(y=Petal.Length, x = Sepal.Length, color = Species)) +\n  geom_point() +\n  facet_wrap(~Species) +\n  geom_smooth(method=\"lm\", se=TRUE, color=\"black\", fill=\"grey20\") +\n  ggtitle(\"Scatter plot\") +\n  xlab(\"Sepal length\") +\n  ylab(\"Petal length\")\nmydata_setosa = mydata %>% filter(Species==\"setosa\") # Keeping one species\nmylm = lm(Petal.Length ~ Sepal.Length,data=mydata_setosa) # linear regression\n\nmydata_setosa %>% mutate(\n  the_line = predict(mylm),    # Extract the predicted values (forming the line)\n  CI_lower = as.data.frame(predict(mylm,interval=\"confidence\"))$lwr, # Lower bound         \n  CI_upper = as.data.frame(predict(mylm,interval=\"confidence\"))$upr  # Upper bound\n  ) %>%\n  ggplot(aes(x = Sepal.Length)) +\n  geom_point(aes(y = Petal.Length), color=\"firebrick\") +\n  geom_line(aes(y = the_line), color=\"black\") +\n  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper), fill=\"grey20\",alpha=0.25) +\n  ggtitle(\"Scatter plot\") +\n  xlab(\"Sepal length\") +\n  ylab(\"Petal length\")\nmydata %>% ggplot(aes(y=Petal.Length, x = Sepal.Length, color = Species)) +\n  geom_point() +\n  facet_wrap(~Species) +\n  geom_smooth( se=FALSE, color=\"black\", fill=\"grey20\") +\n  ggtitle(\"Scatter plot\") +\n  xlab(\"Sepal length\") +\n  ylab(\"Petal length\")"},{"path":"data-visualisation.html","id":"how-to-customize-your-plots","chapter":"4 Data visualisation","heading":"4.3 How to customize your plots","text":"-till now paid much attention appearance plots. Just data “fluid”, plots well. Ggplot allows full customization canvas everything .","code":""},{"path":"data-visualisation.html","id":"changing-the-theme-colors-fonts-combining-plots-and-adding-p-value-indications","chapter":"4 Data visualisation","heading":"4.3.1 changing the theme, colors, fonts, combining plots, and adding p-value indications","text":"can change individual element theme click overview. clicked, noticed lot can change. avoid lengthy discussion, default themes give two relevant demonstrations .ggplot2 package several built-themes. default ggplot goes theme_grey, one saw plot. built-themes include theme_bw(), theme_linedraw(), theme_light(), theme_dark(), theme_minimal(), theme_classic(), theme_void(). Click look Personally,mainly choose theme_classic() following examples.","code":""},{"path":"data-visualisation.html","id":"example-1","chapter":"4 Data visualisation","heading":"4.3.2 Example 1","text":"Suppose collected number flower species measured petal length. want plot shows whether differences average petal length species statistically significant (based p-values). addition, subjected certain rules:\n1. color, grayscale\n2. must confidence interval. lets pretend(!) upper lower bounds confidence intervals half standard deviation average petal length.\n3. Times New Roman font style font size 12 titles x- y-axis, font size 14 title presented bold, font size 10 text marks.\n4. legend placed bottomI use stat_pvalue_manual() function ggpubr package user-friendly “novice” R user. Crucially, stat_pvalue_manual functions demands couple things **: first group, second group, position y-axis want put p-values. clarified soon.First things first, need calculate average petal length per species well confidence intervals (.e., upper lower bounds). group_by() summarize() dplyr can help . recall, creates mini dataset. miniature dataset add five things: group 1, group 2, obtained p-value (arbitrary current demonstration purposes), statistical significance signs, position y-axis want put p-values.group 1 group 2? Well example compare 3 species one another, species B, C, B C. group 1 add left side comparisons (B, C, B C). group 2 add right side comparison (B, C, B C). compute view dataset see combination beneath one another.\nLet’s Move , p-value, arbitrarily choose values combinations: <.001 (B), .040 (C), .231 (B C). Keeping values mind, sign p-values respectively three stars (p<.001), one star (p =.040), “significant” (p = .231). Finally, y-position, put position corresponding petal length averages. However, look unclear add value averages position shift slicing top bar “hoovering” bit .Create bars p-values top (ignoring rules grayscale).looks acceptable. However, encounter something unexpected, notice bars float x-axis? bring bars , specify range y-axis using coord_cartesian() use scale_y_continuous() function.Good, lets’ address given rules. get grayscale can use scale_fill_manual function need determine colors . Font family, size, style (face) can changed theme(). Titles default left-aligned can easily fixed. Similar font, position legend (even existence) can changed theme(). Since legend, don’t need title x-axis plus need mentioning word “species” legend .\nend product:","code":"\nmydata_example1 = mydata %>% group_by(Species) %>% summarise(average_Petal_Length=mean(Petal.Length),\n          CI_lwr = average_Petal_Length - (0.5*sd(Petal.Length)),\n          CI_upr = average_Petal_Length + (0.5*sd(Petal.Length))\n          ) %>%\n  mutate(\n    p = c(\"(<.001)\",\"(.040)\",\"(.231)\"), # Adding the ARBITRARY p-values\n    p_notation = c(\"***\",\"*\",\"ns\"), # The \"signs\" of the above p-values\n    group1 = c(\"setosa\",\"setosa\",\"versicolor\"),\n    group2 = c(\"versicolor\",\"virginica\",\"virginica\"),\n    y.position = average_Petal_Length + 4 # For the y-position, adding it with 4 so it \"hoovers\" above the bars.The x-position will correspond with Species\n  )\n\nlibrary(ggpubr)\nmydata_example1 %>% ggplot(aes(x=Species,y=average_Petal_Length,fill=Species)) +\n  theme_classic() +\n  geom_bar(stat=\"identity\") +\n  geom_errorbar(aes(ymin =  CI_lwr, ymax =  CI_upr), width=0.2) +\n  stat_pvalue_manual(mydata_example1, label = \"{p} {p_notation}\", size =3)\nmydata_example1 %>% ggplot(aes(x=Species,y=average_Petal_Length,fill=Species)) +\n  theme_classic() +\n  geom_bar(stat=\"identity\") +\n  geom_errorbar(aes(ymin =  CI_lwr, ymax =  CI_upr), width=0.2) +\n  stat_pvalue_manual(mydata_example1, label = \"{p} {p_notation}\", size =3) +\n  coord_cartesian(ylim=c(0,10)) + # new \n  scale_y_continuous(expand = expansion(mult = c(0, 0))) # new\nmydata_example1 %>% ggplot(aes(x=Species,y=average_Petal_Length,fill=Species)) +\n  theme_classic() +\n  geom_bar(stat=\"identity\") +\n  geom_errorbar(aes(ymin =  CI_lwr, ymax =  CI_upr), width=0.2) +\n  stat_pvalue_manual(mydata_example1, label = \"{p} {p_notation}\", size =3) +\n  coord_cartesian(ylim=c(0,10)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.0))) +\n  scale_fill_manual(values=c(\"grey65\",\"grey45\", \"grey25\")) +\n  xlab(\"\") + ylab(\"Average petal length\") + ggtitle(\"Comparing species based on petal length\") +\n  theme(\n    axis.title.y = element_text(size=12, family =  \"Times New Roman\"),\n    plot.title = element_text(size = 14, family = \"Times New Roman\", face=\"bold\",hjust = 0.5), # h(orizontal)just ranges from 0 (left) to 1 (right) so 0.5 is the middle\n    axis.text.y = element_text(size = 10), # text on the \"ticks\" on the y-axis\n    axis.text.x = element_text(size = 10), # text on the \"ticks\" on the x-axis\n    legend.position = \"bottom\", \n    legend.title = element_blank() # otherwise the word \"Species\" will appear in the legend\n  )"},{"path":"data-visualisation.html","id":"example-2","chapter":"4 Data visualisation","heading":"4.3.3 Example 2","text":"Staying flowers. Suppose want scatter plot using sepal width (x-axis) sepal length (y-axis). scatter plot want histogram predictor (variable x-axis); right side want histogram outcome (variable y-axis). time, get following rules.\n1. legend\n2. Use following colors: hotpink2, darkgoldenrod3, darkorchid1 yes colors R, click \n3. name species put somewhere random scatter plot without using aes().\n4. histogram outcome rotated 90° right.\n5. Histograms small height, 20 bins, “normal distribution showing line”.Good, need make 3 graphs: one scatter plot, two histograms. can use package cowplot “glue” plots together one object. package can also used reduce height histograms.already familiar scatter plots. novelty removal legend can easily done theme(). text objects (species), can use geom_text place somewhere. name plot “scatter”.also familiar histograms “normal distribution line”. remove x-y-axis, text, tick marks (small vertical stripes axis). can done theme() shown code histogram “hist_x” can also use theme_void() shown code histogram “hist_y”. important, since need rotate one histograms using coord_flip() function, tip put coord_flip() right ggplot(). histogram change extend put coord_flip later code!Alright, lets use cowplot package glue plots together make histograms shorter, putting scatter plot spotlight. Now current example want put one plot spot light putting multiple smaller plots ,,left, right, tricky one. adjust size histograms, done something simple like :align = “hv” ensures axes lined appropriately horizontally vertically. add one histogram (e.g., y-axis one), done something like :enough , lets reduce size histograms align scatter plot. case, need first align histograms using align_plots() function cowplot package. can use aligned histograms alongside scatter plot","code":"\nscatter = mydata %>% ggplot(aes(y = Sepal.Length, x = Sepal.Width, color = Species)) +\n  theme_classic() +\n  scale_color_manual(values = c(\"hotpink2\",\"darkgoldenrod3\",\"darkorchid1\")) +\n  geom_point() +\n  geom_text(label=\"Setosa\", x=2.1, y=7.5,color=\"hotpink\") +\n  geom_text(label=\"Versicolor\", x=2.1, y=7.2,color=\"darkgoldenrod3\") +\n  geom_text(label=\"Virginica\", x=2.1, y=6.9,color=\"darkorchid1\") +\n  ylab(\"Sepal length\") + xlab(\"Sepal width\") +\n  theme(\n   legend.position = \"none\" # Removes the legend\n  )\nhist_x = mydata %>% ggplot(aes(x = Sepal.Width)) + \n  geom_histogram(aes(y=..density..),fill=\"grey40\",color=\"grey10\", bins = 20) +\n  stat_function(fun=dnorm, args=list(mean=mean(mydata$Sepal.Width), sd=sd(mydata$Sepal.Width)),color=\"hotpink\", linetype = \"dotdash\",size=2) +\n  xlab(\"\") + ylab(\"\") +\n  theme_classic() + \n  theme(\n   axis.line.x = element_blank(),\n   axis.ticks.x = element_blank(),\n   axis.text.x = element_blank(),\n   axis.line.y = element_blank(),\n   axis.ticks.y = element_blank(),\n   axis.text.y = element_blank()\n  )\n\nhist_y = mydata %>% ggplot(aes(x = Sepal.Length)) + \n  coord_flip() +\n  geom_histogram(aes(y=..density..),fill=\"grey40\",color=\"grey10\", bins = 20) +\n  stat_function(fun=dnorm, args=list(mean=mean(mydata$Sepal.Length), sd=sd(mydata$Sepal.Length)),color=\"hotpink\", linetype = \"dotdash\",size=2) +\n  xlab(\"\") + ylab(\"\") +\n  theme_void()\nlibrary(cowplot)\nplot_grid(\n  hist_x,NULL,scatter,hist_y,\n  align=\"hv\"\n)\n plot_grid(\n  scatter,hist_y,\n  rel_widths = c(1,0.3), # Here the width of the histogram is multiplied by factor 0.3 \n  align=\"h\" # horizontally\n)\n# Create the aligned histograms (aligned to the scatter plot).\naligned_hist_x = align_plots(hist_x, scatter, align = \"v\")[[1]] # [[1]] will extract the aligned version of our original hist_x\naligned_hist_y = align_plots(hist_y, scatter, align = \"h\")[[1]]\n\n# Arrange plots\nplot_grid(\n  aligned_hist_x\n  , NULL\n  , scatter\n  , aligned_hist_y\n  , ncol = 2\n  , nrow = 2\n  , rel_heights = c(0.3, 1) # hist_x reduced in size, NULL (nothing) with no size adjustments \n  , rel_widths = c(1, 0.3) # scatter plot with no size adjustments sized, hist_y reduced in size\n)"},{"path":"data-visualisation.html","id":"interactive-plots","chapter":"4 Data visualisation","heading":"4.4 Interactive plots","text":"Wrapping section, many “cluster units” (participants, test subjects, etc.). want plot change measurement per cluster unit, time. quickly visualize :fun figuring change per participants… Luckily, ggplotly() function plotly package package offers interact plots. use plotly(), lot cluster units, make sure remove legend (access anyways) otherwise legend see.Look plot . plot can interact webpage. Hover dots see mini window showing time, score, participant. R Markdown R Studio, also see list participants left side. Unfortunately see part webpage describe . \nclick participant 1 participant list (see), temporarily remove participant plot. click , reappear. Click twice rapidly succession participant 20, see dots lines participant. click twice , everything changes normal. short, can “show” “hide” participants . others can beyond scope guide.last plot chapter. can rest eyes bit,Since multiple measurements per cluster unit, consider plot simple regression line per participant (just demonstration purposes). consider plot simple regression slope per participant alongside overall slopeIn ending, want note show different plots later parts discussing linear regressions (e.g., johnson-neyman intervals) mediation (path diagrams).","code":"\n\nmydata = data.frame(\n      participant = factor(rep(c(1:50),times = 5)),\n      score = runif(250,1,10),\n      time = rep(c(1:5), each = 50)\n           )\n\nmydata %>% ggplot(aes(y=score, x=time, color=participant)) +\n  geom_point() + geom_line()\nlibrary(plotly)\nggplotly(\nmydata %>% ggplot(aes(y=score, x=time, color=participant)) +\n  geom_point() + geom_line() +\n  theme(\n    legend.position = \"none\"\n       )\n    )\nggplotly(\nmydata %>% ggplot(aes(y=score, x=time, color=participant)) +\n  geom_smooth(method=\"lm\", se =  FALSE) + # per participant\n  geom_smooth(aes(group=0), method=\"lm\", se = FALSE, color=\"black\") + # Overall (I like to call this \"ungrouping\")\n  geom_smooth(aes(group=0), se = FALSE, color=\"black\", linetype=\"dashed\",alpha=0.75) +  \n  theme(\n    legend.position = \"none\"\n  )\n)"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","text":"now useful skills belt: data preprocessing/cleaning, calculations, data visualization… remaining parts, shift focus data analysis, mainly “investigation/research/testing” view.particular part may interest , particular affiliated fields Psychology. fields, may confronted questionnaires presumed measure something… often abstract construct. Questionnaires often include multiple items presumed represent constructs questionnaire presumed measure. example, items like “happy”, “energized”, “relaxed”, “calm”, presumed reflect construct “positive affect”.question arises, indications consistency questionnaires? questionnaire items reliably tap onto assumed construct? Can questionnaire items summarized factors (“latent constructs”) may?part ’ll go reliability, confirmatory factor analysis, exploratory factor analysis. Specifically:Starting classic (debated) indicator reliability, Cronbach’s alpha.. compute indicator using psych package ’ll show compute hand.explore McDonald’s Omega reliability indicator alternative Cronbach’s alpha. part use lavaan package semTools package introduce Confirmatory Factor Analysis, factor loadings (checking tau equivalence), CFA fit indicators improve .conduct Exploratory Factor Analysis unveil underlying structure data. briefly discuss considerations concerning kind analysis including multicollinearity (variance inflation factors), multivariate normallity (Mardia’s skewness kurtosis), univariate/multivariate outliers (mahalanobis distance). ’ll also briefly discuss methods gives us suggestions regarding number factors restrain (scree plots, parallel analysis, Minimal Average Potential). end small demonstration using fa() function psych package.","code":""},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"cronbachs-alpha","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.1 Cronbach’s alpha","text":"Starting one popular indicators internal consistency (reliability). years, indicator spared criticism click example. Nevertheless, show compute . use psych package free online dataset, click . dataset contains items “belong” presumed construct.Note receive lot output. (raw) alpha printed top output. also skip ask want. example:looks bit complicated brackets. trick .\nSuppose ran following code:Now click freshly created alpha_output object (Environment window, top right). looks something like :\nClick total, click raw_alpha. bottom see: “alpha_output[[”total”]][[”raw_alpha”]]”. Nnow can copy-paste [[“total”]][[“raw_alpha”]] part R. “store object click” strategy works variety contexts regression models.","code":"\nlibrary(pacman)\npacman::p_load(psych, dplyr, haven) \n\nmydata = read_sav(\"data_files/pone.0199750.s001.sav\") \n\nalpha(mydata)\n#> \n#> Reliability analysis   \n#> Call: alpha(x = mydata)\n#> \n#>   raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd\n#>       0.28      0.88    0.89      0.24 7.4 0.022  1.8 0.79\n#>  median_r\n#>      0.26\n#> \n#>     95% confidence boundaries \n#>          lower alpha upper\n#> Feldt     0.21  0.28  0.34\n#> Duhachek  0.23  0.28  0.32\n#> \n#>  Reliability if an item is dropped:\n#>                    raw_alpha std.alpha G6(smc) average_r\n#> age                     0.89      0.89    0.89      0.25\n#> sex                     0.27      0.88    0.89      0.25\n#> BDI1                    0.26      0.87    0.88      0.23\n#> BDI2                    0.26      0.87    0.89      0.23\n#> BDI3                    0.26      0.87    0.88      0.23\n#> BDI4                    0.25      0.87    0.88      0.23\n#> BDI5                    0.27      0.88    0.89      0.24\n#> BDI6                    0.27      0.88    0.89      0.24\n#> BDI7                    0.26      0.87    0.88      0.23\n#> BDI8                    0.26      0.87    0.89      0.23\n#> BDI9                    0.27      0.88    0.89      0.24\n#> BDI10                   0.25      0.87    0.88      0.23\n#> BDI11                   0.26      0.88    0.89      0.23\n#> BDI12                   0.26      0.87    0.89      0.23\n#> BDI13                   0.26      0.87    0.89      0.23\n#> BDI14                   0.26      0.88    0.89      0.23\n#> BDI15                   0.25      0.87    0.88      0.23\n#> BDI16                   0.27      0.88    0.89      0.24\n#> BDI17                   0.26      0.87    0.89      0.23\n#> BDI18                   0.26      0.88    0.89      0.24\n#> BDI19                   0.26      0.87    0.89      0.23\n#> BDI20                   0.25      0.87    0.88      0.23\n#> BDI21                   0.25      0.88    0.89      0.24\n#> clinicalandgeneral      0.27      0.88    0.89      0.25\n#>                    S/N alpha se  var.r med.r\n#> age                7.8   0.0049 0.0091  0.26\n#> sex                7.6   0.0215 0.0111  0.26\n#> BDI1               6.8   0.0214 0.0121  0.25\n#> BDI2               7.0   0.0215 0.0126  0.25\n#> BDI3               6.9   0.0213 0.0122  0.25\n#> BDI4               6.9   0.0216 0.0125  0.25\n#> BDI5               7.1   0.0212 0.0125  0.26\n#> BDI6               7.1   0.0212 0.0125  0.26\n#> BDI7               6.8   0.0212 0.0116  0.25\n#> BDI8               7.0   0.0211 0.0124  0.25\n#> BDI9               7.2   0.0215 0.0128  0.26\n#> BDI10              6.9   0.0215 0.0128  0.25\n#> BDI11              7.1   0.0214 0.0131  0.26\n#> BDI12              7.0   0.0212 0.0124  0.25\n#> BDI13              7.0   0.0212 0.0126  0.25\n#> BDI14              7.0   0.0215 0.0126  0.25\n#> BDI15              6.9   0.0218 0.0125  0.25\n#> BDI16              7.3   0.0213 0.0126  0.26\n#> BDI17              7.0   0.0214 0.0129  0.25\n#> BDI18              7.2   0.0213 0.0131  0.26\n#> BDI19              7.0   0.0211 0.0127  0.25\n#> BDI20              7.0   0.0218 0.0126  0.25\n#> BDI21              7.1   0.0221 0.0131  0.26\n#> clinicalandgeneral 7.5   0.0216 0.0118  0.26\n#> \n#>  Item statistics \n#>                       n raw.r std.r r.cor r.drop  mean\n#> age                1038 0.884  0.17  0.11  0.097 31.44\n#> sex                1040 0.102  0.24  0.18  0.073  0.55\n#> BDI1               1040 0.352  0.65  0.64  0.319  0.35\n#> BDI2               1040 0.319  0.59  0.56  0.288  0.30\n#> BDI3               1040 0.266  0.59  0.57  0.236  0.29\n#> BDI4               1040 0.409  0.62  0.60  0.376  0.47\n#> BDI5               1040 0.205  0.53  0.50  0.170  0.47\n#> BDI6               1040 0.220  0.51  0.48  0.181  0.33\n#> BDI7               1040 0.295  0.67  0.66  0.259  0.39\n#> BDI8               1040 0.246  0.57  0.55  0.205  0.66\n#> BDI9               1040 0.182  0.45  0.41  0.159  0.13\n#> BDI10              1040 0.381  0.60  0.58  0.343  0.50\n#> BDI11              1040 0.307  0.53  0.50  0.266  0.56\n#> BDI12              1040 0.281  0.59  0.56  0.247  0.59\n#> BDI13              1040 0.282  0.57  0.55  0.244  0.49\n#> BDI14              1040 0.320  0.55  0.53  0.288  0.28\n#> BDI15              1040 0.462  0.59  0.57  0.429  0.68\n#> BDI16              1040 0.192  0.42  0.38  0.146  0.92\n#> BDI17              1040 0.298  0.56  0.53  0.261  0.44\n#> BDI18              1040 0.257  0.47  0.43  0.210  0.79\n#> BDI19              1040 0.254  0.57  0.55  0.209  0.71\n#> BDI20              1040 0.458  0.58  0.56  0.426  0.69\n#> BDI21              1040 0.497  0.50  0.47  0.466  0.38\n#> clinicalandgeneral 1040 0.096  0.30  0.25  0.081  1.08\n#>                       sd\n#> age                15.81\n#> sex                 0.50\n#> BDI1                0.69\n#> BDI2                0.64\n#> BDI3                0.60\n#> BDI4                0.73\n#> BDI5                0.64\n#> BDI6                0.74\n#> BDI7                0.71\n#> BDI8                0.78\n#> BDI9                0.43\n#> BDI10               0.90\n#> BDI11               0.81\n#> BDI12               0.74\n#> BDI13               0.82\n#> BDI14               0.66\n#> BDI15               0.74\n#> BDI16               0.82\n#> BDI17               0.72\n#> BDI18               0.89\n#> BDI19               0.85\n#> BDI20               0.76\n#> BDI21               0.78\n#> clinicalandgeneral  0.28\n#> \n#> Non missing response frequency for each item\n#>                       0    1    2    3 miss\n#> sex                0.45 0.55 0.00 0.00    0\n#> BDI1               0.76 0.15 0.07 0.02    0\n#> BDI2               0.78 0.17 0.02 0.03    0\n#> BDI3               0.78 0.18 0.03 0.02    0\n#> BDI4               0.65 0.27 0.06 0.03    0\n#> BDI5               0.59 0.37 0.02 0.02    0\n#> BDI6               0.79 0.14 0.02 0.05    0\n#> BDI7               0.72 0.19 0.07 0.02    0\n#> BDI8               0.49 0.40 0.07 0.04    0\n#> BDI9               0.89 0.09 0.01 0.01    0\n#> BDI10              0.72 0.12 0.10 0.06    0\n#> BDI11              0.60 0.30 0.05 0.05    0\n#> BDI12              0.53 0.37 0.07 0.03    0\n#> BDI13              0.68 0.21 0.07 0.05    0\n#> BDI14              0.82 0.10 0.06 0.02    0\n#> BDI15              0.46 0.43 0.09 0.03    0\n#> BDI16              0.34 0.43 0.19 0.04    0\n#> BDI17              0.67 0.25 0.05 0.03    0\n#> BDI18              0.46 0.36 0.12 0.06    0\n#> BDI19              0.52 0.30 0.15 0.04    0\n#> BDI20              0.47 0.41 0.09 0.03    0\n#> BDI21              0.76 0.15 0.04 0.05    0\n#> clinicalandgeneral 0.00 0.92 0.08 0.00    0\nalpha(mydata)[[\"total\"]][[\"raw_alpha\"]]\n#> [1] 0.2751774\nalpha(mydata)[[\"total\"]][[\"std.alpha\"]]\n#> [1] 0.8808157\nalpha_output = alpha(mydata)"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"alpha-by-hand","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.1.1 Alpha by hand","text":"desired also compute Cronbach’s alpha without fancy packages. Just fun educational purposes, demonstrate .","code":"\n# Formula Cronbach's alpha: (N)/(N-1) * ( (VARIANCE SUM SCORE ACROSS ITEMS - VARIANCE SUM SCORE PER ITEM)/VARIANCE SUM SCORE ACROSS ITEMS )\n  \n  # ingredients:\n    N = ncol(mydata) # N\n    variance_sum_across_items = var( rowSums(mydata) ) # VARIANCE SUM SCORE ACROSS ITEMS\n    variance_sum_per_item = sum(  diag(var(mydata, na.rm = TRUE))  ) # VARIANCE SUM SCORE PER ITEM\n    \n  # Put the above in the formula:\n    (N)/(N-1) * ( (variance_sum_across_items - variance_sum_per_item)/variance_sum_across_items )\n#> [1] NA"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"omega","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.2 Omega","text":"told earlier, bit commotion surrounding whether appropriate use Cronbach’s alpha. put forward alpha holds several strong assumptions, likely apply majority data. classic example, Cronbach’s alpha assumes (essential) tau equivalence, meaning items contribute equally construct measured (.e., similar factor loadings, similar “weight” speak)..can use instead?One popular alternative, McDonald’s omega, relaxes assumption (essential) tau equivalence. variety packages allow compute indicator, even psych package. simplicity, use lavaan semtools packages use reliability() function can compute Cronbach’s alpha McDonald’s omega. , walk Confirmatory Factor Analysis territory.First things first, psych package may interfere certain functions semTools unload . Yes, packages R may sometimes interfere one another. occurs, typically receive message Console (bottom left) telling function masked given package.use reliability() function semTools, “define” model, tell R run CFA using “defined” model. “defining” model CFA structural equation model, need tell R variables want include, variables called manifest latent (see later parts), variables relate one another (regressions), . context CFA, need tell (latent) construct/factor (thing questionnaire presumed tap ) items, (manifest) observed item scores/factors, reflect/load latent construct/factor. define model:Now enter model CFA (using lavaan package). code specify certain options. enable standardized output (discussed later ), use listwise deletion empty values, use Maximum Likelihood Robust Estimations method. goes well, can compute omega putting CFA object reliability() function. Importantly, now temporarily ignore output CFA object (.e., ’s summary). However, highly recommend always look output first (later )Glance output reliability(), see alpha, omega, omega2, omega3, avevar. Avevar average variance extracted, reliability measure indication much variance attributable common factor. Notice three omega’s. short, first one (omega) “controls” (latent) factors, second one (omega2) , third one (omega3) denuminator equals sum elements variance-covariance matrix item scores. Omega omega2 likely differ define one latent factor multi-dimensionality manifest factors/items(e.g., items loading notably latent factors).can also request spread (e.g., confidence intervals) surrounding omega using MBESS package. example use bootstrap 5 (purely demonstration purposes) practice consider go higher number (e.g., 500 ).important note used fairly simple model continuous variables one latent construct (.e., unidimensional model). types models exist including categorical variables, multiple factors, hierarchical factor models. Covering exhaustive purposis guide. However, direct work Flora, 2020 provides detailed background examples R. reference article provided end part.","code":"\ndetach(\"package:psych\", unload = TRUE)\n  p_load(lavaan, semTools)\n  mymodel = '\n  \n  # Here I defined a latent factor (which I arbitrarily named \"DEP\") and told R that the following manifest factors (here the variables from my dataset) load on this latent factor.\n  # The names of the manifest factors must match those in your dataset !\n  # the \"=~\" sign denotes a \"latent construct reflected by manifest factors relation\"\n  \n  DEP =~ BDI1 + BDI2 +  BDI3 +  BDI4 +  BDI5 +  BDI6 +  BDI7 +  \n  BDI8 +  BDI9 +  BDI10 +  BDI11 +  BDI12 +  BDI13 +  BDI14 + \n  BDI15 +  BDI16 +  BDI17 +  BDI18 +  BDI19 +  BDI20 +  BDI21\n  '\n  mycfa=cfa(mymodel, data = mydata, std.lv=TRUE, missing = \"direct\", estimator = \"MLR\")\n  reliability(mycfa)\n#>              DEP\n#> alpha  0.8889281\n#> omega  0.8899104\n#> omega2 0.8899104\n#> omega3 0.8872431\n#> avevar 0.2844963\n  library(MBESS)\n  ci.reliability(data = mydata, type = \"omega\", interval.type = \"perc\", B=5, conf.level = 0.95)\n#> $est\n#> [1] 0.2725901\n#> \n#> $se\n#> [1] 0.03310795\n#> \n#> $ci.lower\n#> [1] 0.2247075\n#> \n#> $ci.upper\n#> [1] 0.3123625\n#> \n#> $conf.level\n#> [1] 0.95\n#> \n#> $type\n#> [1] \"omega\"\n#> \n#> $interval.type\n#> [1] \"percentile bootstrap\"\n    # applying a bootstrap of 5 bootstrap runs (consider 500+) and a percental CI type"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"fit-indices-and-how-to-potentially-improve-model-fit","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.2.1 Fit indices and how to potentially improve model fit","text":"said , ignored output CFA object, really . starters, check model fit. model fit refers closely data matches model defined (relations model). important realize, “good fitting model” prove defined model “good”, “realistic” proven model.see well model fits data start requesting model fit indicators. Sometimes may want improve fit indicators. , affect value omega. ’re can also inspect factor loadings. way can also check cronbach’s alpha assumption (essential) tau equivalence.Alright, lot output. Recall output interpretation beyond scope guide note two things:\n1. argue room improvement based multiple fit indicators. argue CFI TLI preferably .90, perhaps even .950. , RMSEA looks “ok” prefer value 0.05. course really real cut-, conventions.\n2. factor loadings (see “Latent Variables” output) equal. can taken violation tau equivalence assumption, Cronbach’s alpha may appropriate report.Next two points, notice current values alpha omega similar. However, sometimes notable differences emerge upon improving model fit.?Well straightforward way can inspect residual correlations CFA object “adjust/account” (manifest) variables show … “notable” correlation. High residual correlations may indicate items sare unique variance, , variance explained latent construct (extra variance beyond latent construct speak). Let’s look residual correlations note correlations least say .075 (arbitrary example).code tells yhat 13 (unique) correlations .075. Remember step defined model CFA (called “mymodel”)? Within model definition, also add correlations 13 (manifest) factors correlated. ’ll check CFA model output .Ok, model fit indicators improve bit. omega change?bigger difference alpha omega … “notable”. course, small large (reason often see put “” around certain words)? experience, omega sometimes changes “little”, sometimes “notably”. Various factors likely play role , e.g., far Cronbach’s alpha held assumptions violated.","code":"\n  summary(mycfa, fit.measures=TRUE, standardized=TRUE) \n#> lavaan 0.6.16 ended normally after 27 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        63\n#> \n#>   Number of observations                          1040\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                               Standard      Scaled\n#>   Test Statistic                               969.539     590.608\n#>   Degrees of freedom                               189         189\n#>   P-value (Chi-square)                           0.000       0.000\n#>   Scaling correction factor                                  1.642\n#>     Yuan-Bentler correction (Mplus variant)                       \n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              6110.882    3716.183\n#>   Degrees of freedom                               210         210\n#>   P-value                                        0.000       0.000\n#>   Scaling correction factor                                  1.644\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.868       0.885\n#>   Tucker-Lewis Index (TLI)                       0.853       0.873\n#>                                                                   \n#>   Robust Comparative Fit Index (CFI)                         0.886\n#>   Robust Tucker-Lewis Index (TLI)                            0.873\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)             -21461.330  -21461.330\n#>   Scaling correction factor                                  1.772\n#>       for the MLR correction                                      \n#>   Loglikelihood unrestricted model (H1)             NA          NA\n#>   Scaling correction factor                                  1.674\n#>       for the MLR correction                                      \n#>                                                                   \n#>   Akaike (AIC)                               43048.660   43048.660\n#>   Bayesian (BIC)                             43360.319   43360.319\n#>   Sample-size adjusted Bayesian (SABIC)      43160.223   43160.223\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.063       0.045\n#>   90 Percent confidence interval - lower         0.059       0.042\n#>   90 Percent confidence interval - upper         0.067       0.048\n#>   P-value H_0: RMSEA <= 0.050                    0.000       0.993\n#>   P-value H_0: RMSEA >= 0.080                    0.000       0.000\n#>                                                                   \n#>   Robust RMSEA                                               0.058\n#>   90 Percent confidence interval - lower                     0.053\n#>   90 Percent confidence interval - upper                     0.063\n#>   P-value H_0: Robust RMSEA <= 0.050                         0.007\n#>   P-value H_0: Robust RMSEA >= 0.080                         0.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.046       0.046\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Sandwich\n#>   Information bread                           Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   DEP =~                                              \n#>     BDI1              0.438    0.028   15.417    0.000\n#>     BDI2              0.356    0.031   11.445    0.000\n#>     BDI3              0.353    0.030   11.726    0.000\n#>     BDI4              0.433    0.028   15.285    0.000\n#>     BDI5              0.327    0.029   11.381    0.000\n#>     BDI6              0.372    0.034   10.901    0.000\n#>     BDI7              0.479    0.028   17.166    0.000\n#>     BDI8              0.445    0.031   14.474    0.000\n#>     BDI9              0.175    0.022    7.993    0.000\n#>     BDI10             0.505    0.033   15.353    0.000\n#>     BDI11             0.397    0.033   11.984    0.000\n#>     BDI12             0.429    0.027   16.104    0.000\n#>     BDI13             0.459    0.033   13.925    0.000\n#>     BDI14             0.361    0.029   12.354    0.000\n#>     BDI15             0.404    0.029   14.049    0.000\n#>     BDI16             0.307    0.028   11.115    0.000\n#>     BDI17             0.379    0.029   13.112    0.000\n#>     BDI18             0.370    0.032   11.611    0.000\n#>     BDI19             0.467    0.031   15.232    0.000\n#>     BDI20             0.402    0.029   13.925    0.000\n#>     BDI21             0.333    0.036    9.268    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.438    0.633\n#>     0.356    0.559\n#>     0.353    0.588\n#>     0.433    0.597\n#>     0.327    0.512\n#>     0.372    0.500\n#>     0.479    0.678\n#>     0.445    0.568\n#>     0.175    0.412\n#>     0.505    0.562\n#>     0.397    0.488\n#>     0.429    0.582\n#>     0.459    0.557\n#>     0.361    0.544\n#>     0.404    0.549\n#>     0.307    0.374\n#>     0.379    0.526\n#>     0.370    0.418\n#>     0.467    0.547\n#>     0.402    0.526\n#>     0.333    0.427\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .BDI1              0.346    0.021   16.142    0.000\n#>    .BDI2              0.295    0.020   14.938    0.000\n#>    .BDI3              0.287    0.019   15.397    0.000\n#>    .BDI4              0.467    0.022   20.782    0.000\n#>    .BDI5              0.475    0.020   23.953    0.000\n#>    .BDI6              0.329    0.023   14.281    0.000\n#>    .BDI7              0.391    0.022   17.853    0.000\n#>    .BDI8              0.663    0.024   27.270    0.000\n#>    .BDI9              0.134    0.013   10.126    0.000\n#>    .BDI10             0.496    0.028   17.804    0.000\n#>    .BDI11             0.560    0.025   22.184    0.000\n#>    .BDI12             0.591    0.023   25.866    0.000\n#>    .BDI13             0.487    0.026   19.083    0.000\n#>    .BDI14             0.278    0.021   13.494    0.000\n#>    .BDI15             0.676    0.023   29.607    0.000\n#>    .BDI16             0.921    0.025   36.169    0.000\n#>    .BDI17             0.436    0.022   19.500    0.000\n#>    .BDI18             0.788    0.027   28.680    0.000\n#>    .BDI19             0.708    0.026   26.713    0.000\n#>    .BDI20             0.688    0.024   29.058    0.000\n#>    .BDI21             0.378    0.024   15.651    0.000\n#>     DEP               0.000                           \n#>    Std.lv  Std.all\n#>     0.346    0.501\n#>     0.295    0.463\n#>     0.287    0.477\n#>     0.467    0.644\n#>     0.475    0.743\n#>     0.329    0.443\n#>     0.391    0.554\n#>     0.663    0.846\n#>     0.134    0.314\n#>     0.496    0.552\n#>     0.560    0.688\n#>     0.591    0.802\n#>     0.487    0.592\n#>     0.278    0.418\n#>     0.676    0.918\n#>     0.921    1.122\n#>     0.436    0.605\n#>     0.788    0.889\n#>     0.708    0.828\n#>     0.688    0.901\n#>     0.378    0.485\n#>     0.000    0.000\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .BDI1              0.287    0.021   13.687    0.000\n#>    .BDI2              0.279    0.023   11.888    0.000\n#>    .BDI3              0.236    0.018   13.273    0.000\n#>    .BDI4              0.339    0.024   13.925    0.000\n#>    .BDI5              0.302    0.017   17.306    0.000\n#>    .BDI6              0.413    0.037   11.232    0.000\n#>    .BDI7              0.270    0.019   13.971    0.000\n#>    .BDI8              0.417    0.023   18.342    0.000\n#>    .BDI9              0.150    0.019    7.732    0.000\n#>    .BDI10             0.553    0.036   15.323    0.000\n#>    .BDI11             0.504    0.034   14.943    0.000\n#>    .BDI12             0.359    0.023   15.813    0.000\n#>    .BDI13             0.468    0.032   14.807    0.000\n#>    .BDI14             0.311    0.028   10.907    0.000\n#>    .BDI15             0.379    0.021   17.842    0.000\n#>    .BDI16             0.580    0.025   23.143    0.000\n#>    .BDI17             0.375    0.028   13.486    0.000\n#>    .BDI18             0.649    0.031   20.872    0.000\n#>    .BDI19             0.512    0.024   21.019    0.000\n#>    .BDI20             0.421    0.024   17.796    0.000\n#>    .BDI21             0.496    0.037   13.346    0.000\n#>     DEP               1.000                           \n#>    Std.lv  Std.all\n#>     0.287    0.599\n#>     0.279    0.687\n#>     0.236    0.654\n#>     0.339    0.644\n#>     0.302    0.738\n#>     0.413    0.750\n#>     0.270    0.541\n#>     0.417    0.678\n#>     0.150    0.831\n#>     0.553    0.685\n#>     0.504    0.762\n#>     0.359    0.661\n#>     0.468    0.690\n#>     0.311    0.704\n#>     0.379    0.699\n#>     0.580    0.860\n#>     0.375    0.723\n#>     0.649    0.826\n#>     0.512    0.701\n#>     0.421    0.723\n#>     0.496    0.818\n#>     1.000    1.000\n  # fit.measures will show the model fit indicators such as RMSSEA and CFI\n  options(scipen=999) # Disables the scientific notation\n  residuals(mycfa, type = \"cor\")$cor # For visual inspection of \n#> NULL\n  \n  # TIP, since I have a lot of correlations visual inspection of correlations >.075 becomes cumbersome\n  # Below a code that will prompt a window showing the variables with correlations above .075\nView(\n  data.frame(  as.table(residuals(mycfa, type = \"cor\")$cov)  )\n  %>% filter(Freq>0.075) %>% # with Freq being the correlations. Unfortunately this will output duplicates so I will filter them out\n    mutate(is_duplicated = ifelse(duplicated(Freq)==TRUE , \"yes\",\"no\"    )) %>% # i.e., yes to duplicate correlations\n  filter(!is_duplicated ==\"yes\") # get rid of duplicates\n)\nmymodel = '\n  DEP =~ BDI1 + BDI2 +  BDI3 +  BDI4 +  BDI5 +  BDI6 +  BDI7 +  \n  BDI8 +  BDI9 +  BDI10 +  BDI11 +  BDI12 +  BDI13 +  BDI14 + \n  BDI15 +  BDI16 +  BDI17 +  BDI18 +  BDI19 +  BDI20 +  BDI21\n  \n  # the ~~ stands for correlation. So I tell R to consider their correlations these (and to not set them to 0 by default)\n  \n  BDI10 ~~ BDI1\n  BDI4 ~~  BDI2\n  BDI5 ~~  BDI3\n  BDI7 ~~  BDI3\n  BDI9 ~~  BDI3\n  BDI6 ~~  BDI5\n  BDI8 ~~  BDI5\n  BDI17 ~~ BDI11\n  BDI19 ~~ BDI3\n  BDI16 ~~ BDI15\n  BDI20 ~~ BDI15\n  BDI18 ~~ BDI16\n  BDI20 ~~ BDI16\n  '\n\nmycfa=cfa(mymodel, data = mydata, std.lv=TRUE, missing = \"direct\", estimator = \"MLR\")\nsummary(mycfa, fit.measures=TRUE, standardized=TRUE)\n#> lavaan 0.6.16 ended normally after 34 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        76\n#> \n#>   Number of observations                          1040\n#>   Number of missing patterns                         1\n#> \n#> Model Test User Model:\n#>                                               Standard      Scaled\n#>   Test Statistic                               551.368     340.106\n#>   Degrees of freedom                               176         176\n#>   P-value (Chi-square)                           0.000       0.000\n#>   Scaling correction factor                                  1.621\n#>     Yuan-Bentler correction (Mplus variant)                       \n#> \n#> Model Test Baseline Model:\n#> \n#>   Test statistic                              6110.882    3716.183\n#>   Degrees of freedom                               210         210\n#>   P-value                                        0.000       0.000\n#>   Scaling correction factor                                  1.644\n#> \n#> User Model versus Baseline Model:\n#> \n#>   Comparative Fit Index (CFI)                    0.936       0.953\n#>   Tucker-Lewis Index (TLI)                       0.924       0.944\n#>                                                                   \n#>   Robust Comparative Fit Index (CFI)                         0.954\n#>   Robust Tucker-Lewis Index (TLI)                            0.945\n#> \n#> Loglikelihood and Information Criteria:\n#> \n#>   Loglikelihood user model (H0)             -21252.244  -21252.244\n#>   Scaling correction factor                                  1.797\n#>       for the MLR correction                                      \n#>   Loglikelihood unrestricted model (H1)             NA          NA\n#>   Scaling correction factor                                  1.674\n#>       for the MLR correction                                      \n#>                                                                   \n#>   Akaike (AIC)                               42656.489   42656.489\n#>   Bayesian (BIC)                             43032.459   43032.459\n#>   Sample-size adjusted Bayesian (SABIC)      42791.073   42791.073\n#> \n#> Root Mean Square Error of Approximation:\n#> \n#>   RMSEA                                          0.045       0.030\n#>   90 Percent confidence interval - lower         0.041       0.026\n#>   90 Percent confidence interval - upper         0.050       0.034\n#>   P-value H_0: RMSEA <= 0.050                    0.965       1.000\n#>   P-value H_0: RMSEA >= 0.080                    0.000       0.000\n#>                                                                   \n#>   Robust RMSEA                                               0.038\n#>   90 Percent confidence interval - lower                     0.032\n#>   90 Percent confidence interval - upper                     0.044\n#>   P-value H_0: Robust RMSEA <= 0.050                         1.000\n#>   P-value H_0: Robust RMSEA >= 0.080                         0.000\n#> \n#> Standardized Root Mean Square Residual:\n#> \n#>   SRMR                                           0.036       0.036\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                             Sandwich\n#>   Information bread                           Observed\n#>   Observed information based on                Hessian\n#> \n#> Latent Variables:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   DEP =~                                              \n#>     BDI1              0.429    0.029   15.002    0.000\n#>     BDI2              0.354    0.031   11.324    0.000\n#>     BDI3              0.343    0.031   11.097    0.000\n#>     BDI4              0.431    0.028   15.126    0.000\n#>     BDI5              0.312    0.029   10.685    0.000\n#>     BDI6              0.368    0.034   10.800    0.000\n#>     BDI7              0.479    0.028   17.150    0.000\n#>     BDI8              0.445    0.031   14.244    0.000\n#>     BDI9              0.174    0.022    8.005    0.000\n#>     BDI10             0.492    0.033   14.712    0.000\n#>     BDI11             0.393    0.034   11.617    0.000\n#>     BDI12             0.436    0.027   16.044    0.000\n#>     BDI13             0.466    0.033   13.926    0.000\n#>     BDI14             0.365    0.029   12.384    0.000\n#>     BDI15             0.388    0.029   13.333    0.000\n#>     BDI16             0.284    0.028   10.096    0.000\n#>     BDI17             0.373    0.029   12.718    0.000\n#>     BDI18             0.365    0.032   11.255    0.000\n#>     BDI19             0.473    0.031   15.250    0.000\n#>     BDI20             0.383    0.029   13.411    0.000\n#>     BDI21             0.337    0.036    9.244    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.429    0.621\n#>     0.354    0.556\n#>     0.343    0.572\n#>     0.431    0.594\n#>     0.312    0.489\n#>     0.368    0.496\n#>     0.479    0.678\n#>     0.445    0.568\n#>     0.174    0.410\n#>     0.492    0.547\n#>     0.393    0.483\n#>     0.436    0.592\n#>     0.466    0.565\n#>     0.365    0.550\n#>     0.388    0.527\n#>     0.284    0.347\n#>     0.373    0.517\n#>     0.365    0.411\n#>     0.473    0.554\n#>     0.383    0.502\n#>     0.337    0.433\n#> \n#> Covariances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>  .BDI1 ~~                                             \n#>    .BDI10             0.096    0.020    4.901    0.000\n#>  .BDI2 ~~                                             \n#>    .BDI4              0.038    0.017    2.294    0.022\n#>  .BDI3 ~~                                             \n#>    .BDI5              0.037    0.012    3.041    0.002\n#>    .BDI7              0.041    0.015    2.763    0.006\n#>    .BDI9              0.021    0.010    2.138    0.033\n#>  .BDI5 ~~                                             \n#>    .BDI6              0.059    0.016    3.719    0.000\n#>    .BDI8              0.046    0.014    3.294    0.001\n#>  .BDI11 ~~                                            \n#>    .BDI17             0.050    0.018    2.824    0.005\n#>  .BDI3 ~~                                             \n#>    .BDI19            -0.008    0.016   -0.478    0.633\n#>  .BDI15 ~~                                            \n#>    .BDI16             0.065    0.017    3.916    0.000\n#>    .BDI20             0.165    0.020    8.371    0.000\n#>  .BDI16 ~~                                            \n#>    .BDI18             0.100    0.022    4.631    0.000\n#>    .BDI20             0.091    0.018    5.144    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.096    0.235\n#>                   \n#>     0.038    0.124\n#>                   \n#>     0.037    0.135\n#>     0.041    0.160\n#>     0.021    0.111\n#>                   \n#>     0.059    0.163\n#>     0.046    0.129\n#>                   \n#>     0.050    0.114\n#>                   \n#>    -0.008   -0.021\n#>                   \n#>     0.065    0.136\n#>     0.165    0.399\n#>                   \n#>     0.100    0.162\n#>     0.091    0.180\n#> \n#> Intercepts:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .BDI1              0.346    0.021   16.142    0.000\n#>    .BDI2              0.295    0.020   14.938    0.000\n#>    .BDI3              0.287    0.019   15.397    0.000\n#>    .BDI4              0.467    0.022   20.782    0.000\n#>    .BDI5              0.475    0.020   23.953    0.000\n#>    .BDI6              0.329    0.023   14.281    0.000\n#>    .BDI7              0.391    0.022   17.853    0.000\n#>    .BDI8              0.663    0.024   27.270    0.000\n#>    .BDI9              0.134    0.013   10.126    0.000\n#>    .BDI10             0.496    0.028   17.804    0.000\n#>    .BDI11             0.560    0.025   22.184    0.000\n#>    .BDI12             0.591    0.023   25.866    0.000\n#>    .BDI13             0.487    0.026   19.083    0.000\n#>    .BDI14             0.278    0.021   13.494    0.000\n#>    .BDI15             0.676    0.023   29.607    0.000\n#>    .BDI16             0.921    0.025   36.169    0.000\n#>    .BDI17             0.436    0.022   19.500    0.000\n#>    .BDI18             0.788    0.027   28.680    0.000\n#>    .BDI19             0.708    0.026   26.713    0.000\n#>    .BDI20             0.688    0.024   29.058    0.000\n#>    .BDI21             0.378    0.024   15.651    0.000\n#>     DEP               0.000                           \n#>    Std.lv  Std.all\n#>     0.346    0.501\n#>     0.295    0.463\n#>     0.287    0.478\n#>     0.467    0.644\n#>     0.475    0.744\n#>     0.329    0.443\n#>     0.391    0.554\n#>     0.663    0.846\n#>     0.134    0.314\n#>     0.496    0.552\n#>     0.560    0.688\n#>     0.591    0.802\n#>     0.487    0.592\n#>     0.278    0.418\n#>     0.676    0.918\n#>     0.921    1.123\n#>     0.436    0.605\n#>     0.788    0.889\n#>     0.708    0.828\n#>     0.688    0.901\n#>     0.378    0.485\n#>     0.000    0.000\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .BDI1              0.294    0.022   13.545    0.000\n#>    .BDI2              0.281    0.024   11.752    0.000\n#>    .BDI3              0.242    0.019   13.038    0.000\n#>    .BDI4              0.340    0.025   13.644    0.000\n#>    .BDI5              0.310    0.018   17.449    0.000\n#>    .BDI6              0.416    0.037   11.200    0.000\n#>    .BDI7              0.270    0.020   13.588    0.000\n#>    .BDI8              0.417    0.023   18.242    0.000\n#>    .BDI9              0.151    0.019    7.734    0.000\n#>    .BDI10             0.566    0.037   15.313    0.000\n#>    .BDI11             0.507    0.034   14.969    0.000\n#>    .BDI12             0.353    0.023   15.557    0.000\n#>    .BDI13             0.462    0.032   14.528    0.000\n#>    .BDI14             0.308    0.028   10.829    0.000\n#>    .BDI15             0.392    0.022   18.068    0.000\n#>    .BDI16             0.592    0.025   23.500    0.000\n#>    .BDI17             0.380    0.028   13.398    0.000\n#>    .BDI18             0.653    0.031   20.910    0.000\n#>    .BDI19             0.506    0.025   20.483    0.000\n#>    .BDI20             0.436    0.024   18.173    0.000\n#>    .BDI21             0.492    0.037   13.289    0.000\n#>     DEP               1.000                           \n#>    Std.lv  Std.all\n#>     0.294    0.615\n#>     0.281    0.691\n#>     0.242    0.673\n#>     0.340    0.647\n#>     0.310    0.761\n#>     0.416    0.754\n#>     0.270    0.540\n#>     0.417    0.678\n#>     0.151    0.832\n#>     0.566    0.700\n#>     0.507    0.766\n#>     0.353    0.650\n#>     0.462    0.680\n#>     0.308    0.698\n#>     0.392    0.722\n#>     0.592    0.880\n#>     0.380    0.732\n#>     0.653    0.831\n#>     0.506    0.693\n#>     0.436    0.748\n#>     0.492    0.812\n#>     1.000    1.000\nreliability(mycfa)\n#>              DEP\n#> alpha  0.8889281\n#> omega  0.8677875\n#> omega2 0.8677875\n#> omega3 0.8657039\n#> avevar 0.2784132"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"exploratory-factor-analysis","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3 Exploratory factor analysis","text":"now, assumed knew number factors constructs explain data. especially clear CFA define models say many (latent) factors loads (, model fit mean confirmed true model). Still, don’t know? receive couple questionnaire items , whatever reason, want try identify variables/factors explain patterns (co)relations variables. purpose conduct exploratory factor analysis (EFA). following parts use PoliticalDemocracy dataset built-dataset lavaan package. Note renamed last variables.Alright, now plan conduct EFA, always check data. Several points need considered conducting EFA. example, sample size (sometimes debated), missing data, multicollinearity, skewness kurtosis (whether variables resemble univariate/multivariate normal distribution), (univariate/multivariate) outliers, .want quickly inspect last three points: multicollinearity, distribution data, outliers. may help us determine methods consider conducting EFA later .","code":"\nmydata = PoliticalDemocracy\nnames(mydata)[9:ncol(mydata)] = c(\"y9\", \"y10\", \"y11\")"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-check-multicollinearity","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.1 EFA check: multicollinearity","text":"inspect multicollinearity variables? spontaneously think correlation matrix? Well, might miss multicollinearity correlation matrices might miss complex interactions among multiple variables. Correlations “low” necessarily imply absence multicollinearity.extra indicator, can use variance inflation factor (VIF) using vif() function car package. short, VIF indicates whether variance regression coefficient inflated due inter-correlations predictors regression model. VIF around 1 suggests “” multicollinearity, VIF 1-5 suggests “moderate” multicollinearity. However, VIF 5 suggests “high” multicollinearity. example, VIF 5 suggests variance predictor 5 times value without multicollinearity.admit VIF typically used regression analysis rather factor analysis. Still can provide useful use conduct EFA. Spoilers upcoming part linear regression compute VIF, fit linear model one variable dataset regressed remaining ones. regress one variable others, create text shows formula linear regression model. text object restyled read text formula can used lm() function fit simple linear model.Now can put linear model vif() function, simple .","code":"\nmylm = lm(\nas.formula(\n  # A text that will look like y1 ~ y1 + y2 + ... y11. This text will be \"restyled\" as a formula (basicially dropping the \"\" signs)\npaste( colnames(mydata)[1], \"~\",\n  paste(colnames(mydata)[2:(ncol(mydata))], collapse =\"+\"),\n  sep = \"\"\n      )\n      )\n, data = mydata)\nlibrary(car)\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\nvif(mylm)\n#>       y2       y3       y4       y5       y6       y7 \n#> 2.875379 2.005594 3.669274 2.669889 3.070501 2.984355 \n#>       y8       y9      y10      y11 \n#> 3.619843 6.045630 6.930182 3.907849"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-check-univariatemultivariate-normal-distribution","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.2 EFA check: univariate/multivariate normal distribution","text":"Skewness kurtosis affect correlations (especially Pearson correlations), therefore EFA. detect “notable” skewness /kurtosis, might want consider looking e.g., Spearman polychoric correlations instead Pearson ones. Important know, univariate distribution individual variables multivariate distribution data, can play role. Think multivariate distribution multidimensional overview combinations (cross-points values multiple variables). Univariate distributions can plotted (2D) histogram one axis, multivariate distributions multiple axes (one per variable) looks multidimensional. example bivariate normal distribution Wikipedia\nUnivariate distributions can inspected histograms calculation skew kurtosis. Multivariate distributions - whether resemble “normal gaussian distribution” - can checked mardia() function psych package.output shows multivariate kurtosis, skewness, corresponding p values. want follow convention, p values .05 kurtosis /skewness deemed suggest multivariate normal distribution.","code":"\nlibrary(psych)\n#> \n#> Attaching package: 'psych'\n#> The following object is masked from 'package:car':\n#> \n#>     logit\n#> The following object is masked from 'package:MBESS':\n#> \n#>     cor2cov\n#> The following objects are masked from 'package:semTools':\n#> \n#>     reliability, skew\n#> The following object is masked from 'package:lavaan':\n#> \n#>     cor2cov\nmardia(mydata)#> Call: mardia(x = mydata)\n#> \n#> Mardia tests of multivariate skew and kurtosis\n#> Use describe(x) the to get univariate tests\n#> n.obs = 75   num.vars =  11 \n#> b1p =  26.47   skew =  330.9  with probability  <=  0.035\n#>  small sample skew =  346.41  with probability <=  0.0083\n#> b2p =  134.57   kurtosis =  -2.16  with probability <=  0.031"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-check-univariatemultivariate-outliers","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.3 EFA check: univariate/multivariate outliers","text":"Correlations sensitive “notable” data values much “larger” “smaller” value, compared others. Consequently, EFA can affected outliers well. can spot univariate outliers (.e., “extreme values” one variable) using e.g., box plots.multivariate outliers “extremities” combinations two variables. simple example, suppose measure height weight human adult population. people 1.98 meters tall, people weight 53 kilograms. Now imagine person 1.98 meters tall () weights 53 kilograms. considered “outlying” combination.Multivariate outliers can checked Mahalanobis distance using mahalanobis() function. ’ll feed function mean per variable covariance variables. Afterwards, can test whether given distance score “statistically significantly different” compared others. Commonly, chi-square test k-1 degrees freedom (number variables -1) used test Mahalanobis distance, statistically significant differences noted p values equal .001. example put distances dataframe object, add p-values, indicator whether significant (thus “outliers”).","code":"\nmydistances = data.frame(\n  distance = mahalanobis(mydata, center = colMeans(mydata), cov = cov(mydata))\n)\nmydistances$pvalues = pchisq(q = mydistances$distance, df = ncol(mydata)-1, lower.tail = FALSE) \nmydistances = mydistances %>% mutate(outlier = ifelse(  pvalues<=0.001,\"outlier\",\"not outlier\"))"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-how-many-factors","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.4 EFA: how many factors?","text":"Asking big questions: number factors “sufficiently” explain data? Several indications can give use idea including scree plots depicting eigenvalues parallel analysis.","code":""},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-scree-plots-with-eigenvalues","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.4.1 EFA: scree plots with eigenvalues","text":"Scree plots line plots showing connecting eigenvalues. Eigenvalues represent amount variance explained factor. can compute eigenvalues using eigenComputes() function nFactors package. function enter dataset specify use (Pearson) correlation matrix dataset (function automatically compute ) instead covariance matrix.case deem variables sufficiently univariate/multivariate normal distributed, e.g. compute polychoric correlations using polychoric() function psych package, store correlations separate variable, enter variable eigenComputes(). also use e.g., Spearman correlations already built-option within eigenComputes(): eigenComputes(mydata, cor = TRUE, method=“spearman”).Ok, let’s create scree plot. Commonly, number factors retained conventionally deemed number eigenvalues value 1. use ggplot2 package (see also previous part) make plot.","code":"\nlibrary(nFactors)\nmyeigenvalues = eigenComputes(mydata, cor = TRUE)\n  # First I make a dataset containing the eigenvalues and the amount of variables (to create the x- and y-axis)\nlibrary(ggplot2)\n#> \n#> Attaching package: 'ggplot2'\n#> The following objects are masked from 'package:psych':\n#> \n#>     %+%, alpha\n  data.frame( \n  variable = 1:ncol(mydata),\n  eigenvalues = myeigenvalues) %>% # From I create the scree plot\n  ggplot(aes(x=variable, y=eigenvalues)) +\n  geom_point(size = 2, color=\"red\",alpha=0.8) +\n  geom_line(color=\"red\", alpha=0.8) +\n  geom_hline(aes(yintercept=1), linetype=\"dashed\") +\n  theme_minimal()"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-parallel-analysis","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.4.2 EFA: parallel analysis","text":"Parallel analysis simultaneously simulates eigenvalues based observed data (like ) based simulated dataset parallel observed data. determine number factors retain, look number factors simulated data. can use fa.parallel() function psych package run function principal components analysis, common factor analysis, .","code":"\nfa.parallel(mydata, fa = \"pc\", cor = \"cor\", n.iter=500) #> Parallel analysis suggests that the number of factors =  NA  and the number of components =  2\n  # Pearson correlations by default but this can be modified\n  # fa both will output both principal components and principal factor analysis"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-minimum-average-partial-correlations","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.4.3 EFA: Minimum Average Partial (correlations)","text":"last technique want discuss, Minimum Average Partial, used select number factors smallest mean partial correlation. Partial correlations measure relation variables, adjusting influence variables. partial correlations progress 0 optimal number factors. can use VSS()function psych packageYou receive plot plenty output. Velicer MAP achieved minimum (partial correlation) 2 factors. Note also get Bayesian Information Criterium (BIC) well sample adjusted version (SABIC). suggests 2 (Velicer MAP), 6 (BIC SABIC) factors. course, six factors maybe bit much dataset 11 variables.","code":"\nVSS(cor(mydata))\n#> n.obs was not specified and was arbitrarily set to 1000.  This only affects the chi square values.#> \n#> Very Simple Structure\n#> Call: vss(x = x, n = n, rotate = rotate, diagonal = diagonal, fm = fm, \n#>     n.obs = n.obs, plot = plot, title = title, use = use, cor = cor)\n#> VSS complexity 1 achieves a maximimum of 0.89  with  1  factors\n#> VSS complexity 2 achieves a maximimum of 0.97  with  2  factors\n#> \n#> The Velicer MAP achieves a minimum of 0.05  with  2  factors \n#> BIC achieves a minimum of  38.92  with  6  factors\n#> Sample Size adjusted BIC achieves a minimum of  51.63  with  6  factors\n#> \n#> Statistics by number of factors \n#>   vss1 vss2   map dof        chisq\n#> 1 0.89 0.00 0.096  44 3431.3938136\n#> 2 0.81 0.97 0.046  34  831.5327108\n#> 3 0.51 0.89 0.054  25  434.9763651\n#> 4 0.49 0.80 0.076  17  259.3664968\n#> 5 0.47 0.75 0.100  10  135.9475999\n#> 6 0.40 0.71 0.145   4   66.5522974\n#> 7 0.34 0.55 0.216  -1   13.9568471\n#> 8 0.44 0.70 0.345  -5    0.0000057\n#>                                                                                                                                                          prob\n#> 1 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n#> 2 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011\n#> 3 0.000000000000000000000000000000000000000000000000000000000000000000000000000205989781877151495567863925817420067687635309994220733642578125000000000000000\n#> 4 0.000000000000000000000000000000000000000000002537310578025230469682155254318445258832070976495742797851562500000000000000000000000000000000000000000000000\n#> 5 0.000000000000000000000002847326567079168220270740663480069088109303265810012817382812500000000000000000000000000000000000000000000000000000000000000000000\n#> 6 0.000000000000121155814533981051996439082252265961869852617383003234863281250000000000000000000000000000000000000000000000000000000000000000000000000000000\n#> 7                                                                                                                                                          NA\n#> 8                                                                                                                                                          NA\n#>   sqresid  fit RMSEA  BIC SABIC complex        eChisq\n#> 1    4.93 0.89  0.28 3127  3267     1.0 2375.35970442\n#> 2    1.33 0.97  0.15  597   705     1.2  199.31215851\n#> 3    0.83 0.98  0.13  262   342     1.7   55.44789599\n#> 4    0.67 0.99  0.12  142   196     1.8   31.78593735\n#> 5    0.53 0.99  0.11   67    99     2.1   11.62641311\n#> 6    0.46 0.99  0.13   39    52     2.1    3.90783385\n#> 7    0.34 0.99    NA   NA    NA     2.5    0.63731046\n#> 8    0.30 0.99    NA   NA    NA     2.3    0.00000029\n#>        SRMR eCRMS eBIC\n#> 1 0.1469496 0.164 2071\n#> 2 0.0425668 0.054  -36\n#> 3 0.0224515 0.033 -117\n#> 4 0.0169989 0.031  -86\n#> 5 0.0102808 0.024  -57\n#> 6 0.0059603 0.022  -24\n#> 7 0.0024070    NA   NA\n#> 8 0.0000016    NA   NA"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"efa-example","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.3.5 EFA example","text":"Finally, arrive running EFA. can run need consider two additional points (almost ). one hand, need choose factor extraction method use. includes principal components, maximum likelihood (recommend data “suficiently” normal distributed), principal axis factoring (recommend data ), . One another hand, need decide factor rotation methods use enhance factor interpret ability. orthogonal rotation assumes factors correlated. also oblique factor rotation assumes inter-factor correlations. psych packages includes various rotation methods. Popular ones include “oblimin” (oblique factor rotation) “varimax” (orthogonal). Just example go Maximumlikelihood varimax factor rotation, enter 2 factors.Lots output. top see factor loadings (PA1-PA2), communalities (h2), uniqueness values (u2), complexity (com). Scroll , “Proportion var” indicates first factor “explains” 44% total variance, second factor 26%.","code":"\nfa(mydata, nfactors=2,fm=\"ML\", rotate=\"varimax\")\n#> Factor Analysis using method =  ml\n#> Call: fa(r = mydata, nfactors = 2, rotate = \"varimax\", fm = \"ML\")\n#> Standardized loadings (pattern matrix) based upon correlation matrix\n#>      ML2  ML1   h2    u2 com\n#> y1  0.83 0.15 0.71 0.286 1.1\n#> y2  0.77 0.07 0.59 0.407 1.0\n#> y3  0.68 0.17 0.49 0.512 1.1\n#> y4  0.81 0.28 0.74 0.264 1.2\n#> y5  0.71 0.39 0.66 0.342 1.6\n#> y6  0.77 0.19 0.62 0.378 1.1\n#> y7  0.78 0.24 0.67 0.334 1.2\n#> y8  0.79 0.29 0.71 0.292 1.3\n#> y9  0.26 0.89 0.85 0.147 1.2\n#> y10 0.22 0.94 0.94 0.058 1.1\n#> y11 0.17 0.86 0.76 0.236 1.1\n#> \n#>                        ML2  ML1\n#> SS loadings           4.87 2.88\n#> Proportion Var        0.44 0.26\n#> Cumulative Var        0.44 0.70\n#> Proportion Explained  0.63 0.37\n#> Cumulative Proportion 0.63 1.00\n#> \n#> Mean item complexity =  1.2\n#> Test of the hypothesis that 2 factors are sufficient.\n#> \n#> df null model =  55  with the objective function =  9.74 with Chi Square =  677.07\n#> df of  the model are 34  and the objective function was  0.83 \n#> \n#> The root mean square of the residuals (RMSR) is  0.04 \n#> The df corrected root mean square of the residuals is  0.05 \n#> \n#> The harmonic n.obs is  75 with the empirical chi square  15.11  with prob <  1 \n#> The total n.obs was  75  with Likelihood Chi Square =  56.66  with prob <  0.0087 \n#> \n#> Tucker Lewis Index of factoring reliability =  0.94\n#> RMSEA index =  0.093  and the 90 % confidence intervals are  0.048 0.137\n#> BIC =  -90.14\n#> Fit based upon off diagonal values = 0.99\n#> Measures of factor score adequacy             \n#>                                                    ML2  ML1\n#> Correlation of (regression) scores with factors   0.96 0.98\n#> Multiple R square of scores with factors          0.92 0.95\n#> Minimum correlation of possible factor scores     0.84 0.90"},{"path":"reliability-indicators-confirmatory-factor-analysis-and-exploratory-factor-analysis.html","id":"referred-article","chapter":"5 Reliability indicators, Confirmatory Factor Analysis, and Exploratory Factor Analysis","heading":"5.4 Referred article","text":"(McDonald’s omega reliability index)\nFlora, D. B. (2020). coefficient alpha probably wrong, coefficient omega right? tutorial using R obtain better reliability estimates. Advances Methods Practices Psychological Science, 3(4), 484–501. https://doi.org/10.1177/2515245920951747","code":""},{"path":"regression-analysis.html","id":"regression-analysis","chapter":"6 Regression analysis","heading":"6 Regression analysis","text":"part continues data analysis spirit one common analysis models, regression. x relate y (even predict given sufficient methodological rigor)? indication linear relation? relation associated level another variable (moderation)?exists wide variety regression techniques.\n1. Starting brief overview “regression language”, reshape datasets wide long (vice versa), things consider prior fitting regression models\n2. move “classic” (frequentist) linear regression. briefly explore general linear models versus generalized linear models. explore moderation plot simple slopes, heyman-nuyens\n3. discuss regression models: repeated measures, multivariate regression, mixed-effects regression models.\n4. won’t ignore model assumptions provide ways inspect classic linear regression mixed-effects regression models\n5. end brief discussion effect sizes","code":""},{"path":"regression-analysis.html","id":"regression-models-and-things-to-consider","chapter":"6 Regression analysis","heading":"6.1 Regression models and things to consider","text":"","code":""},{"path":"regression-analysis.html","id":"the-language-of-regression-models","chapter":"6 Regression analysis","heading":"6.1.1 The language of regression models","text":"regression models regress outcome outcomes (dependent) variable(s) one predictors (independent variables). Similar dplyr ggplot2, regression preferred notations “symbol” use. brief overview:\n1. Y ~ variable1 + variable2 output “main effect”\n2. Y ~ variable1 : variable2 output interaction/moderation estimate \n3. Y ~ variable1 x variable2 output main effects interactions","code":""},{"path":"regression-analysis.html","id":"long-to-wide-format-and-vice-versa","chapter":"6 Regression analysis","heading":"6.1.2 Long to wide format and vice versa","text":"Generally can distinguish two types data formats: wide data format every repeated measure put separate column long format repeated measures put column. Knowing transform data wide long data formats crucial, different regression models require different data structures. example, regression multiple outcomes prefers data wide format, whereas mixed-effects models ask long format.variety functions can transform long formats wide formats, back. Personally, prefer using melt() dcast() functions reshape2 package. demonstration , made dataset wide data formatNow reshape data wide long ages “glued” individual (4 ages per individual). melt() function specify variable identifies individuals using “id.var” (ID).’m aware reshape2 package quite old now, also provide alternative modern tidyr package. mimic melt() function, tidyr pivot_longer() function.Now go back long format wide format.prefer tidyr, can instead use pivot_wider() function.fairly simple example age main variable. multiple variables? Take example next dataset long format.transform dataset wide format combining variable wave condition. combining multiple variable wide format, use raw score anymore (otherwise stays long), function need applied transform score variable. can simply aggregate score variable per wave condition.Unfortunately, can’t go back long format know original -aggregated scores (various combinations can lead average score).","code":"\n\nset.seed(123)\nmydata = data.frame( \n ID = factor(1:10),\n age_6_years = runif(10,100,120),\n age_8_years =  runif(10,120,135),\n age_10_years = runif(10,135,150),\n age_12_years = runif(10,150,180)  \n  )\nlibrary(reshape2)\nmydata_long = melt(mydata, id.var =\"ID\", variable_name =\"age\")\nhead(mydata_long)\n#>   ID    variable    value\n#> 1  1 age_6_years 105.7516\n#> 2  2 age_6_years 115.7661\n#> 3  3 age_6_years 108.1795\n#> 4  4 age_6_years 117.6603\n#> 5  5 age_6_years 118.8093\n#> 6  6 age_6_years 100.9111\nlibrary(tidyr)\n#> \n#> Attaching package: 'tidyr'\n#> The following object is masked from 'package:reshape2':\n#> \n#>     smiths\nmydata_long =pivot_longer(mydata, cols = -ID, names_to = \"age\", values_to = \"value\")\nhead(mydata_long)\n#> # A tibble: 6 × 3\n#>   ID    age          value\n#>   <fct> <chr>        <dbl>\n#> 1 1     age_6_years   106.\n#> 2 1     age_8_years   134.\n#> 3 1     age_10_years  148.\n#> 4 1     age_12_years  179.\n#> 5 2     age_6_years   116.\n#> 6 2     age_8_years   127.\ndata_wide = dcast(data = mydata_long , ID ~ age, value.var = \"value\")\nhead(data_wide)\n#>   ID age_10_years age_12_years age_6_years age_8_years\n#> 1  1     148.3431     178.8907    105.7516    134.3525\n#> 2  2     145.3921     177.0690    115.7661    126.8000\n#> 3  3     144.6076     170.7212    108.1795    130.1636\n#> 4  4     149.9140     173.8640    117.6603    128.5895\n#> 5  5     144.8356     150.7384    118.8093    121.5439\n#> 6  6     145.6280     164.3339    100.9111    133.4974\nmydata_wide = pivot_wider(mydata_long, names_from = \"age\", values_from = \"value\")\nhead(data_wide)\n#>   ID age_10_years age_12_years age_6_years age_8_years\n#> 1  1     148.3431     178.8907    105.7516    134.3525\n#> 2  2     145.3921     177.0690    115.7661    126.8000\n#> 3  3     144.6076     170.7212    108.1795    130.1636\n#> 4  4     149.9140     173.8640    117.6603    128.5895\n#> 5  5     144.8356     150.7384    118.8093    121.5439\n#> 6  6     145.6280     164.3339    100.9111    133.4974\nset.seed(123)\nmydata = data.frame(\n  subject = factor( rep(  rep(c(1:100), times = 2), times = 3 ) ),\n  condition =  factor( rep(  rep(c(1:2), each = 100   ), times = 3 )  ),\n  wave = factor(  rep(c(1:3), each = 200)  ),\n  score = runif(600, 1, 100)\n)\nhead(mydata)\n#>   subject condition wave     score\n#> 1       1         1    1 29.470174\n#> 2       2         1    1 79.042208\n#> 3       3         1    1 41.488715\n#> 4       4         1    1 88.418723\n#> 5       5         1    1 94.106261\n#> 6       6         1    1  5.510093\nmydata_wide = dcast(mydata, subject ~ wave + condition, value.var = \"score\", fun.aggregate =  mean)\nnames(mydata_wide)[2:ncol(mydata_wide)] = c(\"Wave1_Condition1\", \"Wave2_Condition1\", \"Wave3_Condition1\", \"Wave1_Condition2\", \"Wave2_Condition2\", \"Wave3_Condition2\")\nhead(mydata_wide)\n#>   subject Wave1_Condition1 Wave2_Condition1\n#> 1       1        29.470174         60.39891\n#> 2       2        79.042208         33.94953\n#> 3       3        41.488715         49.37269\n#> 4       4        88.418723         95.49291\n#> 5       5        94.106261         48.80734\n#> 6       6         5.510093         89.14467\n#>   Wave3_Condition1 Wave1_Condition2 Wave2_Condition2\n#> 1         24.63388        78.672951         98.61938\n#> 2         96.27353         1.933561         14.56968\n#> 3         60.53521        78.127522         90.62565\n#> 4         51.98794        73.209675         58.05388\n#> 5         40.85476        63.383053         40.14944\n#> 6         88.14441        48.610172         45.53045\n#>   Wave3_Condition2\n#> 1        36.007002\n#> 2        37.277703\n#> 3        29.422913\n#> 4         8.917318\n#> 5        37.179973\n#> 6        18.623368"},{"path":"regression-analysis.html","id":"simple-linear-regression-using-a-general-linear-model","chapter":"6 Regression analysis","heading":"6.2 (Simple) linear regression using a general linear model","text":"start demonstration fitting linear lines lm() function compute “relatively simple” general linear regression model. However, quickly note classic regression may show age recommended modern alternatives available problems specificity problem (repeated measures context, see next part MANOVA) arise. data time online free--use dataset quality red wine based physicochemical testsNow regress X Y, always check data (e.g., outliers, “strange occurrences”, unwanted duplicates, etc.), run descriptive statistics, check correlations, visualize distribution relations/patterns variables. Let’s assume want compute main effect alcohol content potential Hydrogen (pH) scale.Inspecting summary output, never hurts glance residuals can first quick look residuals distributed. note, general linear models assume normal distribution residuals model (see upcoming parts), variables . said, excuse check distribution variables**. Moving , coefficients statistically significant (p value) positive main effect.can just ask directly coefficients using coef(mylm) confidence interval using confint(mylm). Next coefficients, can ask predicted values (make predicted linear line) using predict(mylm), confidence interval around predicted values using predict(mylm,interval=“confidence”), residuals using residuals(mylm).Note regression coefficients standardized. want standardized versions (ease interpretation easily allow comparison) can either standardize predictor outcome can use lm.beta() function QuantPsyc package standardize_parameters() function effectsize package.case binary predictors, can standardize outcome leading partially standardized coefficients.","code":"\nmydata = read.csv(\"data_files/wineQualityReds.csv\")   \nhead(mydata)\n#>   X fixed.acidity volatile.acidity citric.acid\n#> 1 1           7.4             0.70        0.00\n#> 2 2           7.8             0.88        0.00\n#> 3 3           7.8             0.76        0.04\n#> 4 4          11.2             0.28        0.56\n#> 5 5           7.4             0.70        0.00\n#> 6 6           7.4             0.66        0.00\n#>   residual.sugar chlorides free.sulfur.dioxide\n#> 1            1.9     0.076                  11\n#> 2            2.6     0.098                  25\n#> 3            2.3     0.092                  15\n#> 4            1.9     0.075                  17\n#> 5            1.9     0.076                  11\n#> 6            1.8     0.075                  13\n#>   total.sulfur.dioxide density   pH sulphates alcohol\n#> 1                   34  0.9978 3.51      0.56     9.4\n#> 2                   67  0.9968 3.20      0.68     9.8\n#> 3                   54  0.9970 3.26      0.65     9.8\n#> 4                   60  0.9980 3.16      0.58     9.8\n#> 5                   34  0.9978 3.51      0.56     9.4\n#> 6                   40  0.9978 3.51      0.56     9.4\n#>   quality\n#> 1       5\n#> 2       5\n#> 3       5\n#> 4       6\n#> 5       5\n#> 6       5\nmylm = lm(pH~ alcohol, data = mydata)\nsummary(mylm)\n#> \n#> Call:\n#> lm(formula = pH ~ alcohol, data = mydata)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.54064 -0.10223 -0.00064  0.09340  0.63701 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3.000606   0.037171  80.725   <2e-16 ***\n#> alcohol     0.029791   0.003548   8.397   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1511 on 1597 degrees of freedom\n#> Multiple R-squared:  0.04228,    Adjusted R-squared:  0.04169 \n#> F-statistic: 70.51 on 1 and 1597 DF,  p-value: < 2.2e-16\n# Not using the lm.beta() function. Here I standardized outcome and predictor within the lm() but feel free to compute and add standardized variables to your dataset and use these in the lm() function\ncoef(\n  lm( scale(mydata$pH) ~ scale(mydata$alcohol), data = mydata)\n    )[2]\n#> scale(mydata$alcohol) \n#>             0.2056325\n\n# Using the lm.beta() function from QuantPsyc package\nlibrary(QuantPsyc)\n#> Warning: package 'QuantPsyc' was built under R version\n#> 4.3.3\n#> Loading required package: boot\n#> Loading required package: dplyr\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n#> Loading required package: purrr\n#> Loading required package: MASS\n#> \n#> Attaching package: 'MASS'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     select\n#> \n#> Attaching package: 'QuantPsyc'\n#> The following object is masked from 'package:base':\n#> \n#>     norm\nlm.beta( lm(pH~ alcohol, data = mydata) )\n#>   alcohol \n#> 0.2056325\n\n# Or using the standardize_parameters() from the effectsize package\nlibrary(effectsize)\nstandardize_parameters(mylm)\n#> # Standardization method: refit\n#> \n#> Parameter   | Std. Coef. |        95% CI\n#> ----------------------------------------\n#> (Intercept) |   1.32e-16 | [-0.05, 0.05]\n#> alcohol     |       0.21 | [ 0.16, 0.25]"},{"path":"regression-analysis.html","id":"interaction-terms-johnson-neyman-intervals-and-simple-slopes","chapter":"6 Regression analysis","heading":"6.2.1 Interaction terms, Johnson-Neyman intervals, and simple slopes","text":"","code":""},{"path":"regression-analysis.html","id":"two-way-interaction-with-continuous-variable","chapter":"6 Regression analysis","heading":"6.2.1.1 two-way interaction with continuous variable","text":"suspect (linear) relation pH alcohol content changes level chlorides (continuous variable). words, expect moderation “effect” chlorides. add main effect chlorides interaction term alcohol chlorides model.example interaction term negative. mean? Well, helps visualize interaction effects. plot anything want briefly stand still moment. Procedures visualize interactions potentially misleading careful. Simple slopes often used plotting interaction “effects”. Simple slopes simply represent relation predictor’s effect outcome different levels moderator.important thing slopes need select values moderator. specifically, link outcome predictor (.e., slope) plotted values. Often people select three values represent “low” levels moderator (often one standard deviation mean), “moderate” levels (often mean), “high” levels (often one standard deviation mean). Question , values truly represent “low”, “moderate”, “high”? likely case e.g. distribution moderation variable “notably” skewed.case interaction two continuous variables, recommend plot Johnson-Neyman intervals using johnson_neyman() function interactions package. function computes plots Johnson-Neyman intervals along series values moderator. one glance, can spot values moderator, main effect predictor outcome statistically significant based p value. Even better humble opinion, size relation point displayed full view.dislike plot, can also make version. Luckily, elements need plot provided package . Recall “store object click” strategy previous part? store Johnson Neyman plot variable, click variable (Environment), inspect every element, extract information need.Now can load ggplot2 package create figure . , approximately recreate original figure grayscale.","code":"\nmylm = lm(pH ~ alcohol * chlorides, data = mydata)\nsummary(mylm)\n#> \n#> Call:\n#> lm(formula = pH ~ alcohol * chlorides, data = mydata)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.52078 -0.09344 -0.00439  0.09103  0.59329 \n#> \n#> Coefficients:\n#>                    Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)        2.965316   0.081419  36.420  < 2e-16 ***\n#> alcohol            0.040910   0.008201   4.989 6.74e-07 ***\n#> chlorides          1.607694   0.948468   1.695   0.0903 .  \n#> alcohol:chlorides -0.245655   0.098170  -2.502   0.0124 *  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1469 on 1595 degrees of freedom\n#> Multiple R-squared:  0.09651,    Adjusted R-squared:  0.09481 \n#> F-statistic: 56.79 on 3 and 1595 DF,  p-value: < 2.2e-16\nlibrary(interactions)\n#> Warning: package 'interactions' was built under R version\n#> 4.3.3\njohnson_neyman(model=mylm, pred=alcohol, modx=chlorides)\n#> JOHNSON-NEYMAN INTERVAL\n#> \n#> When chlorides is OUTSIDE the interval [0.12, 0.50], the\n#> slope of alcohol is p < .05.\n#> \n#> Note: The range of observed values of chlorides is\n#> [0.01, 0.61]\nmyplot = johnson_neyman(model=mylm, pred=alcohol, modx=chlorides)\n\nmyjohnson_neyman = data.frame(\n  ci_lower = myplot[[\"cbands\"]][[\"Lower\"]], # Lower bound of the 95%\n  ci_upper = myplot[[\"cbands\"]][[\"Upper\"]], # Upper bound\n  slope = myplot[[\"cbands\"]][[\"Slope of alcohol\"]], # the slope\n  significance = myplot[[\"cbands\"]][[\"Significance\"]], # indicates when the slope is significant or not\n  bound_start = min(mydata$chlorides), # To make the range of observed data for the chlorides variable, the lowest value\n  bound_end = max(mydata$chlorides), # The highest value\n  chlorides_x_axis = myplot[[\"cbands\"]][[\"chlorides\"]] # Needed for the x-axis\n)\nlibrary(ggplot2)\n\nmyjohnson_neyman  %>% # Only the full range of \"chlorides\"\n  ggplot(aes(x=chlorides_x_axis)) +\n  scale_fill_manual(values=c(\"grey50\",\"grey30\"), labels=c(\"p < .05\",\"n.s.\"), name=\"\" ) + # I had to set the labels since it otherwise switches them up. Also I omitted the legend title\n  geom_ribbon( aes(ymin = ci_lower, ymax = ci_upper, fill = significance), alpha = 0.40 ) +\n  geom_line( aes(y = ci_upper), size=1) + # I add this line otherwise the contours of the \"ribbon\" will be transparant (since apha = 0.40)\n  geom_line( aes(y = ci_lower),  size=1) + # See above\n  geom_hline(aes(yintercept=0), linetype = \"dashed\") + # Horizontal line at zero (helps to look when the confidence interval crosses zero)\n  geom_segment(aes(x = bound_start , xend = bound_end), y = 0, yend=0, size=2 ) + # To create the thick line depicting the range of chlorides\n  scale_color_manual(values=\"black\", labels=\"Range of Chlorides\", name=\"\" ) + # for the additional legend \n  geom_line(aes(y = slope), size = 1) + # The slope line \n  xlab(\"Chlorides\") + ylab(\"Slope of alcohol\") + ggtitle(\"Johnson-Neyman plot\") +\n  theme_classic() \n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2\n#> 3.4.0.\n#> ℹ Please use `linewidth` instead.\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_lifecycle_warnings()` to see where\n#> this warning was generated."},{"path":"regression-analysis.html","id":"two-way-interaction-with-a-continuous-and-factor-variable","chapter":"6 Regression analysis","heading":"6.2.1.2 two-way interaction with a continuous and factor variable","text":"Forget chlorides variable second. Now want see whether link pH alcohol content moderated quality (categorical/factor variable). visualize interaction, still use Johnson-Neyman technique note statistical significance category. However, since values categorical/factor moderator determined, can plot simple slopes.simple slopes use effect() function [effects package(https://cran.r-project.org/web/packages/effects/index.html)**. Let’s start fitting regression model. simplicity, include two values “quality”. addition, transform variable 0 1 potentially ease interpretability.effect, add interaction part (can copy-paste), define slope drawn. Specifically, cover full range continuous predictor, use minimum maximum value variable. confidence interval slope per category. slope straight lineAlways handy indication distribution variables show data points lie. show data points outcome (pH) distribution (separate histograms put simple slopes).","code":"\nmydata_simpleslopes = mydata %>% filter(quality %in% c(4,8)) %>%\n  mutate(quality = factor(recode(quality,'4' = '0' , '8' = '1')  )  ) \n\nmylm = lm(pH ~ alcohol * quality, data = mydata_simpleslopes)\nsummary(mylm)\n#> \n#> Call:\n#> lm(formula = pH ~ alcohol * quality, data = mydata_simpleslopes)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.55389 -0.07285  0.00586  0.09034  0.34470 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)       2.34178    0.23601   9.922 8.78e-15 ***\n#> alcohol           0.10129    0.02290   4.423 3.66e-05 ***\n#> quality1         -0.45912    0.44029  -1.043    0.301    \n#> alcohol:quality1  0.01319    0.03821   0.345    0.731    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1544 on 67 degrees of freedom\n#> Multiple R-squared:  0.3793, Adjusted R-squared:  0.3515 \n#> F-statistic: 13.65 on 3 and 67 DF,  p-value: 4.796e-07\nlibrary(effects)\n#> Loading required package: carData\n#> lattice theme set by effectsTheme()\n#> See ?effectsTheme for details.\ndata_slope = as.data.frame(\n  effect(mod=mylm, term = \"alcohol * quality\",\n                  xlevels=list(alcohol = c(min(mydata_simpleslopes$alcohol),\n                                             max(mydata_simpleslopes$alcohol)),se=TRUE, confidence.level=.95) )\n)\n\n# Create the plot\nlibrary(ggplot2)\ndata_slope  %>% ggplot(aes(x = alcohol, y = fit, color = quality)) +\n  geom_ribbon(aes(ymin = lower, ymax = upper, fill = quality), alpha = 0.2) +\n  geom_line() \nlibrary(ggplot2)\nmy_simple_slopes = data_slope  %>% ggplot(aes(x = alcohol, y = fit, color = quality)) +\n  geom_point(data = mydata_simpleslopes, aes(y = pH), alpha = 0.5  ) +\n  geom_ribbon(aes(ymin = lower, ymax = upper, fill = quality), alpha = 0.2) +\n  geom_line() + facet_wrap(~ quality) +\n  ylab(\"Slope\") + xlab(\"Alcohol content\") +\n  theme_classic() +\n  theme(\n   legend.position = \"None\" \n  )\n\nmy_histograms = mydata_simpleslopes %>% ggplot(aes(x = alcohol, fill = quality)) + \n  geom_histogram(color=\"black\", alpha = 0.75, bins = 18) + \n  facet_wrap(~quality) +\n  theme_minimal() \n  \nlibrary(cowplot)\nplot_grid(my_histograms, my_simple_slopes, ncol=1, nrow=2, align=\"v\", rel_heights = c(0.25, 1))\n#> Warning: Graphs cannot be vertically aligned unless the\n#> axis parameter is set. Placing graphs unaligned."},{"path":"regression-analysis.html","id":"simple-generalized-linear-models","chapter":"6 Regression analysis","heading":"6.3 Simple generalIZED linear models","text":"may exist numerous instances outcomes (residuals models) “notably” deviating normal distribution. Think binary outcomes, counts (Poisson), categories, . Generalized linear regression models allow modify distribution model’s residuals handled. allows (binary logistic regression) (logistic regression). models can soften assumption normal distribution model’s residual terms, can also considered case model assumption violations.Within R environment, generalized linear models resemble general ones introduce (least) two additional parameters: family link. link can used , wished , transform model predicted outcome (e.g., logarithms). default, link “identity” (transformation). family determines distribution residuals handled. default family gaussian (normal distribution just like general linear models) can modified poison, binomial, gamma, . Several examples .Starting example poisson linear regression.Next, case binary outcome.final example, also fit general model using glm() function use gaussian link.","code":"\n  set.seed(123)\n  poisson_data = data.frame(\n    counts = c( round(runif(30,15,35),0), round(runif(30,15,28),0), round(runif(30,1,18),0) ),\n    altitude = 1:90\n    )\n  \n  # Note family poisson will by default take the log from the outcome\n  poisson_fit = glm(counts ~ altitude, data = poisson_data, family = poisson(link =\"log\"))\n  summary(poisson_fit)\n#> \n#> Call:\n#> glm(formula = counts ~ altitude, family = poisson(link = \"log\"), \n#>     data = poisson_data)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  3.5020143  0.0427726   81.88   <2e-16 ***\n#> altitude    -0.0136118  0.0009657  -14.10   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for poisson family taken to be 1)\n#> \n#>     Null deviance: 382.59  on 89  degrees of freedom\n#> Residual deviance: 176.47  on 88  degrees of freedom\n#> AIC: 598.46\n#> \n#> Number of Fisher Scoring iterations: 4\n  \n  poisson_data$counts_log = log(poisson_data$counts)\n  \n  # link identity will apply no transformation (but since we took the log ourselves...)\n  poisson_fit = glm(counts_log ~ altitude, data = poisson_data, family = poisson(link =\"identity\"))\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.044522\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.433987\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.135494\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.496508\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.526361\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.772589\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.258097\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.496508\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.258097\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.178054\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.526361\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.178054\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.367296\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.258097\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.496508\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.995732\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.772589\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.091042\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.526361\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.496508\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.367296\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.332205\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.555348\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.332205\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.367296\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.258097\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.295837\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.044522\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.332205\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.295837\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.178054\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.218876\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.708050\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.044522\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.218876\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.944439\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.995732\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.995732\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.995732\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.044522\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.258097\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.772589\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.044522\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.218876\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.091042\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.833213\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.218876\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 3.295837\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.995732\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.484907\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.098612\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.079442\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.791759\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.708050\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.197225\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.708050\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.708050\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.708050\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.079442\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.639057\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.484907\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.564949\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.197225\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.609438\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.945910\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.397895\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.945910\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.098612\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.609438\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.484907\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.079442\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.639057\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.098612\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.079442\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.890372\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.772589\n\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 2.772589\n#> Warning in dpois(y, mu, log = TRUE): non-integer x =\n#> 1.386294\n  summary(poisson_fit)\n#> \n#> Call:\n#> glm(formula = counts_log ~ altitude, family = poisson(link = \"identity\"), \n#>     data = poisson_data)\n#> \n#> Coefficients:\n#>              Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  3.598829   0.376842   9.550  < 2e-16 ***\n#> altitude    -0.017720   0.006705  -2.643  0.00822 ** \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for poisson family taken to be 1)\n#> \n#>     Null deviance: 17.422  on 89  degrees of freedom\n#> Residual deviance: 10.737  on 88  degrees of freedom\n#> AIC: Inf\n#> \n#> Number of Fisher Scoring iterations: 5\n  \n  # Note, that the regression coefficients will be on the log scale, so you could compute the exponent to ease interpretability \n  exp(coef(poisson_fit))\n#> (Intercept)    altitude \n#>  36.5553993   0.9824361\n# Data used \nset.seed(123)\nbinary_data = data.frame(\n  on_or_off = c( round(runif(100,0,1),0) ),\n  distance = 1:100\n)\n\n# Note family binomial will by default take the logit (log of the odds ratio) from the outcome\nbinary_fit = glm(on_or_off ~ distance, data = binary_data, family = binomial(link =\"logit\"))\nsummary(binary_fit)\n#> \n#> Call:\n#> glm(formula = on_or_off ~ distance, family = binomial(link = \"logit\"), \n#>     data = binary_data)\n#> \n#> Coefficients:\n#>              Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)  0.343678   0.406669   0.845    0.398\n#> distance    -0.009227   0.007052  -1.308    0.191\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 138.27  on 99  degrees of freedom\n#> Residual deviance: 136.53  on 98  degrees of freedom\n#> AIC: 140.53\n#> \n#> Number of Fisher Scoring iterations: 4\nmydata = read.csv(\"data_files/wineQualityReds.csv\")   \n\nsummary(\n  lm( pH ~ alcohol    , data = mydata        )\n)\n#> \n#> Call:\n#> lm(formula = pH ~ alcohol, data = mydata)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.54064 -0.10223 -0.00064  0.09340  0.63701 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3.000606   0.037171  80.725   <2e-16 ***\n#> alcohol     0.029791   0.003548   8.397   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1511 on 1597 degrees of freedom\n#> Multiple R-squared:  0.04228,    Adjusted R-squared:  0.04169 \n#> F-statistic: 70.51 on 1 and 1597 DF,  p-value: < 2.2e-16\n\nsummary(\n    glm( pH ~ alcohol, data = mydata, family = gaussian(link =\"identity\"))\n)\n#> \n#> Call:\n#> glm(formula = pH ~ alcohol, family = gaussian(link = \"identity\"), \n#>     data = mydata)\n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 3.000606   0.037171  80.725   <2e-16 ***\n#> alcohol     0.029791   0.003548   8.397   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for gaussian family taken to be 0.02284161)\n#> \n#>     Null deviance: 38.089  on 1598  degrees of freedom\n#> Residual deviance: 36.478  on 1597  degrees of freedom\n#> AIC: -1501.1\n#> \n#> Number of Fisher Scoring iterations: 2"},{"path":"regression-analysis.html","id":"mixed-effects-model","chapter":"6 Regression analysis","heading":"6.4 Mixed effects model","text":"","code":""},{"path":"regression-analysis.html","id":"fixed-and-random-effects","chapter":"6 Regression analysis","heading":"6.4.1 Fixed and random effects","text":"Looks like first indication higher levels measurement across time. realize thirty measures per subject. wonder… every subject also show pattern? average across subject positive slope fits ? draw regression slope relation per subject.\n\nsubjects show increase, others decrease little change. words, average across subjects, may expect positive linear relation. Nevertheless, variety, variance relation across subjects.Just now winked two concepts, fixed random effects can modelled mixed-effects regression models.Fixed effects can considered typical “dependent variable gets predicted independent variable” part. Random effects refer variation regression parameters across subjects “clusters. example, one can attempt study influence medicine reaction time. , ”acknowledge” participants naturally faster react “starting point reaction time” lower (thus ’re faster) irrespective medicine intake. words, can acknowledge may variance natural/base/trait state outcome per person, depicted random variance intercept. Moving , ’re already familiar occurrence random variance slope. Regression slopes depicting given relation may differ per person. scratch surface review , note various points can considered kind analyses.generate dataset 40 repetitions measures across 100 participants (“cluster”)., let’s quickly check outcome changes across time (indicated “simple” regression slopes geom_smooth function).Visually, may expect general (fixed) relation. However, likely “notable” bit variance slope per participant, least based vision. Looking start point (measurement 1), participants lower higher outcome compared one another. Based vision, might expect participants’ “baseline/natural/trait state” outcome may different. technical terms might expect variance intercepts per schools.Alright, let’s fit mixed-effect model. several packages R allow fit mixed-effects models. use lmer() function lmerTest package. Let’s start transformation everyday general linear regression general linear mixed regression, introduction random intercept.note, used Restricted likelihood (REML) recommended estimating random effects variances interested comparing models different fixed effects. interested compare fixed effects, consider Maximum Likelihood instead (REML = FALSE).Glancing summary, might impression looks similar output classic linear models. ’s new separation random fixed effects. Notice random effects part consists variance appropriate call random effect variance. first parameter random intercept variance (variations intercept participants compared). second, residual random variance, variance . Essentially,variance left referred within-cluster variance (within-participant variance). sum variances forms total variance.Similar summary output “classic” linear regression can call regression coefficients using coef(). However, note now get coefficients per cluster-unit (participants ). look coefficients first seven participants.intercept different per participant, “measurement” per participant, expected since modeled fixed random effect intercept, whereas estimated “measurement” sole fixed variable without random part. show fixed effect (fixed slope) can call fixef(), can call th random effect (variation per cluster-unit) using ranef(). Good know, coefficient random intercept per participant sum fixed effect intercept (shared across participants) random effect intercept (unique per participant). look participant one.","code":"\nset.seed(123)  \nn_participants = 100  \nn_repetitions = 40    \nicc_target = 0.45     \n\n# Generate participant IDs\nparticipant_id = rep(1:n_participants, each = n_repetitions)\n\n# Variance components (solving for within-person variance)\nbetween_var = 1  # Arbitrary choice\nwithin_var = between_var * (1 - icc_target) / icc_target  # Ensures ICC = 0.45\n\n# Generate random intercepts (participant-level effects)\nrandom_intercepts = rnorm(n_participants, mean = 50, sd = sqrt(between_var))\nrandom_intercepts_expanded = rep(random_intercepts, each = n_repetitions)\n\n# Generate within-person residuals\nresiduals = rnorm(n_participants * n_repetitions, mean = 0, sd = sqrt(within_var))\n\n# Compute the outcome variable\noutcome = random_intercepts_expanded + residuals\n\n# Create the data frame\nmydata = data.frame(\n  participant_id = factor(participant_id),\n  measurement = rep(1:n_repetitions, times = n_participants),\n  outcome = outcome,\n  predictor = runif(4000, 10,100)\n)\nlibrary(plotly)\n#> \n#> Attaching package: 'plotly'\n#> The following object is masked from 'package:ggplot2':\n#> \n#>     last_plot\n#> The following object is masked from 'package:MASS':\n#> \n#>     select\n#> The following object is masked from 'package:stats':\n#> \n#>     filter\n#> The following object is masked from 'package:graphics':\n#> \n#>     layout\nggplotly(\nmydata %>% ggplot(aes(y = outcome, x = measurement, color=participant_id, group=participant_id))  +\n  geom_smooth(method=\"lm\", se=FALSE) +\n  geom_smooth(aes(group=0),method=\"lm\",se=FALSE, linetype=\"dashed\",color=\"black\") +\n  theme_classic()\n)\n#> `geom_smooth()` using formula = 'y ~ x'\n#> `geom_smooth()` using formula = 'y ~ x'\nlibrary(lmerTest)\n#> Loading required package: lme4\n#> Loading required package: Matrix\n#> \n#> Attaching package: 'Matrix'\n#> The following objects are masked from 'package:tidyr':\n#> \n#>     expand, pack, unpack\n#> \n#> Attaching package: 'lmerTest'\n#> The following object is masked from 'package:lme4':\n#> \n#>     lmer\n#> The following object is masked from 'package:stats':\n#> \n#>     step\nmyfit = lmer(outcome ~ measurement + (1|participant_id), REML = TRUE, data = mydata)\n# Note. REML = Restricted likelihood. If \"TRUE\" then MaximumLikelihood would be used\nsummary(myfit)\n#> Linear mixed model fit by REML. t-tests use\n#>   Satterthwaite's method [lmerModLmerTest]\n#> Formula: outcome ~ measurement + (1 | participant_id)\n#>    Data: mydata\n#> \n#> REML criterion at convergence: 12478.7\n#> \n#> Scaled residuals: \n#>     Min      1Q  Median      3Q     Max \n#> -3.1934 -0.6513 -0.0151  0.6813  3.5145 \n#> \n#> Random effects:\n#>  Groups         Name        Variance Std.Dev.\n#>  participant_id (Intercept) 0.8271   0.9094  \n#>  Residual                   1.2157   1.1026  \n#> Number of obs: 4000, groups:  participant_id, 100\n#> \n#> Fixed effects:\n#>              Estimate Std. Error        df t value Pr(>|t|)\n#> (Intercept) 5.007e+01  9.764e-02 1.223e+02 512.800   <2e-16\n#> measurement 1.210e-03  1.510e-03 3.899e+03   0.801    0.423\n#>                \n#> (Intercept) ***\n#> measurement    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Correlation of Fixed Effects:\n#>             (Intr)\n#> measurement -0.317\n  coef(myfit)[[\"participant_id\"]][1:7,]\n#>   (Intercept) measurement\n#> 1    49.22585 0.001209674\n#> 2    49.75307 0.001209674\n#> 3    51.44249 0.001209674\n#> 4    50.01370 0.001209674\n#> 5    50.42549 0.001209674\n#> 6    51.63878 0.001209674\n#> 7    50.39875 0.001209674\ncoef(myfit)[[\"participant_id\"]][1,1]\n#> [1] 49.22585\n  # -> 49.22585\n\nfixef(myfit)[1] + ranef(myfit)[[\"participant_id\"]][1,]\n#> (Intercept) \n#>    49.22585\n  # -> 49.22585 "},{"path":"regression-analysis.html","id":"intraclass-correlationvariance-partition","chapter":"6 Regression analysis","heading":"6.4.2 Intraclass correlation/variance partition","text":"Now familiarized summary output. One parameter compute context repeated measures intraclasscorrelation (ICC) (sometimes named variance partition coefficient) shows proportion -cluster (-participant) variance compared total variance.compute ICC, fit mixed-effects model outcome variable regressed fixed random intercept (null model). case:obtain ICC use icc() function performance package. function output adjusted ICC unadjusted ICC. Without fancy packages also compute easily . summary output, take -cluster variance (random intercept variance; 0.8271) divide sum random variances (0.8271 + 1.2156). outcome 0.4049053.","code":"\nlmer(outcome ~ 1 + (1|participant_id), REML = TRUE, data = mydata)\n#> Linear mixed model fit by REML ['lmerModLmerTest']\n#> Formula: outcome ~ 1 + (1 | participant_id)\n#>    Data: mydata\n#> REML criterion at convergence: 12468.22\n#> Random effects:\n#>  Groups         Name        Std.Dev.\n#>  participant_id (Intercept) 0.9094  \n#>  Residual                   1.1025  \n#> Number of obs: 4000, groups:  participant_id, 100\n#> Fixed Effects:\n#> (Intercept)  \n#>       50.09"},{"path":"regression-analysis.html","id":"random-slopes","chapter":"6 Regression analysis","heading":"6.4.3 Random slopes","text":"Let’s add “predictor” variable fixed random effect. now introduce random intercept variance random slope variance model. Let’s look summary outputIn section “Random effects” now get correlation .13. correlation random intercepts random slopes, indicating participants higher intercepts (“baselines”) tend (slightly) higher slopes. Moving , also see correlations fixed effects. fixed effect “measurement” “predictor” (“average across participants” slopes speak) negative correlation fixed intercept (“average across participants”). Participants, general, lower intercept (“baseline” levels outcome) may show higher levels “measurement” “predictor”. Furthermore, fixed-effects “measurement” “predictor” near-zero, can good thing high correlation may indicate multicollinearity.","code":"\nmyfit = lmer(outcome ~  measurement + predictor + (1 + predictor |participant_id), REML = TRUE, data = mydata)\n#> Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl =\n#> control$checkConv, : Model failed to converge with\n#> max|grad| = 1.81782 (tol = 0.002, component 1)\n#> Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n#>  - Rescale variables?\nsummary(myfit)\n#> Linear mixed model fit by REML. t-tests use\n#>   Satterthwaite's method [lmerModLmerTest]\n#> Formula: \n#> outcome ~ measurement + predictor + (1 + predictor | participant_id)\n#>    Data: mydata\n#> \n#> REML criterion at convergence: 12488.1\n#> \n#> Scaled residuals: \n#>     Min      1Q  Median      3Q     Max \n#> -3.1858 -0.6519 -0.0073  0.6809  3.5471 \n#> \n#> Random effects:\n#>  Groups         Name        Variance  Std.Dev. Corr\n#>  participant_id (Intercept) 7.264e-01 0.852283     \n#>                 predictor   1.012e-05 0.003182 0.13\n#>  Residual                   1.211e+00 1.100293     \n#> Number of obs: 4000, groups:  participant_id, 100\n#> \n#> Fixed effects:\n#>               Estimate Std. Error         df t value\n#> (Intercept)  5.008e+01  9.981e-02  1.310e+02 501.739\n#> measurement  1.385e-03  1.510e-03  3.887e+03   0.918\n#> predictor   -2.826e-04  7.573e-04  8.973e+01  -0.373\n#>             Pr(>|t|)    \n#> (Intercept)   <2e-16 ***\n#> measurement    0.359    \n#> predictor      0.710    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Correlation of Fixed Effects:\n#>             (Intr) msrmnt\n#> measurement -0.311       \n#> predictor   -0.299  0.002\n#> optimizer (nloptwrap) convergence code: 0 (OK)\n#> Model failed to converge with max|grad| = 1.81782 (tol = 0.002, component 1)\n#> Model is nearly unidentifiable: very large eigenvalue\n#>  - Rescale variables?"},{"path":"regression-analysis.html","id":"extraction-and-plotting-the-random-slopes","chapter":"6 Regression analysis","heading":"6.4.3.1 Extraction and plotting the random slopes","text":"Now random intercept random slope, extract plot specific slope cluster-unit (participant). process relatively simple: extract necessary ingredients fitted mixed-effect model (.e., participant, intercept, slope) glue original dataset (mydata). example stored result separate dataset.plot . visual clarity, included participants 1 30.","code":"\nextracted_data = data.frame(\n  rownames (  coef(myfit)[[\"participant_id\"]]  ), # coef(myfit)... does contain the participant but only as rownames so I call rownames of this object to get my participants\n  coef(myfit)[[\"participant_id\"]] # Note. I added the [[\"participant_id\"]] part  as data.frame( coef(myfit)   ) would prompt an error\n)\nnames(extracted_data) = c(\"participant_id\",\"intercept\",\"slope_measurement\",\"slope_predictor\")\n\nmydata_plus_extracted = left_join(mydata,extracted_data)\n#> Joining with `by = join_by(participant_id)`\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\nggplotly(\n\nmydata_plus_extracted %>% filter(participant_id<=30) %>%\n  ggplot(aes(y=outcome,x= predictor,color=participant_id)) +\n  geom_point(alpha = 0.10) + # To avoid visual overload I make the points fully transparant\n  geom_abline(aes(intercept = intercept, slope = slope_predictor, color = participant_id) ) +\n  geom_abline(intercept = 50.08, slope =  -0.0002826, color = \"black\",linetype=\"dashed\" ) +  # Based on the summary output, the fixed slope\n  theme_classic()\n\n)"},{"path":"regression-analysis.html","id":"model-assumptions","chapter":"6 Regression analysis","heading":"6.5 Model assumptions","text":"now seen output regression models. ever wondered model “sees” data? models receives instruction “forcefully” draw (linear) line computing parameter estimations, model likely assumptions ease computations. assumptions model can relate accuracy can interpret output model, violations assumptions overlooked. already seen model assumptions discussing exploratory factor analysis. part, ’ll focus linear regression models provide easy ways inspect certain model assumptions.","code":""},{"path":"regression-analysis.html","id":"assumptions-linear-regression-not-multilevel","chapter":"6 Regression analysis","heading":"6.5.1 Assumptions: Linear regression (not multilevel)","text":"Unsurprisingly, linear regression models assumes linear relations outcomes predictors, something can visually inspect using scatter plots. assumptions include:assumption normally distributed residualsThe assumption homoscedasticity/homogeneity residualsThe assumption multicollinearity (brief repetition previous part)assumption autocorrelation residuals/independence (time-series data!)One function one go","code":""},{"path":"regression-analysis.html","id":"normal-distributed-residuals-of-the-regression-model","chapter":"6 Regression analysis","heading":"6.5.1.1 Normal distributed residuals of the regression model","text":"Various regression models expect residuals fitted regression model follow normal (gaussian) distribution. Let repeat: error terms model expected resemble normal distribution, assumption say outcome resemble normal distribution. Rather unsurprising, histogram model’s residuals suffice. Let’s take data quality red wine, fit linear regression model, extract model residuals, plot histogram.","code":"\nmydata = read.csv(\"data_files/wineQualityReds.csv\")   \n\nmymodel = lm(pH ~ chlorides, data = mydata)\nsummary(mymodel) # Recall that the summary output can give a quick at how the residuals are distributed\n#> \n#> Call:\n#> lm(formula = pH ~ chlorides, data = mydata)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.46195 -0.09847 -0.00152  0.08717  0.65849 \n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  3.387153   0.007861  430.89   <2e-16 ***\n#> chlorides   -0.869355   0.079148  -10.98   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.1489 on 1597 degrees of freedom\n#> Multiple R-squared:  0.07024,    Adjusted R-squared:  0.06966 \n#> F-statistic: 120.6 on 1 and 1597 DF,  p-value: < 2.2e-16\n\nlibrary(ggplot2)\n\ndata.frame(\n  myresiduals=mymodel$residuals) %>%\n  ggplot(aes(x = myresiduals)) + \n  geom_histogram(fill=\"white\",color=\"black\")\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"regression-analysis.html","id":"homoscedasticityhomogeneity-of-the-residuals","chapter":"6 Regression analysis","heading":"6.5.1.2 homoscedasticity/homogeneity of the residuals","text":"unique sounding word, homoscedasticity residuals refer extent residuals constant along predicted values models’ linear regression. want check whether residuals homoscedastic rather heteroskedastic, need extract plot residuals (y-axis) along predicted values (x-axis).Now, use “raw” residuals using residuals() function. However, also use standardized residuals. use studentized residuals example. get studentized residuals, can use rstudent() function., plot raw studentized residuals.Now visual inspection extent homoscedasticity, look left side plot. Mind distance upper lower points. always put index finger “upper residuals” thumb “lower ones”. Now move along left right (follow method, slide hand left right). distance change notably multiple points? see funnel shape? , may indicate residuals () homoscedastic.Next visual inspection, also consider Breusch-Pagan test heteroskedasticity p value .05 suggests heteroskedasticity. purpose can use e.g., bptest() function lmtest package","code":"\n\nmymodel = lm(pH ~ chlorides, data = mydata)\n\nlibrary(ggplot2)\n\ndata.frame(myresiduals=residuals(mymodel),\n           mypredictedvalues = predict(mymodel) ) %>% \n  ggplot(aes(x = mypredictedvalues, y = myresiduals)) + geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\") +\n  ylab(\" raw residuals\") +\n  theme_classic()\n\n\ndata.frame(myresiduals=rstudent(mymodel),\n           mypredictedvalues = predict(mymodel) ) %>% \n  ggplot(aes(x = mypredictedvalues, y = myresiduals)) + geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\") +\n  ylab(\"studentized residuals\") +\n  theme_classic()\nlibrary(lmtest)\n#> Warning: package 'lmtest' was built under R version 4.3.3\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\nbptest(mymodel, studentize = TRUE)\n#> \n#>  studentized Breusch-Pagan test\n#> \n#> data:  mymodel\n#> BP = 6.3505, df = 1, p-value = 0.01173"},{"path":"regression-analysis.html","id":"no-multicollinearity","chapter":"6 Regression analysis","heading":"6.5.1.3 No multicollinearity","text":"discussed previous part exploratory factor analysis, can use vif() function car package. course, assumption applies regression models one predictor. mentioned , pay extra attention vif scores five, suggest “high” multicollinearity.","code":"\nmymodel = lm(pH ~ chlorides + alcohol + residual.sugar,data = mydata)\nlibrary(car)\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:purrr':\n#> \n#>     some\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\n#> The following object is masked from 'package:boot':\n#> \n#>     logit\nvif(mymodel)\n#>      chlorides        alcohol residual.sugar \n#>       1.056105       1.054706       1.006240"},{"path":"regression-analysis.html","id":"no-autocorrelation-of-residuals","chapter":"6 Regression analysis","heading":"6.5.1.4 No autocorrelation of residuals","text":"assumption case multiple measurements time (e.g., time-series), autocorrelation implies residuals relate one another time. Specifically, correlation variable (residuals) copy one previous time points (commonly referred lags)First, generate data predetermine fixed autocorrelation .55.Autocorrelations can generated visualized using acf() function car package. function correlate inserted value past values (commonly called “lags”) autocorrelations depicted bars (unless instruct plot autocorrelations). “low” autocorrelation indicated bars drop immediately (approximately) zero. Bars instead gradually barely decline indicative autocorrelation.use acf() function ’ll tell function plot autocorrelations, .want statistically test absence autocorrelation, Durbin-Watson test can service. tests checks correlation values variable (including residuals) previous time (.e., time lag one), comes test statistic p.Value (.05 suggests autocorrelation). test statistic ranges zero four values two suggesting positive autocorrelation, two negative autocorrelation, close two autocorrelation.Multiple functions can perform Durbin-Watson test. use durbinWatsonTest() function car() package implements bootstrap resampling procedure can convenient, especially “smaller” samples.","code":"\nexample_autocor = data.frame(\n  predictor = runif(9999,1,10) \n)\n\nerror = arima.sim(n = 9999, list(ar = 0.55))  # AR(1) process, to create autocorrelated residuals\nexample_autocor$outcome = 3 + 1 * example_autocor$predictor + error  \n\nmymodel = lm(outcome ~ predictor  ,data = example_autocor)\n\nmy_autocor = acf(residuals(mymodel), lag.max = 5, plot = FALSE)\nplotly::ggplotly(\n  data.frame(autocorrelations = my_autocor$acf[-1], # The first value is the correlation with itself at the current time, hence a perfect correlation of 1 (so I will exclude this value),\n             lagged = my_autocor$lag[-1]\n  ) %>%\n    ggplot(aes(y=autocorrelations, x = lagged)) +\n    coord_cartesian(ylim=c(-0.5,0.5)) + \n    geom_bar(stat=\"identity\", fill=\"green\",color=\"black\",alpha=0.75) +\n    geom_point() + geom_line(alpha = 0.5, linetype=\"dashed\") +\n    geom_hline(aes(yintercept = 0), color=\"red\") +\n    geom_hline(aes(yintercept = 0.2), color=\"blue\") +\n    geom_hline(aes(yintercept = -0.2), color=\"blue\") # Note that negative autocorrelations are also possible.\n)\n#> Warning: 'bar' objects don't have these attributes: 'mode'\n#> Valid attributes include:\n#> '_deprecated', 'alignmentgroup', 'base', 'basesrc', 'cliponaxis', 'constraintext', 'customdata', 'customdatasrc', 'dx', 'dy', 'error_x', 'error_y', 'hoverinfo', 'hoverinfosrc', 'hoverlabel', 'hovertemplate', 'hovertemplatesrc', 'hovertext', 'hovertextsrc', 'ids', 'idssrc', 'insidetextanchor', 'insidetextfont', 'legendgroup', 'legendgrouptitle', 'legendrank', 'marker', 'meta', 'metasrc', 'name', 'offset', 'offsetgroup', 'offsetsrc', 'opacity', 'orientation', 'outsidetextfont', 'selected', 'selectedpoints', 'showlegend', 'stream', 'text', 'textangle', 'textfont', 'textposition', 'textpositionsrc', 'textsrc', 'texttemplate', 'texttemplatesrc', 'transforms', 'type', 'uid', 'uirevision', 'unselected', 'visible', 'width', 'widthsrc', 'x', 'x0', 'xaxis', 'xcalendar', 'xhoverformat', 'xperiod', 'xperiod0', 'xperiodalignment', 'xsrc', 'y', 'y0', 'yaxis', 'ycalendar', 'yhoverformat', 'yperiod', 'yperiod0', 'yperiodalignment', 'ysrc', 'key', 'set', 'frame', 'transforms', '_isNestedKey', '_isSimpleKey', '_isGraticule', '_bbox'\nlibrary(car)\ndurbinWatsonTest(mymodel, reps=500)\n#>  lag Autocorrelation D-W Statistic p-value\n#>    1       0.5506772     0.8983863       0\n#>  Alternative hypothesis: rho != 0"},{"path":"regression-analysis.html","id":"cheat-all-in-one-to-test-a-lot-of","chapter":"6 Regression analysis","heading":"6.5.1.5 (cheat) all-in-one to test a lot of","text":"performance package check_model() function providing visual check assumptions including normal distribution residuals, homoscedasticity residuals, multicollinearity.","code":"\nmydata = read.csv(\"data_files/wineQualityReds.csv\")   \nmymodel = lm(pH ~ chlorides, data = mydata)\n\nlibrary(performance)\ncheck_model(mymodel)"},{"path":"regression-analysis.html","id":"assumptions-multilevel-linear-regression","chapter":"6 Regression analysis","heading":"6.5.2 Assumptions: Multilevel linear regression","text":"Alright let’s take one step Move assumptions multilevel (mixed-effects, hierarchical) linear regression models. models rely assumption similar ’ve seen earlier also assumptions. Like assumptions :linear relation predictor outcomeNormal distribution residualsHomoscedasticity residualsNo autocorrelations residualsNo multicollinearityAnd unique ones including:6.Normal distribution random effects\n7. appropriate Covariance structureThe first five points can tested like , nothing new.\ninspect whether random effects resemble normal distribution, can extract random effects (.e., random intercepts slopes) using ranef() function use plot histogram quantile-quantile plot.last one, appropriate covariance structure. test whether models complex covariance structure (e.g., models random slopes) preferred simple ones (e.g., models random intercept). can compare simple complex models analysis variance (conveniently topic upcoming part). example compare model random intercept one including random intercept slopeA significant test suggests complex model preferable, advise base decisions solely p value significance. complex model affect statistical power results interpret consider well.","code":"\nmodel1 = lmer(Reaction ~ Days + (1 | Subject), data = sleepstudy)\nmodel2 = lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)\nanova(model1, model2)\n#> refitting model(s) with ML (instead of REML)\n#> Data: sleepstudy\n#> Models:\n#> model1: Reaction ~ Days + (1 | Subject)\n#> model2: Reaction ~ Days + (1 + Days | Subject)\n#>        npar    AIC    BIC  logLik deviance  Chisq Df\n#> model1    4 1802.1 1814.8 -897.04   1794.1          \n#> model2    6 1763.9 1783.1 -875.97   1751.9 42.139  2\n#>        Pr(>Chisq)    \n#> model1               \n#> model2  7.072e-10 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"regression-analysis.html","id":"effect-sizes","chapter":"6 Regression analysis","heading":"6.6 Effect sizes","text":"One aspect p values fail quantify strength relations. Therefore, handy also report effect sizes give indications strength associations. give brief overview effect sizes context linear regression continuous predictors. next part concerning analysis variance, briefly cover effect sizes appropriate context (e.g., eta-squared).","code":""},{"path":"regression-analysis.html","id":"standardized-beta-coefficients-and-r²","chapter":"6 Regression analysis","heading":"6.6.1 Standardized beta coefficients and R²","text":"Alright, actually already discussed one type effect size, standardized beta coefficient. coefficients allow compare predictors measured different scales. Moreover, can help interpreting model outcomes.Suppose standardized beta coefficient 0.5 - mean predictor increases 1 standard deviation, outcome increase 0.5 standard deviation. Remember can obtain coefficients including standardized variables regression models using functions lm.beta() QuantPsyc package **standardize_parameters() effectsize package. Just quick reminder:actually effect size discuss yet summary output, R².\nR² reflects proportion variance outcome/dependent variable explained model (.e., predictors model). turns , equates approximates square correlation predicted outcome (linear regression) raw observed outcome dataset, hence name. can find R² summary output.However, basic R² may biased decide include many predictors whatever reason (.e., overestimate explained variance). case, might want shift attention towards adjusted R² can also retrieved summary output.R² adjusted version concerns joint contribution predictor. Now, want focus contribution individual predictor? purpose can use squared semi-partial correlations (sr²) reflects proportion variance outcome/dependent variable explained specific predictor. words, sr² shows percentage unique variance outcome predictor.","code":"\n# Load dataset\nmydata = mtcars\n\n# Fit a regression model\nmylm = lm(wt ~ hp + mpg, data = mydata)\n\nlibrary(effectsize)\nstandardize_parameters(mylm)\n#> # Standardization method: refit\n#> \n#> Parameter   | Std. Coef. |         95% CI\n#> -----------------------------------------\n#> (Intercept) |   8.24e-17 | [-0.19,  0.19]\n#> hp          |      -0.04 | [-0.34,  0.26]\n#> mpg         |      -0.90 | [-1.20, -0.60]\nsummary(mylm)\n#> \n#> Call:\n#> lm(formula = wt ~ hp + mpg, data = mydata)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -0.6097 -0.3261 -0.1417  0.3081  1.3873 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  6.2182863  0.7455994   8.340 3.42e-09 ***\n#> hp          -0.0005277  0.0020872  -0.253    0.802    \n#> mpg         -0.1455218  0.0237443  -6.129 1.12e-06 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.5024 on 29 degrees of freedom\n#> Multiple R-squared:  0.7534, Adjusted R-squared:  0.7364 \n#> F-statistic: 44.29 on 2 and 29 DF,  p-value: 1.529e-09\n\n# Or call it directly from the output\nsummary(mylm)$r.squared \n#> [1] 0.7533765\n\n# Which equates/resembles the square of the correlation between the predicted outcome and the raw outcome\ncor(predict(mylm), mydata$wt, use = \"complete.obs\")^2 \n#> [1] 0.7533765\nsummary(mylm)$adj.r.squared  # Adjusted\n#> [1] 0.736368\nlibrary(effectsize)\nr2_semipartial(mylm,alternative = \"two.sided\")\n#> Term |      sr2 |       95% CI\n#> ------------------------------\n#> hp   | 5.44e-04 | [0.00, 0.01]\n#> mpg  |     0.32 | [0.10, 0.54]"},{"path":"regression-analysis.html","id":"in-case-of-mixed-effects-models","chapter":"6 Regression analysis","heading":"6.6.2 In case of mixed-effects models","text":"mixed-effects models (multilevel)?use built-sleepstudy dataset (lme4 package).Remember mixed-effects models fixed random part. Intercepts slopes can specified vary cluster unit. Given situation, effect sizes fixed effects also control adjust random effects.Like , opt (partially) standardized beta coefficients compare predictors. One detail , variables standardized using standard deviation sample variable. Therefore, standard deviations can differ extent variables.R²? computation less straightforward given two residual terms. However, r2() function performance package allows compute easily.receive conditional R² marginal R². conditional R² reflects explained variance fixed random effects. marginal R² reflects much variance conditional R² attributed fixed effects.Moving joint-contribution predictors individual contribution. Semi-partial R² can provided partR2() function partR2 package. Note function also computes bootstrapped confidence intervals. demonstration purpose ask 5 bootstraps practice consider set much higher (e.g., 500).lot output. Let’s start top, first marginal R² 95% number predictors plus intercept. semi-partial R². example, unique variance days variable almost equates full model. Third, inclusive R² shows strength predictors model’s predicted values. value approximates semi-partial R², indicates mainly unique variance. notably higher, predictor shares variance predictors. Fourth structure coefficients. may predictors show “low” regression coefficient semi-partial R², (statistically) relevant. predictor showing “high” structure coefficient “low” semi-partial R², likely contributes indirectly shared variance. case structure coefficient “low” well, predictor likely (strongly) related outcome.summary . semi-partial R², inclusive semi-partial R², structure coefficients “high”, predictor shows unique (direct) contribution total variance. semi-partial R² “high”, predictor shows little unique contribution nonetheless explains variance shared correlations others. semi-partial R² “high”, predictor uniquely contributes correlated others.Finally last part output shows standardized beta coefficients.","code":"\nlibrary(lmerTest)\nset.seed(531)\nmydata = sleepstudy\nmydata$Predictor = rnorm(180, 100,25) # I also added an extra predictor\n\nmymixed =  lmer(Reaction ~ Days + Predictor + (1  | Subject), data = mydata)\nlibrary(performance)\nr2(mymixed)\n#> # R2 for Mixed Models\n#> \n#>   Conditional R2: 0.703\n#>      Marginal R2: 0.279\nlibrary(partR2)\n#> Warning: package 'partR2' was built under R version 4.3.3\n\noptions(scipen=999) # \n\npart_r_squared = partR2(mymixed,\n       partvars = c(\"Days\",\"Predictor\"),\n       nboot = 5 # Just for demonstration purpose, set this to a higher value in practice.\n       )\nsummary(part_r_squared)\n#> \n#> \n#> R2 (marginal) and 95% CI for the full model: \n#>  R2     CI_lower CI_upper ndf\n#>  0.2795 0.2726   0.3418   3  \n#> \n#> ----------\n#> \n#> Part (semi-partial) R2:\n#>  Predictor(s)   R2     CI_lower CI_upper ndf\n#>  Model          0.2795 0.2726   0.3418   3  \n#>  Days           0.2792 0.2723   0.3413   2  \n#>  Predictor      0.0000 0.0016   0.0331   2  \n#>  Days+Predictor 0.2795 0.2726   0.3418   1  \n#> \n#> ----------\n#> \n#> Inclusive R2 (SC^2 * R2):\n#>  Predictor IR2    CI_lower CI_upper\n#>  Days      0.2795 0.2724   0.3411  \n#>  Predictor 0.0002 0.0002   0.0019  \n#> \n#> ----------\n#> \n#> Structure coefficients r(Yhat,x):\n#>  Predictor SC     CI_lower CI_upper\n#>  Days      1.0000  0.9956  1.0000  \n#>  Predictor 0.0275 -0.0698  0.0556  \n#> \n#> ----------\n#> \n#> Beta weights (standardised estimates)\n#>  Predictor BW     CI_lower CI_upper\n#>  Days      0.5351  0.5287  0.5894  \n#>  Predictor 0.0052 -0.0487  0.0223  \n#> \n#> ----------\n#> \n#> Parametric bootstrapping resulted in warnings or messages:\n#> Check r2obj$boot_warnings and r2obj$boot_messages."},{"path":"anova.html","id":"anova","chapter":"7 Anova","heading":"7 Anova","text":"linear regression goal “forcefully” draw straight line (slope) using full range continuous predictor (whole x-axis). predictor categorical variable, variable offers discrete values, two, three, categories? Instead estimating slope, focus shifts comparing group means, corresponding levels categorical predictors.part tackle special case linear regression, analysis variance, ANOVA short. ANOVA tests group means per categorical variable (e.g., experimental vs control condition) differ statistically one another. ANOVA comparing variance group variance within groups, hence name.can consider using ANOVA predictors categorical want see whether exist statistically significant differences (based p value) mean outcome per category. part making contrasts, comparing groups one another.start contrasts created allow comparing groups. Two common ones, sum treatment contrasts, discussed. Along lines, tell story dummy-codingThen finally conduct first ANOVA one factor multiple factors. omnibus test show post-hoc group comparisons techniques, create contrasts using linearhypothesis() function, calculate effect sizes.Finally, discuss multivariate ANOVA (MANOVA). learn create outcome contrast matrix test specific “effects” hypotheses.","code":""},{"path":"anova.html","id":"sum-and-treatment-contrasts","chapter":"7 Anova","heading":"7.1 Sum and Treatment Contrasts","text":"mentioned earlier, ANOVA comparing groups e.g., making contrasts . Knowledge R contrasts groups important want properly interpret output ANOVA want flexibly create contrasts restrictions (part hypothesis testing). conducting series ANOVAs (special types), first discuss two common types contrasts: treatment contrasts sum contrasts. treatment contrasts applied factor categorical variables, default R, categories compared reference category (.e., shown intercept model).Say dataset containing factor variable three categories mean scores factors 20,60, 10, respectively. fit regression model factor predictor, change default treatment contrasts, R take reference category categories contrasted .category reference? default, R select reference category alphabetically based lowest value unordered factors, choose category “” . want another reference category like “B”, can use relevel() function.Now, treatment contrasts, category “B” (average score 60) contrasted reference category “” (20). Similarly, category “C” (10) contrasted factor “”. call coefficients, can expect values 20 (reference), 40 (since factor B , average, 40 units higher reference), - 10 (reasoning). Let’s check.can also check treatment contrasts handles factor variable running contrasts() function. can come handy ’ll later reveal can create contrasts restrictions test specific group comparisons. clarity purposes, discuss output contrasts() function section: Making specific hypotheses contrasts.Moving sum contrasts, compare (contrast) category overall mean. use type contrasts sum estimated coefficients equal zero. discuss later , type contrasts required conducting type III ANOVA. Recall means factors 20,60, 10, therefore overall mean 30. Now, values coefficients different compared (default) threatment contrasts. starters, first coefficient mean factor “” overall mean (.e., 30). second coefficient difference first category “” overall mean (.e., 20-30 = -10). value third last coefficient difference second category “B” overall mean (60-30 = 30).coefficient category “C”? hidden can easily uncover . According sum contrasts, coefficient remaining category (“C”) value makes sum estimated coefficients (.e., -10 30), zero. words get following equation: -10 + 30 + coefficient factor “C” = 0. Just clear, value coefficient “C” -20.good well set sum contrasts? can change contrasts “locally” (per individual variable) “globally” (variables ). Note set contrasts fit regression models.Now may wondering, contrasts use? Without making custom contrasts (also possibility), experience, default treatment contrasts fine intuitive interpret. However, bring later, want test interaction effects, might want consider set sum contrasts (thinking using type III ANOVA).","code":"\nset.seed(999)\nmydata = data.frame(\n  \n  score = c( rnorm(20,20,0.001), rnorm(20,60,0.001), rnorm(20,10,0.001) ),\n  factor_variable = factor( rep(c(\" A\",\" B\", \" C\"   ),  each = 20 ) )\n\n  )\n\nmymodel = lm(score ~ factor_variable, data=mydata)\nmymodel = lm(score ~ relevel(factor_variable, ref=\" B\"), data = mydata)\n# Disclaimer. I will NOT run the above code. The reference category will still be \"A\" in the parts below\nround( coef(mymodel), 0)\n#>       (Intercept) factor_variable B factor_variable C \n#>                20                40               -10\ncontrasts(mydata$factor_variable)\n#>     B  C\n#>  A  0  0\n#>  B  1  0\n#>  C  0  1\n# \"Locally\" setting contrasts per variable\ncontrasts(mydata$factor_variable) = contr.sum(3) # 3 since we this variable has three levels/categories\n\n# \"Globally\" setting contrasts that will apply to all variables\noptions(contrasts = c(\"contr.sum\", \"contr.sum\"))\n  # the first \"contr.sum\" applies it to categorical variables\n  # the second \"contr.sum\" applies it to ordered factor variables (ordered() instead of factor() )"},{"path":"anova.html","id":"dummy-coding","chapter":"7 Anova","heading":"7.1.1 Dummy-coding","text":"One small thing, may heard dummy coding need dummy-code variables. might bit confusing surrounding topic, let clarify. Dummy coding often deemed synonymous aforementioned treatment contrasts. Technically, however, dummy coding can refer contrasts use non-negative binary values. contrasts sum contrasts (negative binary values) dummy coded. Personally, avoid confusing, prefer use terms treatment, sum, “custom” coded say something like “contrast code variables” (still can decide ).However, fit regression models using lm(), lmer(), aov() (demonstrate function later ), R automatically create contrasts (.e., contrast code factors). regression models ANOVA, treatment contrasts default.within R typically need add contrast coded variables dataset use ANOVAs. However, still doesn’t hurt want share analysis scripts across software (Stata, SPSS, Mplus, ) want create special contrasts.quickly show add contrast coded variables datasets. First, contrast coding identical treatment contrasts (“dummy-coding” many people call ).Sum coding.","code":"\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\nset.seed(999)\nmydata = data.frame(\n  score = c( rnorm(20,20,0.001), rnorm(20,60,0.001), rnorm(20,10,0.001) ),\n  factor_variable = factor( rep(c(\" A\",\" B\", \" C\"   ),  each = 20 )  )\n) %>%\n  mutate(\n         treatment_B = ifelse(factor_variable==\" B\",1,0),\n         treatment_C = ifelse(factor_variable==\" C\",1,0)\n           )\n\nmymodel = lm(score ~ factor_variable, data = mydata) # To show that R automatically (by default) use treatment contrast coding\nmymodel_dummy = lm(score ~ treatment_B + treatment_C, data = mydata) # treatment_A is the reference so I can leave that out\n\nround( coef(mymodel), 0)\n#>      (Intercept) factor_variable1 factor_variable2 \n#>               30              -10               30\nround( coef(mymodel_dummy), 0)\n#> (Intercept) treatment_B treatment_C \n#>          20          40         -10\nset.seed(999)\nlibrary(dplyr)\nmydata = data.frame(\n  score = c(rnorm(20,20,0.001), \n            rnorm(20,60,0.001), \n            rnorm(20,10,0.001)),\n  factor_variable = factor(rep(c(\"A\", \"B\", \"C\"), each = 20))\n) %>%\n  mutate(\n    sum_A = ifelse(factor_variable == \"A\", 1, \n                   ifelse(factor_variable == \"C\", -1, 0)),\n    sum_B = ifelse(factor_variable == \"B\", 1, \n                   ifelse(factor_variable == \"C\", -1, 0))\n  )\n\ncontrasts(mydata$factor_variable) = contr.sum(3)\n\nmymodel = lm(score ~ factor_variable, data = mydata)\nmymodel_contrast = lm(score ~ sum_A + sum_B, data = mydata)\n\nround(coef(mymodel), 0)\n#>      (Intercept) factor_variable1 factor_variable2 \n#>               30              -10               30\nround(coef(mymodel_contrast), 0)\n#> (Intercept)       sum_A       sum_B \n#>          30         -10          30"},{"path":"anova.html","id":"one-way-anova","chapter":"7 Anova","heading":"7.2 One-way ANOVA","text":"now let’s leave contrasts bit. come back later demonstrate can flexible compare groups. Moving actually conducting ANOVA, starting classic example one categorical variable simple linear regression.use build iris dataset test whether average sepal length differs per species, per group speak. conduct ANOVA never hurts plot outcome per group. purpose, personally like create violin plotsTo conduct ANOVA, can use aov() function enter regression formula just like ’ve done compute regression models. can choose whether want directly conduct ANOVA make linear regression model first. One important detail, make sure predictor variables factors aov() function requires .Time summary output. receive degrees freedom, sum squares (.e., total variance overall mean means per group), mean sum squares (.e., sum squares divided degrees freedom parameter, except residuals), F- p values. p value suggests mean outcome least one group statistically significantly different others. Indeed, aov() function conducted omnibus test test whether least one group-comparison different. Nice, groups statistically significant different ?","code":"\nlibrary(pacman)\np_load(dplyr, ggplot2)  \n\nmydata = iris\n\nmydata %>% ggplot(aes(x = Species, y = Sepal.Length, fill = Species)) +\n  geom_violin(alpha=0.6) + geom_boxplot(alpha = 0.8) + stat_summary(fun = \"mean\")  +\n  theme_classic() + theme(legend.position = \"none\")\n# Feeding the regression formula directly to aov()\nmyanova = aov(Sepal.Length ~ Species, data = mydata)\nsummary(myanova)\n#>              Df Sum Sq Mean Sq F value Pr(>F)    \n#> Species       2  63.21  31.606   119.3 <2e-16 ***\n#> Residuals   147  38.96   0.265                   \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Or compute a separate regression model first\nmymodel = lm(Sepal.Length ~ Species, data = mydata)\nmyanova = aov(mymodel)  \nsummary(myanova)\n#>              Df Sum Sq Mean Sq F value Pr(>F)    \n#> Species       2  63.21  31.606   119.3 <2e-16 ***\n#> Residuals   147  38.96   0.265                   \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"post-hoc-group-comparisons","chapter":"7 Anova","heading":"7.2.1 Post-hoc group-comparisons","text":"exist couple group-comparison methods determine pair groups statistically significantly different, done omnibus test (post-hoc). Let’s start popular one, Tukey Honest Significant Differences test multiple pairwise-comparisons groups (know, mouthful). method called TukeyHSD() function. test can recommended equal sample size per group (e.g., groups sufficiently normal distributed).Conveniently, receive difference sepal length, p value per group comparison, corresponding 95% confidence interval. Note p values adjusted multiple comparisons.methods context one-way ANOVA include Bonferroni correction(classic), ok small number group comparisons (e.g., three) may conservative otherwise. less conservative post-hoc comparison test Holm correction Benjamini-Hochberg correction, even less conservative Bonferroni Holm (recommended large sample lot group comparisons). tests use pairwise.t.test() function specify p value adjustment method.","code":"\nTukeyHSD(myanova)\n#>   Tukey multiple comparisons of means\n#>     95% family-wise confidence level\n#> \n#> Fit: aov(formula = mymodel)\n#> \n#> $Species\n#>                       diff       lwr       upr p adj\n#> versicolor-setosa    0.930 0.6862273 1.1737727     0\n#> virginica-setosa     1.582 1.3382273 1.8257727     0\n#> virginica-versicolor 0.652 0.4082273 0.8957727     0\noptions(scipen=999) # prevents the scientific notation\npairwise.t.test(mydata$Sepal.Length, mydata$Species, p.adj = \"bonf\") # Outcome ; predictor ; adjustment method\npairwise.t.test(mydata$Sepal.Length, mydata$Species, p.adj = \"holm\")\npairwise.t.test(mydata$Sepal.Length, mydata$Species, p.adj = \"BH\")"},{"path":"anova.html","id":"making-your-own-specific-hypotheses-and-contrasts.","chapter":"7 Anova","heading":"7.2.2 Making your own specific hypotheses and contrasts.","text":"methods create group-comparisons using contrasts (explained detail start part). However, desired, can flexibly manipulate contrasts, make group-comparisons whatever differences want test restrictions “special rule” can imagine.part create combinations specific group-comparisons want test separately simultaneously. also yield knowledge relevant special types ANOVA (see later ).\n1. Create “contrast matrix” made “contrast/restriction vectors”. contrast matrices reflect specific group-comparisons want\n2. Conduct specific (combinations ) group-comparison(s) using linearhypothesis() function car packageBefore create contrast matrix, handy look coefficients regression model. Indeed, work coefficients factors specifically order coefficients. Let’s keep model three species flowers.Note regression model used treatment contrasts default. got three coefficients/categories: Setosa (intercept, hence “reference category” using treatment contrasts), versicolor, virginica. categories/groups can represented vector, “contrast/restriction vector” speak, looks like: c(category 1, category 2,categoy 3). Importantly, can easily manipulate categories within matrix/restriction vector. can “activate” “deactivate” category asigning “0” “1” .example, vector (0,1,0) “activate” “category 2” (.e., coefficient multiplied 1) “category 3” “deactivated” (since coefficient multiplied 0). linearHypothesis() function take contrast/restriction matrix made contrast/restriction vectors (example binded rbind function) read : test whether coefficient/ average “category 2” (versicolor) different zero. Remember, work coefficients (differences reference category) different zero actually means different average reference category (setosa flowers).can also combine multiple “contrast/restriction” vectors create restriction matrix tests multiple group-comparisons simultaneously. example, can recreate omnibus test based treatment contrast style .Another thing can make contrasts groups (similar sum contrasts). look vector: (0,1,-1). “activate category 2” now asign negative value “category 3”. can interpret contrast “category 2” “category 3, average versicolor differ virginica? Let’s find :","code":"\nmydata = iris\nmymodel = lm(Sepal.Length ~ Species, data = mydata)\ncoef(mymodel)\n#> (Intercept)    Species1    Species2 \n#>  5.84333333 -0.83733333  0.09266667\nrestriction = rbind(\n           c(0,1,0)\n)\n\nlibrary(car)\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\nlinearHypothesis(mymodel, hypothesis.matrix = restriction, test=\"F\")\n#> Linear hypothesis test\n#> \n#> Hypothesis:\n#> Species1 = 0\n#> \n#> Model 1: restricted model\n#> Model 2: Sepal.Length ~ Species\n#> \n#>   Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n#> 1    148 91.541                                  \n#> 2    147 38.956  1    52.585 198.43 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nrestriction = rbind(\n           c(0,1,0),\n           c(0,0,1)\n)\n\nlibrary(car)\nlinearHypothesis(mymodel, hypothesis.matrix = restriction, test=\"F\")\n#> Linear hypothesis test\n#> \n#> Hypothesis:\n#> Species1 = 0\n#> Species2 = 0\n#> \n#> Model 1: restricted model\n#> Model 2: Sepal.Length ~ Species\n#> \n#>   Res.Df     RSS Df Sum of Sq      F    Pr(>F)    \n#> 1    149 102.168                                  \n#> 2    147  38.956  2    63.212 119.26 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nrestriction = rbind(\n           c(0,1,-1)\n)\n\nlinearHypothesis(mymodel, hypothesis.matrix = restriction, test=\"F\")\n#> Linear hypothesis test\n#> \n#> Hypothesis:\n#> Species1 - Species2 = 0\n#> \n#> Model 1: restricted model\n#> Model 2: Sepal.Length ~ Species\n#> \n#>   Res.Df    RSS Df Sum of Sq      F   Pr(>F)    \n#> 1    148 60.579                                 \n#> 2    147 38.956  1    21.622 81.592 8.77e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"let-us-get-creative-with-hypothesis-testing","chapter":"7 Anova","heading":"7.2.2.1 Let us get creative with hypothesis testing","text":"Alright, promised can get creative hypothesis testing ? Well, give couple examples, suppose, reason, want test whether category “versicolor” five times larger reference category “setosa”.already know default R uses treatment contrasts setosa reference category (since “s” comes first alphabet). Now restriction/contrast vector, thought using something like:Well, get think test whether coefficient (.e., difference mean versicolor setosa) versicolor group times five zero. testing whether mean versicolor five times reference setosaInstead, get “specific group (difference score) five time larger …” part, can use rhs argument. set prespecified value rhs, test whether linear combination coefficients equals prespecified value. Therefore, “activate” versicolor, “deactivate” virginica, set rhs coefficient versicolor times five, test whether versicolor five times larger reference.Another example, suppose want test whether sum coefficients “versicolor” “virginica” 10. case need use categories need activate . Remember rhs argument allows test whether linear combination equals value. Therefore, activate “versicolor”, activate “virginica”, set rhs 10, test whether sum coefficients 10.","code":"\nrestriction = rbind( c(0,5,0) )\nrestriction = rbind(\n  c(0,1,0)\n)\nlibrary(car)\nlinearHypothesis(mymodel, hypothesis.matrix = restriction, rhs = coef(mymodel)[1]*5, test=\"F\") # with coef(mymodel)[1] being the versicolor category\n#> Linear hypothesis test\n#> \n#> Hypothesis:\n#> Species1 = 29.2166666666667\n#> \n#> Model 1: restricted model\n#> Model 2: Sepal.Length ~ Species\n#> \n#>   Res.Df   RSS Df Sum of Sq      F    Pr(>F)    \n#> 1    148 67782                                  \n#> 2    147    39  1     67743 255627 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nrestriction = rbind(\n  c(0,1,1)\n)\nlibrary(car)\nlinearHypothesis(mymodel, hypothesis.matrix = restriction, test=\"F\", rhs = 10)\n#> Linear hypothesis test\n#> \n#> Hypothesis:\n#> Species1  + Species2 = 10\n#> \n#> Model 1: restricted model\n#> Model 2: Sepal.Length ~ Species\n#> \n#>   Res.Df    RSS Df Sum of Sq     F    Pr(>F)    \n#> 1    148 8697.5                                 \n#> 2    147   39.0  1    8658.6 32673 < 2.2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"effect-sizes-1","chapter":"7 Anova","heading":"7.2.3 Effect sizes","text":"Continuing spirit last part, useful include effect sizes next common F statistics obtained output. Several effect sizes appropriate use context ANOVA. Let’s start perhaps known effect size Cohen’s d difference group means divided pooled standard deviations groups. can use cohens_d() function old acquaintance, effectsize package, compute effect size. use function, make sure (temporarily) remove categories two groups error outputted otherwise.Moving . Similar discussed semi-partial R² linear regressions (continuous predictors), ANOVA context, (partial) eta-squared omega-squared measure. eta-squared measures shows proportion total variance explained (one) factor variable whereas partial eta-squared shows proportion variance explained specific factor controlling others. However, (partial) eta-squared biased bias decreasing size groups increases, consider omega-square measure instead (especially “small” sample sizes). compute effect sizes, can consider eta_squared() omega_squared() function effectsize package.One thing want notice. Recently, use eta-squared ANOVA mixed-effects model criticized (click ). discussed previous part, effect sizes mixed-effects models acknowledge fixed random effects part. want compute (partial) eta-squared mixed-effects models include 2 x 2 design (.e., two categorical predictors two levels), recommended use sum contrast coding use cluster-mean centered outcome variables obtain eta-squared within. Full details provided linked article, reference article shown end part.","code":"\nlibrary(dplyr)\nlibrary(effectsize)\n\nmydata = iris\nmydata_temp = mydata %>% filter(!Species==\"virginica\") # the cohens_d functions asks for exactly two groups, hence I temporarily filter out \"virginica\" as an example\n\ncohens_d(Sepal.Length ~ Species, data = mydata_temp) \n#> Cohen's d |         95% CI\n#> --------------------------\n#> -2.10     | [-2.59, -1.61]\n#> \n#> - Estimated using pooled SD.\nlibrary(effectsize)\n\nmyanova = aov(Sepal.Length ~ Species, data = iris)\neta_squared(myanova)\n#> # Effect Size for ANOVA\n#> \n#> Parameter | Eta2 |       95% CI\n#> -------------------------------\n#> Species   | 0.62 | [0.54, 1.00]\n#> \n#> - One-sided CIs: upper bound fixed at [1.00].\nomega_squared(myanova)  \n#> # Effect Size for ANOVA\n#> \n#> Parameter | Omega2 |       95% CI\n#> ---------------------------------\n#> Species   |   0.61 | [0.53, 1.00]\n#> \n#> - One-sided CIs: upper bound fixed at [1.00]."},{"path":"anova.html","id":"two-way-anova","chapter":"7 Anova","heading":"7.3 Two-way ANOVA","text":"Let’s add extra categorical variable equation. Suppose also included location flower (location “”,“b”,…“e”). Now can test main effect species location sepal length well interaction effect two predictors.Since used default treatment contrasts, note “reference category” consists two variables: setosa flower measured location “”. Coefficient versicolor shows difference reference flower setosa reference location “”. Similarly, coefficient “c” shows difference reference location “” reference flower setosa. look coefficients interaction terms, say virginica location d, shows difference virginica setosa, differs location “c” compared location “”.Since factors interaction effect, novel decision pop . type ANOVA want use?","code":"\nmydata = iris\nmydata$Location = factor(rep(c(\"a\",\"b\",\"c\",\"d\",\"e\"), each = 10))\n\nmydata %>% ggplot(aes(x = Species, y = Sepal.Length, fill = Species)) +\n  geom_violin(alpha=0.6) + geom_boxplot(alpha = 0.8) + stat_summary(fun = \"mean\")  +\n  facet_wrap(~Location) +\n  theme_classic() + theme(legend.position = \"none\")\n\nmymodel = lm(Sepal.Length ~ Species * Location, data = mydata)\ncoef(mymodel)\n#>        (Intercept)           Species1           Species2 \n#>       5.843333e+00      -8.373333e-01       9.266667e-02 \n#>          Location1          Location2          Location3 \n#>       4.658198e-17       2.666667e-02       1.233333e-01 \n#>          Location4 Species1:Location1 Species2:Location1 \n#>       3.666667e-02      -1.460000e-01       1.640000e-01 \n#> Species1:Location2 Species2:Location2 Species1:Location3 \n#>       1.773333e-01      -1.126667e-01      -1.193333e-01 \n#> Species2:Location3 Species1:Location4 Species2:Location4 \n#>       2.006667e-01       2.733333e-02      -1.426667e-01"},{"path":"anova.html","id":"four-different-types-of-anova","chapter":"7 Anova","heading":"7.3.1 Four different types of ANOVA","text":"Since introduced interaction effect regression models ANOVA, may good time acknowledge existence different types ANOVA. aov() function used far computes type ANOVA tests factor order specified model (handy order factors crucial). Next type , also type II, III, IV. type II ANOVA tests main effect adjusting main effects (however ignores interactions suitable interactions included). Type III tests factors accounting others, including interactions. consider go type III (since want include interactions), use sum contrasts instead default treatment contrasts. Finally, type IV, considered complex models categories category combinations empty (data).access type II IV, can use Anova() function car package.difference type II type III ANOVA depend “strong” interaction effect models . remainder examples use type III flexible approach (.e., strong assumptions limitations).Irrespective choice ANOVA type, model conduct omnibus test. Therefore, , need dive deeper individual post-hoc group-comparisons.","code":"\n# Type II ANOVA\nmymodel = lm(Sepal.Length ~ Species * Location, data = mydata)\nAnova(mymodel, type=\"II\") # the type ignoring the interaction\n#> Anova Table (Type II tests)\n#> \n#> Response: Sepal.Length\n#>                  Sum Sq  Df  F value Pr(>F)    \n#> Species          63.212   2 120.9107 <2e-16 ***\n#> Location          1.563   4   1.4952 0.2071    \n#> Species:Location  2.104   8   1.0061 0.4345    \n#> Residuals        35.289 135                    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Type III ANOVA\noptions(contrasts = c(\"contr.sum\", \"contr.sum\"))\nAnova(mymodel, type=\"III\") # the type you should use with sum  contrasts, see above\n#> Anova Table (Type III tests)\n#> \n#> Response: Sepal.Length\n#>                  Sum Sq  Df    F value Pr(>F)    \n#> (Intercept)      5121.7   1 19593.2734 <2e-16 ***\n#> Species            63.2   2   120.9107 <2e-16 ***\n#> Location            1.6   4     1.4952 0.2071    \n#> Species:Location    2.1   8     1.0061 0.4345    \n#> Residuals          35.3 135                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"two-way-anova-post-hoc-comparisons","chapter":"7 Anova","heading":"7.3.2 Two-way ANOVA: Post-hoc comparisons","text":"Instead pairwise t tests one-way ANOVA, prefer use emmeans() function emmeans package. function allows comparisons main effects: comparing petal length species one another per location comparing location one another per species, interaction effects: compare difference petal length species across different locations. Similar pairwise.t.test() function, can choose want adjust p value (Bonferroni, Benjamini-Hochberg, etc.).Now approach group-comparisons different ways. example, check whether interaction effect statistically significant regression model ANOVA (deem sufficiently significant). , can zoom mean sepal length differs per species within location, differs per location within species. way, checking main effects, involve variable. addition, look interaction effect check whether combinations species locations differ combinationsInstead, deem interaction effect “significant”, also decide skip interaction effect keep main effects separate variable , don’t look species within locations locations within different species across locations species.far ’ve dealth groups manifesting predictors. Depending data, can also can simultaneously compare different combinations/groups outcome well. special type ANOVA can found within multivariate (.e., multiple outcomes/dependent variables) regression models. One relatively robust one ignored issue.","code":"\nmydata = iris\nmydata$Location = factor(rep(c(\"a\",\"b\",\"c\",\"d\",\"e\"), each = 10))\nmymodel = lm(Sepal.Length ~ Species * Location, data = mydata)\n\nlibrary(emmeans)\n\nemmeans(mymodel, pairwise ~ Location | Species, adjust = \"Tukey\") # Main effect: differences between locations WITHIN species\n#> $emmeans\n#> Species = setosa:\n#>  Location emmean    SE  df lower.CL upper.CL\n#>  a          4.86 0.162 135     4.54     5.18\n#>  b          5.21 0.162 135     4.89     5.53\n#>  c          5.01 0.162 135     4.69     5.33\n#>  d          5.07 0.162 135     4.75     5.39\n#>  e          4.88 0.162 135     4.56     5.20\n#> \n#> Species = versicolor:\n#>  Location emmean    SE  df lower.CL upper.CL\n#>  a          6.10 0.162 135     5.78     6.42\n#>  b          5.85 0.162 135     5.53     6.17\n#>  c          6.26 0.162 135     5.94     6.58\n#>  d          5.83 0.162 135     5.51     6.15\n#>  e          5.64 0.162 135     5.32     5.96\n#> \n#> Species = virginica:\n#>  Location emmean    SE  df lower.CL upper.CL\n#>  a          6.57 0.162 135     6.25     6.89\n#>  b          6.55 0.162 135     6.23     6.87\n#>  c          6.63 0.162 135     6.31     6.95\n#>  d          6.74 0.162 135     6.42     7.06\n#>  e          6.45 0.162 135     6.13     6.77\n#> \n#> Confidence level used: 0.95 \n#> \n#> $contrasts\n#> Species = setosa:\n#>  contrast estimate    SE  df t.ratio p.value\n#>  a - b       -0.35 0.229 135  -1.531  0.5444\n#>  a - c       -0.15 0.229 135  -0.656  0.9652\n#>  a - d       -0.21 0.229 135  -0.918  0.8894\n#>  a - e       -0.02 0.229 135  -0.087  1.0000\n#>  b - c        0.20 0.229 135   0.875  0.9057\n#>  b - d        0.14 0.229 135   0.612  0.9729\n#>  b - e        0.33 0.229 135   1.443  0.6009\n#>  c - d       -0.06 0.229 135  -0.262  0.9989\n#>  c - e        0.13 0.229 135   0.569  0.9794\n#>  d - e        0.19 0.229 135   0.831  0.9206\n#> \n#> Species = versicolor:\n#>  contrast estimate    SE  df t.ratio p.value\n#>  a - b        0.25 0.229 135   1.093  0.8097\n#>  a - c       -0.16 0.229 135  -0.700  0.9562\n#>  a - d        0.27 0.229 135   1.181  0.7623\n#>  a - e        0.46 0.229 135   2.012  0.2660\n#>  b - c       -0.41 0.229 135  -1.793  0.3818\n#>  b - d        0.02 0.229 135   0.087  1.0000\n#>  b - e        0.21 0.229 135   0.918  0.8894\n#>  c - d        0.43 0.229 135   1.881  0.3328\n#>  c - e        0.62 0.229 135   2.712  0.0574\n#>  d - e        0.19 0.229 135   0.831  0.9206\n#> \n#> Species = virginica:\n#>  contrast estimate    SE  df t.ratio p.value\n#>  a - b        0.02 0.229 135   0.087  1.0000\n#>  a - c       -0.06 0.229 135  -0.262  0.9989\n#>  a - d       -0.17 0.229 135  -0.744  0.9458\n#>  a - e        0.12 0.229 135   0.525  0.9847\n#>  b - c       -0.08 0.229 135  -0.350  0.9968\n#>  b - d       -0.19 0.229 135  -0.831  0.9206\n#>  b - e        0.10 0.229 135   0.437  0.9923\n#>  c - d       -0.11 0.229 135  -0.481  0.9890\n#>  c - e        0.18 0.229 135   0.787  0.9339\n#>  d - e        0.29 0.229 135   1.268  0.7110\n#> \n#> P value adjustment: tukey method for comparing a family of 5 estimates\nemmeans(mymodel, pairwise ~ Species | Location, adjust = \"Bonferroni\") \n#> $emmeans\n#> Location = a:\n#>  Species    emmean    SE  df lower.CL upper.CL\n#>  setosa       4.86 0.162 135     4.54     5.18\n#>  versicolor   6.10 0.162 135     5.78     6.42\n#>  virginica    6.57 0.162 135     6.25     6.89\n#> \n#> Location = b:\n#>  Species    emmean    SE  df lower.CL upper.CL\n#>  setosa       5.21 0.162 135     4.89     5.53\n#>  versicolor   5.85 0.162 135     5.53     6.17\n#>  virginica    6.55 0.162 135     6.23     6.87\n#> \n#> Location = c:\n#>  Species    emmean    SE  df lower.CL upper.CL\n#>  setosa       5.01 0.162 135     4.69     5.33\n#>  versicolor   6.26 0.162 135     5.94     6.58\n#>  virginica    6.63 0.162 135     6.31     6.95\n#> \n#> Location = d:\n#>  Species    emmean    SE  df lower.CL upper.CL\n#>  setosa       5.07 0.162 135     4.75     5.39\n#>  versicolor   5.83 0.162 135     5.51     6.15\n#>  virginica    6.74 0.162 135     6.42     7.06\n#> \n#> Location = e:\n#>  Species    emmean    SE  df lower.CL upper.CL\n#>  setosa       4.88 0.162 135     4.56     5.20\n#>  versicolor   5.64 0.162 135     5.32     5.96\n#>  virginica    6.45 0.162 135     6.13     6.77\n#> \n#> Confidence level used: 0.95 \n#> \n#> $contrasts\n#> Location = a:\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor       -1.24 0.229 135  -5.423  <.0001\n#>  setosa - virginica        -1.71 0.229 135  -7.479  <.0001\n#>  versicolor - virginica    -0.47 0.229 135  -2.056  0.1253\n#> \n#> Location = b:\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor       -0.64 0.229 135  -2.799  0.0176\n#>  setosa - virginica        -1.34 0.229 135  -5.861  <.0001\n#>  versicolor - virginica    -0.70 0.229 135  -3.061  0.0080\n#> \n#> Location = c:\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor       -1.25 0.229 135  -5.467  <.0001\n#>  setosa - virginica        -1.62 0.229 135  -7.085  <.0001\n#>  versicolor - virginica    -0.37 0.229 135  -1.618  0.3239\n#> \n#> Location = d:\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor       -0.76 0.229 135  -3.324  0.0034\n#>  setosa - virginica        -1.67 0.229 135  -7.304  <.0001\n#>  versicolor - virginica    -0.91 0.229 135  -3.980  0.0003\n#> \n#> Location = e:\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor       -0.76 0.229 135  -3.324  0.0034\n#>  setosa - virginica        -1.57 0.229 135  -6.866  <.0001\n#>  versicolor - virginica    -0.81 0.229 135  -3.543  0.0016\n#> \n#> P value adjustment: bonferroni method for 3 tests\nemmeans(mymodel, pairwise ~ Species * Location, adjust = \"BH\") # interaction effect: comparing combinations to all other combinations\n#> $emmeans\n#>  Species    Location emmean    SE  df lower.CL upper.CL\n#>  setosa     a          4.86 0.162 135     4.54     5.18\n#>  versicolor a          6.10 0.162 135     5.78     6.42\n#>  virginica  a          6.57 0.162 135     6.25     6.89\n#>  setosa     b          5.21 0.162 135     4.89     5.53\n#>  versicolor b          5.85 0.162 135     5.53     6.17\n#>  virginica  b          6.55 0.162 135     6.23     6.87\n#>  setosa     c          5.01 0.162 135     4.69     5.33\n#>  versicolor c          6.26 0.162 135     5.94     6.58\n#>  virginica  c          6.63 0.162 135     6.31     6.95\n#>  setosa     d          5.07 0.162 135     4.75     5.39\n#>  versicolor d          5.83 0.162 135     5.51     6.15\n#>  virginica  d          6.74 0.162 135     6.42     7.06\n#>  setosa     e          4.88 0.162 135     4.56     5.20\n#>  versicolor e          5.64 0.162 135     5.32     5.96\n#>  virginica  e          6.45 0.162 135     6.13     6.77\n#> \n#> Confidence level used: 0.95 \n#> \n#> $contrasts\n#>  contrast                    estimate    SE  df t.ratio\n#>  setosa a - versicolor a        -1.24 0.229 135  -5.423\n#>  setosa a - virginica a         -1.71 0.229 135  -7.479\n#>  setosa a - setosa b            -0.35 0.229 135  -1.531\n#>  setosa a - versicolor b        -0.99 0.229 135  -4.330\n#>  setosa a - virginica b         -1.69 0.229 135  -7.391\n#>  setosa a - setosa c            -0.15 0.229 135  -0.656\n#>  setosa a - versicolor c        -1.40 0.229 135  -6.123\n#>  setosa a - virginica c         -1.77 0.229 135  -7.741\n#>  setosa a - setosa d            -0.21 0.229 135  -0.918\n#>  setosa a - versicolor d        -0.97 0.229 135  -4.242\n#>  setosa a - virginica d         -1.88 0.229 135  -8.222\n#>  setosa a - setosa e            -0.02 0.229 135  -0.087\n#>  setosa a - versicolor e        -0.78 0.229 135  -3.411\n#>  setosa a - virginica e         -1.59 0.229 135  -6.954\n#>  versicolor a - virginica a     -0.47 0.229 135  -2.056\n#>  versicolor a - setosa b         0.89 0.229 135   3.892\n#>  versicolor a - versicolor b     0.25 0.229 135   1.093\n#>  versicolor a - virginica b     -0.45 0.229 135  -1.968\n#>  versicolor a - setosa c         1.09 0.229 135   4.767\n#>  versicolor a - versicolor c    -0.16 0.229 135  -0.700\n#>  versicolor a - virginica c     -0.53 0.229 135  -2.318\n#>  versicolor a - setosa d         1.03 0.229 135   4.505\n#>  versicolor a - versicolor d     0.27 0.229 135   1.181\n#>  versicolor a - virginica d     -0.64 0.229 135  -2.799\n#>  versicolor a - setosa e         1.22 0.229 135   5.336\n#>  versicolor a - versicolor e     0.46 0.229 135   2.012\n#>  versicolor a - virginica e     -0.35 0.229 135  -1.531\n#>  virginica a - setosa b          1.36 0.229 135   5.948\n#>  virginica a - versicolor b      0.72 0.229 135   3.149\n#>  virginica a - virginica b       0.02 0.229 135   0.087\n#>  virginica a - setosa c          1.56 0.229 135   6.823\n#>  virginica a - versicolor c      0.31 0.229 135   1.356\n#>  virginica a - virginica c      -0.06 0.229 135  -0.262\n#>  virginica a - setosa d          1.50 0.229 135   6.560\n#>  virginica a - versicolor d      0.74 0.229 135   3.236\n#>  virginica a - virginica d      -0.17 0.229 135  -0.744\n#>  virginica a - setosa e          1.69 0.229 135   7.391\n#>  virginica a - versicolor e      0.93 0.229 135   4.067\n#>  virginica a - virginica e       0.12 0.229 135   0.525\n#>  setosa b - versicolor b        -0.64 0.229 135  -2.799\n#>  setosa b - virginica b         -1.34 0.229 135  -5.861\n#>  setosa b - setosa c             0.20 0.229 135   0.875\n#>  setosa b - versicolor c        -1.05 0.229 135  -4.592\n#>  setosa b - virginica c         -1.42 0.229 135  -6.210\n#>  setosa b - setosa d             0.14 0.229 135   0.612\n#>  setosa b - versicolor d        -0.62 0.229 135  -2.712\n#>  setosa b - virginica d         -1.53 0.229 135  -6.692\n#>  setosa b - setosa e             0.33 0.229 135   1.443\n#>  setosa b - versicolor e        -0.43 0.229 135  -1.881\n#>  setosa b - virginica e         -1.24 0.229 135  -5.423\n#>  versicolor b - virginica b     -0.70 0.229 135  -3.061\n#>  versicolor b - setosa c         0.84 0.229 135   3.674\n#>  versicolor b - versicolor c    -0.41 0.229 135  -1.793\n#>  versicolor b - virginica c     -0.78 0.229 135  -3.411\n#>  versicolor b - setosa d         0.78 0.229 135   3.411\n#>  versicolor b - versicolor d     0.02 0.229 135   0.087\n#>  versicolor b - virginica d     -0.89 0.229 135  -3.892\n#>  versicolor b - setosa e         0.97 0.229 135   4.242\n#>  versicolor b - versicolor e     0.21 0.229 135   0.918\n#>  versicolor b - virginica e     -0.60 0.229 135  -2.624\n#>  virginica b - setosa c          1.54 0.229 135   6.735\n#>  virginica b - versicolor c      0.29 0.229 135   1.268\n#>  virginica b - virginica c      -0.08 0.229 135  -0.350\n#>  virginica b - setosa d          1.48 0.229 135   6.473\n#>  virginica b - versicolor d      0.72 0.229 135   3.149\n#>  virginica b - virginica d      -0.19 0.229 135  -0.831\n#>  virginica b - setosa e          1.67 0.229 135   7.304\n#>  virginica b - versicolor e      0.91 0.229 135   3.980\n#>  virginica b - virginica e       0.10 0.229 135   0.437\n#>  setosa c - versicolor c        -1.25 0.229 135  -5.467\n#>  setosa c - virginica c         -1.62 0.229 135  -7.085\n#>  setosa c - setosa d            -0.06 0.229 135  -0.262\n#>  setosa c - versicolor d        -0.82 0.229 135  -3.586\n#>  setosa c - virginica d         -1.73 0.229 135  -7.566\n#>  setosa c - setosa e             0.13 0.229 135   0.569\n#>  setosa c - versicolor e        -0.63 0.229 135  -2.755\n#>  setosa c - virginica e         -1.44 0.229 135  -6.298\n#>  versicolor c - virginica c     -0.37 0.229 135  -1.618\n#>  versicolor c - setosa d         1.19 0.229 135   5.205\n#>  versicolor c - versicolor d     0.43 0.229 135   1.881\n#>  versicolor c - virginica d     -0.48 0.229 135  -2.099\n#>  versicolor c - setosa e         1.38 0.229 135   6.035\n#>  versicolor c - versicolor e     0.62 0.229 135   2.712\n#>  versicolor c - virginica e     -0.19 0.229 135  -0.831\n#>  virginica c - setosa d          1.56 0.229 135   6.823\n#>  virginica c - versicolor d      0.80 0.229 135   3.499\n#>  virginica c - virginica d      -0.11 0.229 135  -0.481\n#>  virginica c - setosa e          1.75 0.229 135   7.654\n#>  virginica c - versicolor e      0.99 0.229 135   4.330\n#>  virginica c - virginica e       0.18 0.229 135   0.787\n#>  setosa d - versicolor d        -0.76 0.229 135  -3.324\n#>  setosa d - virginica d         -1.67 0.229 135  -7.304\n#>  setosa d - setosa e             0.19 0.229 135   0.831\n#>  setosa d - versicolor e        -0.57 0.229 135  -2.493\n#>  setosa d - virginica e         -1.38 0.229 135  -6.035\n#>  versicolor d - virginica d     -0.91 0.229 135  -3.980\n#>  versicolor d - setosa e         0.95 0.229 135   4.155\n#>  versicolor d - versicolor e     0.19 0.229 135   0.831\n#>  versicolor d - virginica e     -0.62 0.229 135  -2.712\n#>  virginica d - setosa e          1.86 0.229 135   8.135\n#>  virginica d - versicolor e      1.10 0.229 135   4.811\n#>  virginica d - virginica e       0.29 0.229 135   1.268\n#>  setosa e - versicolor e        -0.76 0.229 135  -3.324\n#>  setosa e - virginica e         -1.57 0.229 135  -6.866\n#>  versicolor e - virginica e     -0.81 0.229 135  -3.543\n#>  p.value\n#>   <.0001\n#>   <.0001\n#>   0.1748\n#>   0.0001\n#>   <.0001\n#>   0.5729\n#>   <.0001\n#>   <.0001\n#>   0.4447\n#>   0.0001\n#>   <.0001\n#>   0.9304\n#>   0.0017\n#>   <.0001\n#>   0.0635\n#>   0.0004\n#>   0.3494\n#>   0.0756\n#>   <.0001\n#>   0.5479\n#>   0.0344\n#>   <.0001\n#>   0.3070\n#>   0.0103\n#>   <.0001\n#>   0.0693\n#>   0.1748\n#>   <.0001\n#>   0.0037\n#>   0.9304\n#>   <.0001\n#>   0.2358\n#>   0.8167\n#>   <.0001\n#>   0.0029\n#>   0.5233\n#>   <.0001\n#>   0.0002\n#>   0.6501\n#>   0.0103\n#>   <.0001\n#>   0.4680\n#>   <.0001\n#>   <.0001\n#>   0.5984\n#>   0.0124\n#>   <.0001\n#>   0.2036\n#>   0.0894\n#>   <.0001\n#>   0.0048\n#>   0.0008\n#>   0.1067\n#>   0.0017\n#>   0.0017\n#>   0.9304\n#>   0.0004\n#>   0.0001\n#>   0.4447\n#>   0.0156\n#>   <.0001\n#>   0.2682\n#>   0.7633\n#>   <.0001\n#>   0.0037\n#>   0.4754\n#>   <.0001\n#>   0.0003\n#>   0.7027\n#>   <.0001\n#>   <.0001\n#>   0.8167\n#>   0.0010\n#>   <.0001\n#>   0.6241\n#>   0.0115\n#>   <.0001\n#>   0.1511\n#>   <.0001\n#>   0.0894\n#>   0.0581\n#>   <.0001\n#>   0.0124\n#>   0.4754\n#>   <.0001\n#>   0.0014\n#>   0.6763\n#>   <.0001\n#>   0.0001\n#>   0.4991\n#>   0.0022\n#>   <.0001\n#>   0.4754\n#>   0.0221\n#>   <.0001\n#>   0.0003\n#>   0.0002\n#>   0.4754\n#>   0.0124\n#>   <.0001\n#>   <.0001\n#>   0.2682\n#>   0.0022\n#>   <.0001\n#>   0.0012\n#> \n#> P value adjustment: BH method for 105 tests\nemmeans(mymodel, pairwise ~ Species, adjust = \"Holm\") \n#> $emmeans\n#>  Species    emmean     SE  df lower.CL upper.CL\n#>  setosa       5.01 0.0723 135     4.86     5.15\n#>  versicolor   5.94 0.0723 135     5.79     6.08\n#>  virginica    6.59 0.0723 135     6.45     6.73\n#> \n#> Results are averaged over the levels of: Location \n#> Confidence level used: 0.95 \n#> \n#> $contrasts\n#>  contrast               estimate    SE  df t.ratio p.value\n#>  setosa - versicolor      -0.930 0.102 135  -9.095  <.0001\n#>  setosa - virginica       -1.582 0.102 135 -15.471  <.0001\n#>  versicolor - virginica   -0.652 0.102 135  -6.376  <.0001\n#> \n#> Results are averaged over the levels of: Location \n#> P value adjustment: holm method for 3 tests\nemmeans(mymodel, pairwise ~ Location, adjust = \"Holm\") \n#> $emmeans\n#>  Location emmean     SE  df lower.CL upper.CL\n#>  a          5.84 0.0933 135     5.66     6.03\n#>  b          5.87 0.0933 135     5.69     6.05\n#>  c          5.97 0.0933 135     5.78     6.15\n#>  d          5.88 0.0933 135     5.70     6.06\n#>  e          5.66 0.0933 135     5.47     5.84\n#> \n#> Results are averaged over the levels of: Species \n#> Confidence level used: 0.95 \n#> \n#> $contrasts\n#>  contrast estimate    SE  df t.ratio p.value\n#>  a - b     -0.0267 0.132 135  -0.202  1.0000\n#>  a - c     -0.1233 0.132 135  -0.934  1.0000\n#>  a - d     -0.0367 0.132 135  -0.278  1.0000\n#>  a - e      0.1867 0.132 135   1.414  1.0000\n#>  b - c     -0.0967 0.132 135  -0.732  1.0000\n#>  b - d     -0.0100 0.132 135  -0.076  1.0000\n#>  b - e      0.2133 0.132 135   1.616  0.8674\n#>  c - d      0.0867 0.132 135   0.657  1.0000\n#>  c - e      0.3100 0.132 135   2.348  0.2031\n#>  d - e      0.2233 0.132 135   1.692  0.8369\n#> \n#> Results are averaged over the levels of: Species \n#> P value adjustment: holm method for 10 tests"},{"path":"anova.html","id":"manova","chapter":"7 Anova","heading":"7.4 MANOVA","text":"consider use classic univariate repeated measures design factors two levels, may encounter violation assumption sphericity. Violation sphericity confer risk unreliable p values. attempt detect violations herein, consider use e.g., Mauchly’s test sphericity. Unfortunately, like many statistical tests, reliability depend different factors including sample size, degree departure normal distribution, . short, tricky situation.context e.g., experiments within-subject design (subject goes multiple experimental conditions) consider aggregate data across conditions, method multivariate analysis variance (MANOVA). MANOVA multiple outcomes/dependent variables analyzed simultaneously.MANOVA typically yields following steps.\n1. Transform data wide format outcome - commonly repeated measure subject - aggregated across conditions\n2. Create contrast matrices outcomes\n3. Compute multivariate linear regression models include contrast matrices step two.data created . first step transform, rather reshape, data wide format outcome “score” aggregated spread across variable “condition_numbers”. may recall previous part, prefer use dcast() function reshape2 package() reshape long wide.create contrast matrix outcomes, can think terms vectors done beginning part. Just like work coefficients. Different time model multivariate regression model since outcome “score” spread across multiple levels “condition_number”. multivariate regression model takes form classic linear regression multiple outcomes bind together using cbind() function.job replace x activate deactivate given multiple condition(s). words, decide part outcome want include parts want compare (become clear later ). However, rules bit different compared predictor contrast vectors matrices. treatment sum contrast coding reference, least outcomes. Also, sum values vector must zero cases.Say want compare Condition_1 Condition_2. can asign value “1” Condition_1 “-1” Condition_2, vice versa. interested Condition_3 multiplying zero deactivate . get vector c(1,-1,0) condition_1 multiplied 1 (remains alive), condition_2 multiplied -1 (also remains alive becomes negative, contrast), condition_3 temporarily erased existence multiplied zero. end product difference Condition_1 Condition_2\nfeed vector (outcome) contrast matrix call M. Within classic linear regression model multiply outcome spread across Condition freshly created contrast matrix. Since created one vector, end univariate regression, hence ANOVA.Let’s briefly check (outcome) contrast matrix outcome within regression.Indeed, vector (1,-1,0) created difference Condition_1 Condition_2 difference used within regression.Alright, next example. Let’s say compare Condition_3 average Condition_1 Condition_2. case need “activate” conditions nothing multiplied zero. different ways compute average. multiply Condition_3 two contrast Condition_1 Condition_2. makes outcome within Condition_2 twice high value. Alternatively, can half values Condition_1 Condition_2 multiplying 0.5. Either way, creates equal fight since Condition_3 (.e., sum ) Condition_1 Condition_2 respects rule sum values inside vector zero.\nLast example one outcome variable, till now, included one vector inside (outcome) contrast matrix, therefore end multivariate regression. Say want compare conditions one another.keep one outcome (.e., two differences). One thing note, Anova() function anymore accept classic F test statistic (chi-squared test statistic). context MANOVA, four common test statistics used: Pillai-Bartlett trace (coded “pillai” within anova), Wilk’s likelihood ration (“Wilks”), Hoteling-Lawley trace (“Hoteling-Lawley”), Roy’s Largest Root (“Roy”). Like many tests, power tests can depend different factors including sample size, (multivariate) normal distribution outcomes, . Therefore, moment writing guide, claim superiority one test another.","code":"\nset.seed(987)\nmydata = data.frame(\n  participant = rep(c(1:100), times = 30),\n  score = round( c(rnorm(100,10,3),  rnorm(100,5,1.5),  rnorm(100, 20,5) ), 2  ),\n  condition_numbers = factor( rep( c(\"1\",\"2\",\"3\"), each = 100) )\n)\n\n# Reshape to wide format with the outcome aggregated and spread across condition\nlibrary(reshape2)\nmydata = dcast(participant ~ condition_numbers, data=mydata, value.var=\"score\", mean)\nnames(mydata)[2:ncol(mydata)] = paste0(\"Condition_\" , colnames(mydata)[2:ncol(mydata)]  ) # to rename \"1\" to \"Condition_1\", etc.\nmymodel = lm(cbind(Condition_1, Condition_2, Condition_3) ~ 1, data = mydata)  \ncoef(mymodel)\n#>             Condition_1 Condition_2 Condition_3\n#> (Intercept)     10.0528      5.2094     19.8799\n# Contrast \"Condition_1\" vs \"Condition_2\"\ndiff = c(1,-1,0)\nM = cbind(diff)\nmymodel = lm(cbind(Condition_1, Condition_2, Condition_3) %*% M ~ 1, data = mydata)\nanova(mymodel)\n#> Analysis of Variance Table\n#> \n#> Response: cbind(Condition_1, Condition_2, Condition_3) %*% M\n#>           Df Sum Sq Mean Sq F value Pr(>F)\n#> Residuals 99 1050.4  10.611\ncbind(mydata$Condition_1, mydata$Condition_2, mydata$Condition_3)  %*% M\n#>         diff\n#>   [1,]  2.09\n#>   [2,]  4.89\n#>   [3,]  9.21\n#>   [4,]  3.01\n#>   [5,]  6.91\n#>   [6,]  4.27\n#>   [7,]  2.49\n#>   [8,] -0.46\n#>   [9,]  1.61\n#>  [10,] -0.56\n#>  [11,]  6.49\n#>  [12,]  5.87\n#>  [13,] 11.65\n#>  [14,]  4.79\n#>  [15,]  2.19\n#>  [16,]  5.87\n#>  [17,]  4.50\n#>  [18,]  2.23\n#>  [19,]  2.66\n#>  [20,]  7.87\n#>  [21,]  6.80\n#>  [22,]  1.73\n#>  [23,] -0.75\n#>  [24,]  7.66\n#>  [25,]  3.34\n#>  [26,]  0.42\n#>  [27,]  6.81\n#>  [28,]  2.71\n#>  [29,] -1.54\n#>  [30,]  5.53\n#>  [31,]  4.74\n#>  [32,]  6.16\n#>  [33,]  8.93\n#>  [34,] 10.51\n#>  [35,]  7.14\n#>  [36,]  5.77\n#>  [37,]  4.87\n#>  [38,]  8.87\n#>  [39,]  8.78\n#>  [40,]  0.44\n#>  [41,]  4.03\n#>  [42,]  9.32\n#>  [43,]  0.11\n#>  [44,]  1.43\n#>  [45,] 10.19\n#>  [46,]  7.97\n#>  [47,]  4.75\n#>  [48,]  6.75\n#>  [49,]  1.87\n#>  [50,]  9.17\n#>  [51,]  9.55\n#>  [52,]  4.14\n#>  [53,] -1.70\n#>  [54,]  0.85\n#>  [55,]  4.70\n#>  [56,]  8.24\n#>  [57,]  6.97\n#>  [58,]  9.54\n#>  [59,]  7.95\n#>  [60,]  6.85\n#>  [61,] 12.92\n#>  [62,]  6.88\n#>  [63,]  3.12\n#>  [64,] -1.61\n#>  [65,]  3.10\n#>  [66,]  5.08\n#>  [67,]  6.64\n#>  [68,]  6.63\n#>  [69,]  5.16\n#>  [70,] -0.41\n#>  [71,]  1.27\n#>  [72,]  0.80\n#>  [73,]  6.27\n#>  [74,]  9.37\n#>  [75,]  1.12\n#>  [76,]  6.27\n#>  [77,]  0.33\n#>  [78,]  5.29\n#>  [79,]  4.01\n#>  [80,]  6.60\n#>  [81,]  3.61\n#>  [82,]  8.23\n#>  [83,]  5.25\n#>  [84,]  4.47\n#>  [85,]  5.21\n#>  [86,]  7.58\n#>  [87,]  2.91\n#>  [88,]  5.98\n#>  [89,]  0.66\n#>  [90,] 11.40\n#>  [91,]  6.34\n#>  [92,]  3.30\n#>  [93,]  3.35\n#>  [94,]  5.69\n#>  [95,]  2.83\n#>  [96,]  5.30\n#>  [97,] -0.79\n#>  [98,]  4.31\n#>  [99,]  5.41\n#> [100,]  5.28\n# Contrast \"Condition_3\" vs the average between \"Condition_1\" and \"Condition_2\"\ndiff = c(-0.5,-0.5,1)\nM = cbind(diff)\nmymodel = lm(cbind(Condition_1, Condition_2, Condition_3) %*% M ~ 1, data = mydata)\nanova(mymodel)\n#> Analysis of Variance Table\n#> \n#> Response: cbind(Condition_1, Condition_2, Condition_3) %*% M\n#>           Df Sum Sq Mean Sq F value Pr(>F)\n#> Residuals 99 2616.2  26.426\n# Contrast all\ndiff1 = c(1,-1,0)\ndiff2 = c(1,0,-1)\nM = cbind(diff1, diff2)\nmymodel = lm(cbind(Condition_1, Condition_2, Condition_3) %*% M ~ 1, data = mydata)\nanova(mymodel, test=\"Wilks\")\n#> Analysis of Variance Table\n#> \n#>             Df    Wilks approx F num Df den Df    Pr(>F)\n#> (Intercept)  1 0.093849   473.11      2     98 < 2.2e-16\n#> Residuals   99                                          \n#>                \n#> (Intercept) ***\n#> Residuals      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"practical-example-manova-two-outcome-variables","chapter":"7 Anova","heading":"7.4.1 Practical example Manova: two outcome variables","text":"Let’s introduce case two outcomes variables. Suppose receive data (quasi) experimental study. Participants went two conditions, condition_X condition_Y two three levels, respectively. addition, participants’ gender used predictor outcome.Like always transform wide format aggregate outcome across condition_X condition_Y.Given outcome (spreaded two variables) predictor can test several things:\n1. Main effects outcomes\n2. Interaction effects outcomes\n3. Main effect predictor\n4. Interaction effects outcomes predictorIn remainder part, show test objectives way one go (without outcome contrast matrix).First things first, fit multivariate linear regression without contrast matrix extract coefficients know place .Alright, notice condition_X’s “absent” level spread across condition_Y’s low, medium, high levels. goes condition_X’s “present” level. Now, want test main effect condition_X outcome need look intercept. Specifically, need test whether difference condition_X’s “absent” level statistically significantly different “present” level. use following outcome contrast matrix.\ntold , intercept show main effect condition_X gender? Well can considered interaction effect gender condition_X outcome, estimated main effect interaction effect.Good, onto condition_Y three levels “low”, “medium”, “high” spread across two levels condition_X. main effect difference levels nuance need two three potential contrasts. know low levels statistically significantly different medium levels low levels statistically significantly different high levels, medium levels statistically significantly different high levels.\n, intercept shows main effect gender show interaction condition_Y.can also look interaction outcome variables. words, difference condition_X’s “absent” “present” levels, different levels condition_y? make outcome contrast matrix interactions within outcome variables, typically mirror values (“1” “-1”) shown .intercepts shows interaction effect, gender now shows three-way interaction outcome_X, outcome_Y.Now, want look main effect gender (.e., separate variables)? exception sum values within outcome contrast matrix zero. Specifically, set values 1/6 average prediction gender outcome variables.end part neat trick. without single (outcome) contrast matrix? needed called idata idesign. idata simple data frame object specify variables contained within conjoined outcome (condition_X condition_Y). essence recreate following data set:\n","code":"\nset.seed(112358)\noptions(contrasts = c(\"contr.sum\", \"contr.sum\"))\nn_ID = 120  # Increase number of IDs\nn_rep = 60  # Repetitions per ID\ntot = n_ID * n_rep  # Total number of rows\n\nmydata = data.frame(\n  ID = rep(1:n_ID, each = n_rep),\n  outcome = runif(tot, 500, 1000),\n  condition_X = rep(c(\"absent\", \"present\"), each = n_rep/2, times = n_ID),\n  condition_Y = rep(rep(c(\"low\", \"medium\", \"high\"), each = n_rep/6), times = 2 * n_ID),\n  gender = rep(c(\"males\", \"female\") , each = 3600)\n)\n\n# Long to wide\nlibrary(reshape2)\nmydata = dcast(data = mydata, ID + gender ~ condition_X + condition_Y, value.var = \"outcome\", fun.aggregate = mean)\nnames(mydata)[3:ncol(mydata)] = c(\"abs_l\", \"abs_m\", \"abs_h\", \"pres_l\",\"pres_m\",\"pres_h\")\nmymodel = lm( cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) ~ gender , data = mydata )\ncoef(mymodel)\n#>                   abs_l     abs_m       abs_h      pres_l\n#> (Intercept) 749.1389449 752.36649 748.6051946 746.4309883\n#> gender1      -0.0984652   2.10392   0.4240033   0.6321018\n#>                  pres_m    pres_h\n#> (Intercept) 749.1050034 751.80796\n#> gender1       0.8787361   7.01653\ndiff = c(1, 1, 1, -1, -1, -1)\nM = cbind(diff)\nmymodel = lm( cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) %*% M ~ gender , data = mydata )\nAnova(mymodel, type=\"III\", test=\"F\")\n#> Anova Table (Type III tests)\n#> \n#> Response: cbind(abs_l, abs_m, abs_h, pres_l, pres_m, pres_h) %*% M\n#>              Sum Sq  Df F value Pr(>F)\n#> (Intercept)     919   1  0.0860 0.7698\n#> gender         4462   1  0.4178 0.5193\n#> Residuals   1260382 118\n# Main effect\ndiff1 = c( 1, -1, 0, 1, -1, 0 ) # low vs medium\ndiff2 = c( 1, 0, -1, 1, 0, -1 ) # low vs high\nM = cbind(diff1, diff2)\nmymodel = lm( cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) %*% M ~ gender , data = mydata )\nAnova(mymodel, type=\"III\", test=\"Wilks\") # Just for demonstration purposes I switch the test statistic\n#> \n#> Type III MANOVA Tests: Wilks test statistic\n#>             Df test stat approx F num Df den Df Pr(>F)\n#> (Intercept)  1   0.99582  0.24555      2    117 0.7827\n#> gender       1   0.99511  0.28725      2    117 0.7509\n# Interaction and three-way interaction\ndiff1 = c( 1, -1, 0, 1, -1, 0 ) # high vs low\ndiff2 = c( 0, 1, -1, 0, -1, 1 ) # high vs medium\nM = cbind(diff1, diff2)\nmymodel = lm( cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) %*% M ~ gender , data = mydata )\nAnova(mymodel, type=\"III\", test=\"Hotelling-Lawley\") # Just for demonstration purposes I switch the test statistic\n#> \n#> Type III MANOVA Tests: Hotelling-Lawley test statistic\n#>             Df test stat approx F num Df den Df Pr(>F)\n#> (Intercept)  1 0.0108108  0.63243      2    117 0.5331\n#> gender       1 0.0094164  0.55086      2    117 0.5779\ndiff = c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6 ) # high vs low\nM = diff\nmymodel = lm( cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) %*% M ~ gender , data = mydata )\naov(mymodel, test=\"F\") \n#> Warning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n#>  extra argument 'test' will be disregarded\n#> Call:\n#>    aov(formula = mymodel, test = \"F\")\n#> \n#> Terms:\n#>                   gender Residuals\n#> Sum of Squares    400.17  49919.47\n#> Deg. of Freedom        1       118\n#> \n#> Residual standard error: 20.56809\n#> Estimated effects are balanced\ncondition_X = factor(   rep(c(\"absent\",\"present\"), each = 3), levels = c(\"absent\",\"present\")   )\ncondition_Y = factor(   rep(c(\"low\",\"medium\", \"high\"), times = 2), levels = c(\"low\",\"medium\", \"high\")   )\n\nidata = data.frame( condition_X, condition_Y )\n\nmymodel = lm(cbind(  abs_l, abs_m, abs_h, pres_l, pres_m, pres_h ) ~ gender, data=mydata )\nAnova(mymodel, type=\"III\", idata=idata, idesign=~condition_X*condition_Y, test=\"Wilks\")\n#> \n#> Type III Repeated Measures MANOVA Tests: Wilks test statistic\n#>                                Df test stat approx F num Df\n#> (Intercept)                     1   0.00074   159377      1\n#> gender                          1   0.99205        1      1\n#> condition_X                     1   0.99927        0      1\n#> gender:condition_X              1   0.99647        0      1\n#> condition_Y                     1   0.99582        0      2\n#> gender:condition_Y              1   0.99511        0      2\n#> condition_X:condition_Y         1   0.99340        0      2\n#> gender:condition_X:condition_Y  1   0.99146        1      2\n#>                                den Df Pr(>F)    \n#> (Intercept)                       118 <2e-16 ***\n#> gender                            118 0.3327    \n#> condition_X                       118 0.7698    \n#> gender:condition_X                118 0.5193    \n#> condition_Y                       117 0.7827    \n#> gender:condition_Y                117 0.7509    \n#> condition_X:condition_Y           117 0.6790    \n#> gender:condition_X:condition_Y    117 0.6056    \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"anova.html","id":"referred-article-1","chapter":"7 Anova","heading":"7.5 Referred article","text":"(see section concerning effect sizes):\nBrysbaert, M., & Debeer, D. (2025). Run Linear Mixed Effects Analysis Pairwise Comparisons? Tutorial Proposal Calculation Standardized Effect Sizes. Journal cognition, 8(1), 5. https://doi.org/10.5334/joc.409","code":""},{"path":"structural-equation-modelling-and-mediation.html","id":"structural-equation-modelling-and-mediation","chapter":"8 Structural Equation Modelling and mediation","heading":"8 Structural Equation Modelling and mediation","text":"Structural Equation Modelling (SEM) can used test hypotheses relations latent observed (least measured way) variables. already seen SEM action discussing confirmatory factor analysis now want end guide briefly talking mediation. part discussThe basic mediation using lavaan packageHow visualize results mediation using semPlot packageThe moderated mediation categorical continuous moderators.","code":""},{"path":"structural-equation-modelling-and-mediation.html","id":"basic-mediation","chapter":"8 Structural Equation Modelling and mediation","heading":"8.1 Basic mediation","text":"heard spurious correlations arise correlate everything everything? classic textbook example positive correlation ice cream consumption drowning. course, correlation causation. typical “direct” relation outcome predictor, can represented correlation coefficient regression coefficient.\nice cream consumption (predictor) relates drowning (outcome)? reason relation likely brought indirect relations. Ice cream consumption related another variable, mediator, mediator relate drowning. “indirect pathways”, ice cream consumption may appear associated drowning. common explanation tend eat ice cream hot. Hot weather can increase susceptibiliy heatstroke symptoms (mediator). experience heatstroke symptoms go swim… unfortunate outcomes may occurMediation analysis allows us test extent (direct) relation variables can explained (indirect) relations variables. confuse mediation moderation, examines whether strength association depends variables. learn mediation, typically encounter “triangle” (trapezium, whatever prefer):\nnoticed talk lot “direct” “indirect” relations? direct relation (henceforth referred direct effect) relation predictor(s) outcome adjusting mediator (denote using beta coefficients). Indirect effects relation predictor outcome mediator consists two parts. First association predictor mediator. Second association mediatior outcome. goal determine extent mediator explains direct relation predictor outcome.continue, want address common misconception. time writing guide, mediation analysis confirm causal relations. Causality methodological issue. advice look properly(!) randomized properly(!) controlled experimental designs causal inference.","code":""},{"path":"structural-equation-modelling-and-mediation.html","id":"basic-example","chapter":"8 Structural Equation Modelling and mediation","heading":"8.2 Basic example","text":"mediation analysis typically involves two steps. First, like confirmatory factor analysis, specify variables relations model structure (SEM model structure)., need specify indirect, direct, optionally total effects, discuss later .Second, estimate model based SEM model structure.made simple dataset took liberty load lavaan package.essence, need model regressions define direct effect indirect effect.\nNotice three regressions: predictor -> outcome, predictor -> mediator, mediator -> outcome. direct “effect” reflects relation predictor -> outcome. regression coefficient β(PO). convention many work, call regression coefficient “c”. indirect effect product two regression coefficients: β(PM) predictor -> mediator regression (hencefort called “”), β(MO) mediator -> outcome regression (“b”). want, can also define total “effect” sum direct indirect effect.Note within SEM model structure, use letters ,b, c, represent three regression coefficients. use letters give regression coefficients name can use compute ()direct total effects (e.g., c*predictor name regression coefficient β(MO) “c”).Now use feed sem() function lavaan. also ask bootstrap simulations important obtaining reliable confidence intervals mediation analysis. Note set number bootstrap simulations 5 just demonstration purpose. However, consider (e.g., 500 ).Summary output time. focus three defined parameters. Indirect, mentioned , reflects model’s estimated “effect” predictor outcome mediator. words, mediation effect. direct, shows relation predictor outcome accounting mediator. total formula-wise sum indirect direct estimated “effects” total impact predictor outcome.example, report mediation (indirect effect) statistically significant (based p value) whereas estimated direct “effect” . words, predictor statistically significantly relates outcome mediator. people describe case “full” mediation label “partial” mediation case direct effect also statistically significant.Let’s return back R code, can also obtain (standardized) estimated parameters using parameterEstimates() function.However, confidence intervals may use bootstrapped solutions accurate (percentile) confidence intervals, can use standardized_Solution_boot_ci() function semhelpinghands package.","code":"\nlibrary(pacman)\np_load(lavaan)  \n\nset.seed(54321)\nn = 250  # Sample size\ncor_Y_X = 0.5 # correlation between outcome Y and predictor X \ncor_Y_M = 0.6 # correlation between outcome Y and mediator M\ncor_X_M = 0.7 # correlation between predictor X and mediator M\n\npredictor = rnorm(n, mean = 20, sd = 5) # Create the predictor\nmediator = rnorm(n, mean = 15, sd = 3) + (predictor * cor_X_M) # Create a mediator that is associated with the above predictor \n\nmydata = data.frame(\n  predictor = predictor,\n  mediator = mediator, \n  outcome = rnorm(n, mean = 25, sd = 7) + (mediator * cor_Y_M) + (predictor * cor_Y_X) # Outcome that is associated with both the predictor and mediator\n)\nmystructure = '\n\n# Regression outcome - predictor\n\n  outcome ~ c*predictor # with c being the regression coefficient between the two, beta(PM) in my figure\n  \n# Indirect relation:\n\n  mediator ~ a*predictor # with a being the regression coefficient, beta(PM)\n  outcome ~ b*mediator # \n  \n  # Alternatively you can redo the above like (without the # of course)\n    # outcome ~ b*mediator + c*predictor\n    # mediator ~ a*predictor\n    \n# The above is needed to compute indirect \n\nindirect := a*b\ndirect := c\ntotal := (a*b) + c\n\n'\nmymodel=sem(mystructure,data=mydata, se = \"bootstrap\", iseed=1234, bootstrap = 5) # I take 5 bootstrap simulation but consider 500+ when doing it for real \n#> Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING:\n#>     The variance-covariance matrix of the estimated parameters (vcov)\n#>     does not appear to be positive definite! The smallest eigenvalue\n#>     (= 8.463702e-17) is close to zero. This may be a symptom that the\n#>     model is not identified.\nsummary(mymodel,standardized=TRUE)\n#> lavaan 0.6.16 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         5\n#> \n#>   Number of observations                           250\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 0.000\n#>   Degrees of freedom                                 0\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                            Bootstrap\n#>   Number of requested bootstrap draws                5\n#>   Number of successful bootstrap draws               5\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   outcome ~                                           \n#>     predictor  (c)    0.230    0.122    1.885    0.059\n#>   mediator ~                                          \n#>     predictor  (a)    0.644    0.033   19.351    0.000\n#>   outcome ~                                           \n#>     mediator   (b)    0.760    0.148    5.121    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.230    0.140\n#>                   \n#>     0.644    0.713\n#>                   \n#>     0.760    0.417\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .outcome          47.380    5.939    7.977    0.000\n#>    .mediator          9.689    0.684   14.163    0.000\n#>    Std.lv  Std.all\n#>    47.380    0.723\n#>     9.689    0.491\n#> \n#> Defined Parameters:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>     indirect          0.490    0.113    4.334    0.000\n#>     direct            0.230    0.136    1.686    0.092\n#>     total             0.720    0.033   22.118    0.000\n#>    Std.lv  Std.all\n#>     0.490    0.297\n#>     0.230    0.140\n#>     0.720    0.437\nparameterEstimates(mymodel, standardized = TRUE)\n#>         lhs op       rhs    label    est    se      z\n#> 1   outcome  ~ predictor        c  0.230 0.122  1.885\n#> 2  mediator  ~ predictor        a  0.644 0.033 19.351\n#> 3   outcome  ~  mediator        b  0.760 0.148  5.121\n#> 4   outcome ~~   outcome          47.380 5.939  7.977\n#> 5  mediator ~~  mediator           9.689 0.684 14.163\n#> 6 predictor ~~ predictor          24.160 0.000     NA\n#> 7  indirect :=       a*b indirect  0.490 0.113  4.334\n#> 8    direct :=         c   direct  0.230 0.136  1.686\n#> 9     total :=   (a*b)+c    total  0.720 0.033 22.118\n#>   pvalue ci.lower ci.upper std.lv std.all std.nox\n#> 1  0.059   -0.006    0.365  0.230   0.140   0.028\n#> 2  0.000    0.600    0.697  0.644   0.713   0.145\n#> 3  0.000    0.560    0.986  0.760   0.417   0.417\n#> 4  0.000   36.165   53.789 47.380   0.723   0.723\n#> 5  0.000    8.815   10.709  9.689   0.491   0.491\n#> 6     NA   24.160   24.160 24.160   1.000  24.160\n#> 7  0.000    0.369    0.669  0.490   0.297   0.060\n#> 8  0.092   -0.006    0.365  0.230   0.140   0.028\n#> 9  0.000    0.663    0.734  0.720   0.437   0.089\nlibrary(semhelpinghands)\nstandardizedSolution_boot_ci(mymodel)\n#>         lhs op       rhs    label est.std    se      z\n#> 1   outcome  ~ predictor        c   0.140 0.079  1.769\n#> 2  mediator  ~ predictor        a   0.713 0.022 31.727\n#> 3   outcome  ~  mediator        b   0.417 0.074  5.611\n#> 4   outcome ~~   outcome            0.723 0.033 21.637\n#> 5  mediator ~~  mediator            0.491 0.032 15.333\n#> 6 predictor ~~ predictor            1.000 0.000     NA\n#> 7  indirect :=       a*b indirect   0.297 0.051  5.791\n#> 8    direct :=         c   direct   0.140 0.079  1.769\n#> 9     total :=   (a*b)+c    total   0.437 0.038 11.444\n#>   pvalue ci.lower ci.upper boot.ci.lower boot.ci.upper\n#> 1  0.077   -0.015    0.294        -0.004         0.248\n#> 2  0.000    0.669    0.757         0.669         0.730\n#> 3  0.000    0.271    0.563         0.347         0.555\n#> 4  0.000    0.658    0.789         0.693         0.787\n#> 5  0.000    0.429    0.554         0.467         0.552\n#> 6     NA    1.000    1.000            NA            NA\n#> 7  0.000    0.197    0.398         0.251         0.399\n#> 8  0.077   -0.015    0.294        -0.004         0.248\n#> 9  0.000    0.362    0.512         0.394         0.499\n#>   boot.se\n#> 1   0.091\n#> 2   0.026\n#> 3   0.085\n#> 4   0.040\n#> 5   0.036\n#> 6      NA\n#> 7   0.059\n#> 8   0.091\n#> 9   0.045"},{"path":"structural-equation-modelling-and-mediation.html","id":"visualize-your-path-diagrams","chapter":"8 Structural Equation Modelling and mediation","heading":"8.2.1 Visualize your : path diagrams","text":"Using summary() output, use estimated parameters make plots, context mediation, path diagrams. However, also consider use ^packages like semPlot work . Basically, recreate “triangle” now add estimates β(PM), β(MO), β(PM). experience, take bit knowledge make path diagrams look aesthetically pleasing. Allow guide .first concern figure put labels variables. “predictor”, “mediator”, “outcome” placed. prefer predictor placed left, outcome right, mediator middle top. tell semPlot use layout, create matrix contains position variables (see R code chunk). can use semPaths() function make path diagrams.Now, want, can also add notifications significance (asterisks) (standardized) estimates. , need extract p values estimates. Since want plot standardized estimates, need extract standardized estimates. can done using aforementioned parameterEstimates() function.Using p values now () transform significance notifications (b) glue original estimates. first step “value asterisk” make function checks p value determines whether asign , one, two, three asterisk actually apply function p values glue asterixes (lack thereoff) standardized estimates.looks like.","code":"\nlibrary(semPlot)\n\n# To determine the location of the labels:\n  my_layout <- matrix(c(\n    1, 0,   # To put the variable \"predictor\" to the RIGHT side and at the BOTTOM\n    0.5, 1,   # Put the \"mediator\" in the MIDDLE at the TOP\n    0, 0   # Put the \"outcome\" at the left side and at the BOTTOM\n  ), byrow = TRUE, ncol = 2)\n\n# Create the path diagram\nsemPaths(mymodel, \n         what = \"std\",  # I want to use the standardized estimates\n         layout = my_layout,  # Use our above custom layout\n         edge.label.cex = 1.3,  # Set the font size for the estimates\n         label.cex = 1.2, # Set the font size for the labels (\"predictor\", \"mediator\", etc.)\n         sizeMan = 15,  # Set the sizes of the boxes\n         fade = FALSE, # TRUE will create make the larger estimates also thicker\n         residuals = FALSE,  # Hide residual variances of the variables\n         edge.color = \"black\",  # Determine the color for the arrows (\"edges\")\n         nCharNodes = 0  # If Set to zero, it will display the full variable name instead of shorten it down\n)\n# Alright we need to acquire the estimates and corresponding p value\nparameter_estimates = parameterEstimates(mymodel, standardized = TRUE)\n\n# For our plot we only need the parameters for the a,b, and c-path so here I make sure to exclusive include these three\nparameter_estimates = parameter_estimates[parameter_estimates$op == \"~\", ]\n\n# Now we can translate these p values into significance labels, the famous asteriks (*, **, ***)\n# To do so, I will create a function to add asterisks based on p value\n\nadd_stars = function(p) { # This function will take the p-value and determines what sign it should attribute to it (i.e., the number of asterix)\n  \n  # Functions are beyond of the scope of this guide\n  # However, functions apply anything contained within the function to whatever argument you feed it (here the argument called \"p\")\n  # So my function checks the value of the p value, and determines whether to transform it into a given number of asterisks or nothing\n  \n  \n  if (is.na(p)) return(\"\")  # If the p value is NA, empty, return an empty string\n  else if (p < 0.001) return(\"***\") # If the p-value is below .001 then return ***\n  else if (p < 0.01) return(\"**\")\n  else if (p < 0.05) return(\"*\")\n  else return(\"\") # If the p-value is 0.05 or larger then do not add an asterisk\n}\n\n\n# Alright I want to put the label and the asterisk on my path diagram (e.g., \"0.71***\") so I will need to glue them together\nparameter_estimates$label = paste0(\n  round(parameter_estimates$std.all, 2), # round the estimates to two decimals\n  sapply(parameter_estimates$pvalue, add_stars) # apply the \"p value to asterisks\" function\n)\n\n# Finally, our path diagram with significance asterisks\nsemPaths(mymodel, \n         what = \"std\",  # I want to use the standardized estimates\n         layout = my_layout,  # Use our above custom layout\n         edge.label.cex = 1.3,  # Set the font size for the estimates\n         label.cex = 1.2, # Set the font size for the labels (\"predictor\", \"mediator\", etc.)\n         sizeMan = 15,  # Set the sizes of the boxes\n         fade = FALSE, \n         residuals = FALSE,  # Hide residual variances of the variables\n         edge.color = \"black\",  # Determine the color for the arrows (\"edges\")\n         nCharNodes = 0, # If Set to zero, it will display the full variable name instead of shorten it down\n         edgeLabels = parameter_estimates$label)  # Apply the significance labels (estimate + asterixes)"},{"path":"structural-equation-modelling-and-mediation.html","id":"moderated-mediation","chapter":"8 Structural Equation Modelling and mediation","heading":"8.3 Moderated mediation","text":"mediation relation (extent mediation, variance explained mediator) depends level yet another variable “moderator”? Recall three relations reflected three beta’s. moderator can moderate three relations. Let’s start simple situation one relation (say -path) moderated categorical variable. Crucially, need compute include interaction dataset (just predictor multiplied moderator) lavaan accept something like “predictor:moderator” unlike linear regression models.repeat steps now need remember need add moderator relation predictor mediator. Specifically, mediator now analytically predicted predictor (main effect), interaction term moderator predictor, customary include interactions, moderator (main effect) . now three beta’s (two main effects, one interaction term) link acknowledge. original “-path” now become a1 (say main effect predictor), a2 (say main effect moderator), a3(say interaction term). acknowledge define regressions within SEM structure.now, inclusion moderator two repercussions need compute indirect effect. First, original “* b” formula suffice anymore multiple ’s. “” original formula changes a1 + a3 main effect predictor interaction term predictor moderator. incomplete, indirect effect now dependent values moderator, brings us second point. compute indirect effect value moderator something, indirect effect value something else. Since moderator binary factor, can just compute indirect effect moderator zero also moderator one. final formula becomes a1 + (a3 * 0) * b moderator zero a1 + (a3 * 1) * b, moderator one.Finally, want include total effect, becomes also different across values moderator. total effect moderator zero, total effect moderator one.Let us implement SEM structure object.Like can make path diagram using semPaths() function semPlot package. Remember made layout determine labels placed? Now additional labels can determine position want. nothing notably changes .","code":"\nset.seed(54321)\nn = 250  # Sample size\ncor_Y_X = 0.5 # correlation between outcome Y and predictor X \ncor_Y_M = 0.6 # correlation between outcome Y and mediator M\ncor_X_M = 0.7 # correlation between predictor X and mediator M\n\n\npredictor = rnorm(n, mean = 20, sd = 5) # Create the predictor\nmediator = rnorm(n, mean = 15, sd = 3) + (predictor * cor_X_M) # Create a mediator that is associated with the above predictor \nmoderator = rep(c(0,1), times=125)\n\n\nmydata = data.frame(\n  predictor = predictor,\n  mediator = mediator, \n  outcome = rnorm(n, mean = 25, sd = 7) + (mediator * cor_Y_M) + (predictor * cor_Y_X), # Outcome that is associated with both the predictor and mediator\n  moderator = moderator,\n  interaction_predictor_moderator = moderator * predictor\n  )\nmystructure = '\n\n# Direct relation\n\n  outcome ~ c*predictor\n  \n# Indirect relation:\n\n  mediator ~ a1*predictor + a2*moderator + a3*interaction_predictor_moderator # Again, you need to compute and include the interaction in your dataset and use that\n  outcome ~ b*mediator\n\n# The indirect \n\nindirect_0 := (a1 + (a3*0)) * b # when the moderator is zero\nindirect_1 := (a1 + (a3*1)) * b # when the moderator is one\ndirect := c\ntotal_0 := indirect_0 + c # when the moderator is zero (also \"c\" can be changed to \"direct\" if you want)\ntotal_1 := indirect_1 + c # when the moderator is one\n'\n\nmymodel=sem(mystructure,data=mydata, se = \"bootstrap\", iseed=1234, bootstrap = 5) # Again I take 5 but consider 500+ when doing it for real \nsummary(mymodel,standardized=TRUE)\n#> lavaan 0.6.16 ended normally after 1 iteration\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                         7\n#> \n#>   Number of observations                           250\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                                 0.787\n#>   Degrees of freedom                                 2\n#>   P-value (Chi-square)                           0.675\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                            Bootstrap\n#>   Number of requested bootstrap draws                5\n#>   Number of successful bootstrap draws               5\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   outcome ~                                           \n#>     predictor  (c)    0.230    0.122    1.885    0.059\n#>   mediator ~                                          \n#>     predictor (a1)    0.696    0.048   14.510    0.000\n#>     moderator (a2)    1.546    1.589    0.973    0.331\n#>     intrctn__ (a3)   -0.093    0.068   -1.359    0.174\n#>   outcome ~                                           \n#>     mediator   (b)    0.760    0.148    5.121    0.000\n#>    Std.lv  Std.all\n#>                   \n#>     0.230    0.140\n#>                   \n#>     0.696    0.770\n#>     1.546    0.174\n#>    -0.093   -0.226\n#>                   \n#>     0.760    0.417\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .outcome          47.380    5.939    7.977    0.000\n#>    .mediator          9.618    0.716   13.425    0.000\n#>    Std.lv  Std.all\n#>    47.380    0.723\n#>     9.618    0.488\n#> \n#> Defined Parameters:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>     indirect_0        0.529    0.122    4.329    0.000\n#>     indirect_1        0.458    0.106    4.316    0.000\n#>     direct            0.230    0.136    1.686    0.092\n#>     total_0           0.759    0.042   18.263    0.000\n#>     total_1           0.688    0.050   13.744    0.000\n#>    Std.lv  Std.all\n#>     0.529    0.321\n#>     0.458    0.227\n#>     0.230    0.140\n#>     0.759    0.461\n#>     0.688    0.367\nlibrary(semPlot)\nmy_layout = matrix(c(\n  3, 0,   # Predictor (bottom right)\n  1.5, 3,   # Mediator (middle top)\n  0, 0,   # Outcome (bottom left)\n  0.1, 3,   # Moderator (top right)\n  1.25, -0.75 # Interaction (middle right)\n), byrow = TRUE, ncol = 2)\n\n# Create the path diagram\nsemPaths(mymodel, \n         what = \"std\",  # Standardized estimates\n         layout = my_layout,  # Updated layout\n         edge.label.cex = 1.3,  # Font size for estimates\n         label.cex = 1.2,  # Font size for variable labels\n         sizeMan = 15,  # Size of the boxes\n         fade = FALSE, \n         residuals = FALSE,  # Hide residual variances\n         edge.color = \"black\",  # Arrow color\n         nCharNodes = 0,  # Show full variable names\n         intercepts = FALSE)  # Hide intercepts for clarity"},{"path":"structural-equation-modelling-and-mediation.html","id":"on-all-pathways","chapter":"8 Structural Equation Modelling and mediation","heading":"8.3.1 On all pathways","text":"decide theory moderation plausible pathways? case different , just need adjust linear regressions. Note however, need a2 * moderator b2 * moderator, one two (). indirect effect remains now need adjust formula. () change lies direct effect now two forms: moderator value 0 value 1. Remember compute include interaction term every path way dataset use within SEM structure object.\n","code":"\nset.seed(54321)\nn = 250  # Sample size\ncor_Y_X = 0.5 # correlation between outcome Y and predictor X \ncor_Y_M = 0.6 # correlation between outcome Y and mediator M\ncor_X_M = 0.7 # correlation between predictor X and mediator M\n\n\npredictor = rnorm(n, mean = 20, sd = 5) # Create the predictor\nmediator = rnorm(n, mean = 15, sd = 3) + (predictor * cor_X_M) \nmoderator = rep(c(0,1), times=125)\n\n\nmydata = data.frame(\n  predictor = predictor,\n  mediator = mediator, \n  outcome = rnorm(n, mean = 25, sd = 7) + (mediator * cor_Y_M) + (predictor * cor_Y_X), # Outcome that is associated with both the predictor and mediator\n  moderator = moderator,\n  interaction_predictor_moderator = moderator * predictor,\n  interaction_mediator_outcome = mediator * moderator,\n  interaction_predictor_outcome = predictor * moderator\n  )\n\nmystructure = '\n\n# Direct relation\n\n  outcome ~ c1*predictor + c2*moderator + c3*interaction_predictor_outcome\n  \n# Indirect relation:\n\n  mediator ~ a1*predictor + a2*moderator + a3*interaction_predictor_moderator\n  outcome ~ b1*mediator + b3*interaction_mediator_outcome # Note that there is no need for a b2*moderator term as this is captued in a2*moderator\n\n# indirect, direct, and total effects\n\nindirect_0 := (a1 + (a3*0)) * (b1 + (b3*0)) # when the moderator is zero\nindirect_1 := (a1 + (a3*1)) * (b1 + (b3*1)) # when the moderator is one\n\ndirect_0 := c1 + (c3*0)\ndirect_1 := c1 + (c3*1)\n\ntotal_0 := indirect_0 + direct_0 \ntotal_1 := indirect_1 + direct_1  \n'\n\nmymodel=sem(mystructure,data=mydata, se = \"bootstrap\", iseed=1234, bootstrap = 5) # I take 5 bootstrap simulation but consider 500+ when doing it for real \nsummary(mymodel,standardized=TRUE)\n#> lavaan 0.6.16 did not run (perhaps do.fit = FALSE)?\n#> ** WARNING ** Estimates below are simply the starting values\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        10\n#> \n#>   Number of observations                           250\n#> \n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                            Bootstrap\n#>   Number of requested bootstrap draws                5\n#>   Number of successful bootstrap draws               0\n#> \n#> Regressions:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>   outcome ~                                           \n#>     predictor (c1)    0.339       NA                  \n#>     moderator (c2)   -0.251       NA                  \n#>     intrctn__ (c3)   -0.181       NA                  \n#>   mediator ~                                          \n#>     predictor (a1)    0.696       NA                  \n#>     moderator (a2)    1.546       NA                  \n#>     intrctn__ (a3)   -0.093       NA                  \n#>   outcome ~                                           \n#>     mediator  (b1)    0.694       NA                  \n#>     intrctn__ (b3)    0.113       NA                  \n#>    Std.lv  Std.all\n#>                   \n#>     0.339    0.207\n#>    -0.251   -0.016\n#>    -0.181   -0.244\n#>                   \n#>     0.696    0.770\n#>     1.546    0.174\n#>    -0.093   -0.226\n#>                   \n#>     0.694    0.383\n#>     0.113    0.209\n#> \n#> Variances:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>    .outcome          47.201       NA                  \n#>    .mediator          9.618       NA                  \n#>    Std.lv  Std.all\n#>    47.201    0.729\n#>     9.618    0.488\n#> \n#> Defined Parameters:\n#>                    Estimate  Std.Err  z-value  P(>|z|)\n#>     indirect_0        0.483                           \n#>     indirect_1        0.487                           \n#>     direct_0          0.339                           \n#>     direct_1          0.158                           \n#>     total_0           0.822                           \n#>     total_1           0.645                           \n#>    Std.lv  Std.all\n#>     0.483    0.295\n#>     0.487    0.322\n#>     0.339    0.207\n#>     0.158   -0.037\n#>     0.822    0.502\n#>     0.645    0.285"},{"path":"structural-equation-modelling-and-mediation.html","id":"using-a-continuous-moderator","chapter":"8 Structural Equation Modelling and mediation","heading":"8.3.2 Using a continuous moderator","text":"final example moderated mediation, continuous moderator moderates path “c” path “b”. encounter something seen . However, remember defined multiple ()direct effects depending values moderator? Now continuous moderator, need decide values want include many. Remind every included moderator value pair extra ()direct effects estimated, hence taxing statistical power.example include three values moderator: “low” (.e., standard deviation mean); “moderate” (mean), “high” (.e., standard deviation mean). include values within SEM model structure, add dataset beforehand compute inside SEM structure. demonstrate latter. define use mean moderator, add additional regression moderator predicted intercept without predictors (hence intercept mean). now simply give intercept name can use later (like letter ,b, c) define ()direct effects.get variance moderator, remember confirmatory factor analysis notation ~~ defines covariance within SEM model structure? Well, let moderator co-vary , get variance give name variance, can use later define ()direct effect. mean variance defined, can now define standard deviation mean. Note need take square root variance, can easily done within SEM model structure.","code":"\n\nset.seed(54321)\nn = 250  # Sample size\ncor_Y_X = 0.5 # correlation between outcome Y and predictor X \ncor_Y_M = 0.6 # correlation between outcome Y and mediator M\ncor_X_M = 0.7 # correlation between predictor X and mediator M\n\n\npredictor = rnorm(n, mean = 20, sd = 5) # Create the predictor\nmediator = rnorm(n, mean = 15, sd = 3) + (predictor * cor_X_M) # Create a mediator that is associated with the above predictor \nmoderator = rnorm(n, mean = 17, sd = 4 )\noutcome = rnorm(n, mean = 25, sd = 7) + (mediator * cor_Y_M) + (predictor * cor_Y_X)\n\n\nmydata = data.frame(\n  predictor = predictor,\n  mediator = mediator, \n  outcome = outcome, # Outcome that is associated with both the predictor and mediator\n  moderator = moderator,\n  interaction_mediator_outcome = moderator * mediator,\n  interaction_predictor_outcome = predictor * moderator\n  )\n\nmystructure = '\n\n\n# Mean and SD to be used to compute indirect and direct effect\n\n  moderator ~ moderator_mean*1 # to define and use the intercept of the moderator/the mean\n  moderator ~~ moderator_var*moderator # to define use the variance of the moderator\n\n\n# Direct relation\n\n  outcome ~ c1*predictor + c2*moderator + c3*interaction_predictor_outcome\n  \n# Indirect relation:\n\n  mediator ~ a*predictor\n  outcome ~ b1*mediator + b3*interaction_mediator_outcome # Note that there is no need for a b2*moderator term as this is captued in a2*moderator\n\n\n# indirect, direct, and total effects\n\nindirect_low := a * (b1 + b3*(moderator_mean - sqrt(moderator_var)))         # when the moderator is zero\nindirect_moderate :=  a * (b1 + (b3*moderator_mean))\nindirect_high := a * (b1 + b3*(moderator_mean + sqrt(moderator_var))) \n\ndirect_low := c1 + c3*(moderator_mean - sqrt(moderator_var))\ndirect_moderate := c1 + c3*moderator_mean\ndirect_high := c1 + c3*(moderator_mean + sqrt(moderator_var))\n\ntotal_low := indirect_low + direct_low \ntotal_moderate := indirect_moderate + direct_moderate \ntotal_high := indirect_high + direct_high\n\n'\n\nmymodel=sem(mystructure,data=mydata, se = \"bootstrap\", iseed=1234, bootstrap = 5) # I take 5 bootstrap simulation but consider 500+ when doing it for real \nsummary(mymodel,standardized=TRUE)\n#> lavaan 0.6.16 ended normally after 13 iterations\n#> \n#>   Estimator                                         ML\n#>   Optimization method                           NLMINB\n#>   Number of model parameters                        12\n#> \n#>   Number of observations                           250\n#> \n#> Model Test User Model:\n#>                                                       \n#>   Test statistic                              1502.466\n#>   Degrees of freedom                                 6\n#>   P-value (Chi-square)                           0.000\n#> \n#> Parameter Estimates:\n#> \n#>   Standard errors                            Bootstrap\n#>   Number of requested bootstrap draws                5\n#>   Number of successful bootstrap draws               5\n#> \n#> Regressions:\n#>                    Estimate   Std.Err  z-value  P(>|z|)\n#>   outcome ~                                            \n#>     predictor (c1)     1.114    0.547    2.039    0.041\n#>     moderator (c2)    -0.994    0.753   -1.321    0.186\n#>     intrctn__ (c3)    -0.044    0.034   -1.288    0.198\n#>   mediator ~                                           \n#>     predictor  (a)     0.644    0.033   19.350    0.000\n#>   outcome ~                                            \n#>     mediator  (b1)    -0.360    0.766   -0.470    0.639\n#>     intrctn__ (b3)     0.058    0.042    1.379    0.168\n#>    Std.lv   Std.all\n#>                    \n#>      1.114    0.551\n#>     -0.994   -0.398\n#>     -0.044   -0.470\n#>                    \n#>      0.644    0.713\n#>                    \n#>     -0.360   -0.161\n#>      0.058    0.783\n#> \n#> Intercepts:\n#>                    Estimate   Std.Err  z-value  P(>|z|)\n#>     modertr (mdr_)    16.663    0.211   79.066    0.000\n#>    .outcome           43.243   14.415    3.000    0.003\n#>    .mediatr           15.996    0.847   18.877    0.000\n#>    Std.lv   Std.all\n#>     16.663    4.196\n#>     43.243    4.354\n#>     15.996    3.603\n#> \n#> Variances:\n#>                    Estimate   Std.Err  z-value  P(>|z|)\n#>     modertr (mdr_)    15.772    2.083    7.570    0.000\n#>    .outcome           49.139    2.438   20.154    0.000\n#>    .mediatr            9.689    0.684   14.163    0.000\n#>    Std.lv   Std.all\n#>     15.772    1.000\n#>     49.139    0.498\n#>      9.689    0.491\n#> \n#> Defined Parameters:\n#>                    Estimate   Std.Err  z-value  P(>|z|)\n#>     indirect_low       0.238    0.205    1.163    0.245\n#>     indirect_modrt     0.386    0.098    3.916    0.000\n#>     indirect_high      0.533    0.133    4.011    0.000\n#>     direct_low         0.560    0.167    3.349    0.001\n#>     direct_moderat     0.387    0.087    4.469    0.000\n#>     direct_high        0.214    0.202    1.059    0.289\n#>     total_low          0.799    0.080   10.037    0.000\n#>     total_moderate     0.772    0.032   23.942    0.000\n#>     total_high         0.746    0.095    7.827    0.000\n#>    Std.lv   Std.all\n#>      0.238    1.669\n#>      0.386    2.228\n#>      0.533    2.786\n#>      0.560   -0.952\n#>      0.387   -1.422\n#>      0.214   -1.893\n#>      0.799    0.717\n#>      0.772    0.805\n#>      0.746    0.893"},{"path":"missing-data-and-multiple-imputation.html","id":"missing-data-and-multiple-imputation","chapter":"9 Missing data and multiple imputation","heading":"9 Missing data and multiple imputation","text":"datasets far blessing . Sure, sometimes clean, transform, process data relatively spared one common inconvenience, missing data. simply ignore values missing, ignorance potentially introduce bias estimates lead reduced statistical power. part.briefly discuss consider confronted missing data.shortly show inspect missing values. Specifically, much data missing, variables may relate missing values another variable (plotting patterns using VIM package), patterns missingness: Missing Completely Random, Missing Random, Missing Random.Finally, introduce multiple imputation procedure use demonstrate mice package, step--step.","code":""},{"path":"missing-data-and-multiple-imputation.html","id":"missing-data","chapter":"9 Missing data and multiple imputation","heading":"9.1 Missing data","text":"","code":""},{"path":"missing-data-and-multiple-imputation.html","id":"listwise-deletion-and-single-mean-imputation","chapter":"9 Missing data and multiple imputation","heading":"9.1.1 Listwise deletion and single (mean) imputation","text":"Let known, best way handle missing data put efforts avoiding first place. said, perhaps easiest option deal missing values, exclude incomplete cases (listwise deletion). example.However, depending number excluded cases, statistical power may drop notably. Moreover, create additional inconveniences unbalanced designs (e.g., notably participants one group compared others) bias estimated outcomes including inflation standard errors.short, listwise deletion ill-advised sometimes. Alternatively can also start thinking filling empty values confronted two questions. First, start filling empty values, amount missing data , consider , becomes unacceptable? question ongoing debate, hence suggestion look simulation studies related work. Second, impute data need decide fill missing values.One intuitive candidate variable’s mean. However, simply use mean, fill gaps something uninformative. addition, remember compute variance, divide differences values mean amount complete cases. Therefore, end underestimating certain extent standard errors.deal issue, can fill empty values multiple plausible values instead one . multiple imputation comes view.","code":"\nmydata = data.frame(x = c(1,2,NA,3,4,5),\n                    y = c(NA,2,3,NA,4,5)\n                    )\n\nmydata_no_NA = mydata[complete.cases(mydata), ] # To apply listwise deletion\nhead(mydata_no_NA)\n#>   x y\n#> 2 2 2\n#> 5 4 4\n#> 6 5 5"},{"path":"missing-data-and-multiple-imputation.html","id":"multiple-imputation","chapter":"9 Missing data and multiple imputation","heading":"9.2 Multiple imputation","text":"Multiple imputation, missing values imputed (.e., filled ) across multiple simulated complete datasets. can pool results inspect extent overlap simulated dataset. sounds straightforward various aspects considered. guide step--step. Let’s assume following data missing values two predictors outcome. note, missing values predictor variables imputed imputed values used later analyses (see later ) mice() function. Missing values outcome also imputed mice() function used later analyses. Note also created variable named auxiliary, relevance become clear later .","code":"\nlibrary(dplyr)\nset.seed(902)\n# Create the dataset\nn = 500\npredictor1 = rnorm(n)\npredictor2 = rnorm(n)\nauxiliary = rnorm(n)\noutcome = 0.5 * predictor1 + 0.3 * predictor2 + rnorm(n)\nmydata = data.frame(outcome, predictor1, predictor2, auxiliary)\n\n# Now, introduce missing values based on the variable  \"auxiliary\" (so that the absence of values correlates to this \"auxiliary\" variable, as explained later on)\n# Below I applied my own rule, predictors and outcomes are set NA based on the value of \"auxiliary\" (based on the quantile of its values)\n\nmydata = mydata %>% mutate(\n  across(c(\"predictor1\",\"predictor2\"),\n         ~ ifelse(auxiliary < quantile(auxiliary, 0.25), NA, .)  \n         ),\n  outcome = ifelse(auxiliary < quantile(auxiliary, 0.10), NA, outcome)\n)\nhead(mydata)\n#>      outcome predictor1 predictor2   auxiliary\n#> 1 -0.4294810   0.305674 -0.2005052  0.68156926\n#> 2  0.5090547         NA         NA -0.91705860\n#> 3 -0.3250196         NA         NA -1.04904178\n#> 4 -1.1898698  -1.394627  0.1331301  0.05551047\n#> 5  0.8797796         NA         NA -0.90291118\n#> 6  2.7468572   1.362628  0.7923936  0.22223424"},{"path":"missing-data-and-multiple-imputation.html","id":"before-mice-check-missing-values","chapter":"9 Missing data and multiple imputation","heading":"9.2.1 before mice: Check missing values","text":"Alright, begin mice function(), always good idea check much missing values . can ask questions like many missing values per variable interest whether missing values one variable related variables. missing value checking needs, like use aggr() function VIM package.left side plot see proportion missing data imagine right side requires explanation.\nvertical axis shows frequency missing pattern. can distinguish three patterns case. common one (75%) values present (colored green). next pattern (15%) missing values predictor1 predictor2 (colored red) outcome auxiliary variable. Finally, 10% cases, missing values auxiliary variable. Altogether, patterns suggests occurrence missing values clusters around auxiliary variable (always present). missing values related measured (“observed”) variables, just like case, can take indication Missing Random (MAR).","code":"\nlibrary(VIM)\naggr(mydata, col = c('red', 'green'), # Colored this way so that red will represent the missing values and green the present ones in the right side of the plot\n     numbers = TRUE,\n     sortVars = TRUE,\n     labels = names(mydata),\n     cex.axis = 0.7,\n     gap = 3,\n     ylab = c(\"Proportion of missing values\", \"Missingness Pattern\")\n)#> \n#>  Variables sorted by number of missings: \n#>    Variable Count\n#>  predictor1  0.25\n#>  predictor2  0.25\n#>     outcome  0.10\n#>   auxiliary  0.00"},{"path":"missing-data-and-multiple-imputation.html","id":"before-mice-missing-not-completely-at-random","chapter":"9 Missing data and multiple imputation","heading":"9.2.1.1 before mice: Missing (Not) (Completely) at Random","text":"MAR pattern encounter plot one three forms missingness multiple imputations assumes data missing either completely random (MCAR) least random (MAR). However, missing pattern Missing Random, may run trouble. describe pattern missingness MNAR missing values notably related variable measure (unobserved, outside dataset). run mice MNAR, may end biased outcomes.may wondering, know type missingness ? Let’s start MCAR, one common ways test type missingness use Little’s MCAR test. can done using mcar_test() function naniar package. test significant based provided p value, suggest data MCAR.Since test significant, test suggests either MAR MNAR. However, regardless outcome, advise caution interpreting test. MCAR unlikely cases missingness typically related variables. Also, like many tests, Little’s MCAR test can sensitive sample size larger samples, p values likely drop 0.05.Therefore, cases, comes either MNAR MAR. decide whether pattern missingess MAR MNAR, can visualize inspect patterns missing values like using VIM package. addition, consider fit logistic regression models missing values given variable predicted another variable. example, say want test whether occurrence missing values (yes ) predictor1 predicted predictor2.However, note test linear corelation, might miss forms association.","code":"\nlibrary(naniar)\nmcar_test(mydata)\n#> # A tibble: 1 × 4\n#>   statistic    df p.value missing.patterns\n#>       <dbl> <dbl>   <dbl>            <int>\n#> 1      294.     3       0                3\n# For demonstration purpose I temporarily make a binomial variable that indicates whether the value of predictor1 is missing or not\ntemp_mydata = mydata %>% mutate(missing_predictor1 = ifelse(is.na(predictor1),1,0))\n\n# Fit the logistic regression\noptions(scipen=999)\nsummary(\n glm(missing_predictor1 ~ predictor2, family = \"binomial\", data=temp_mydata) \n)\n#> Warning: glm.fit: algorithm did not converge\n#> \n#> Call:\n#> glm(formula = missing_predictor1 ~ predictor2, family = \"binomial\", \n#>     data = temp_mydata)\n#> \n#> Coefficients:\n#>                             Estimate\n#> (Intercept)   -26.566068523538149293\n#> predictor2     -0.000000000000004675\n#>                           Std. Error z value Pr(>|z|)\n#> (Intercept) 18390.786054817810509121  -0.001    0.999\n#> predictor2  17583.793427717431768542   0.000    1.000\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 0.0000000000000  on 374  degrees of freedom\n#> Residual deviance: 0.0000000021756  on 373  degrees of freedom\n#>   (125 observations deleted due to missingness)\n#> AIC: 4\n#> \n#> Number of Fisher Scoring iterations: 25"},{"path":"missing-data-and-multiple-imputation.html","id":"mice-decissions-joint-modeling-versus-fully-conditional-specification","chapter":"9 Missing data and multiple imputation","heading":"9.2.2 mice decissions: joint modeling versus fully conditional specification","text":"determined pattern missingness (likely) MAR multiple imputation deemed adequate procedure given number missing values.next decision decide imputation method take. multiple imputation, joint modeling assumes multivariate distribution variables used sample missing values. practice, missing values commonly sampled multivariate normal distribution. However, since categorical variable follow multivariate normal distribution, might consider go joint modeling data mix categorical continuous variables. Instead, mix, second option fully conditional specification (FCS) might preferred. short, FCS specifies regression model missing values predicted taking variables dataset predictors. missing value procedure repeated convergence.mice package uses FCS resort packages Amelia (assumes multivariate normality) want perform joint modelling. focus part mice package given common use flexibility, hence go FCS.","code":""},{"path":"missing-data-and-multiple-imputation.html","id":"mice-decisions-number-of-imputations","chapter":"9 Missing data and multiple imputation","heading":"9.2.3 mice decisions: number of imputations","text":"final decision put everything practice: number imputed datasets. knowledge, strict rules regarding number. sometimes considered take percentage missingness dataset number imputation. example, across variables interest total 35% missing data, consider use 35 imputations. However, guarantee number lead stable results. advice can consider rule decide number. ran mice, repeat check whether obtained results similar increase number imputations. consider practical example.","code":""},{"path":"missing-data-and-multiple-imputation.html","id":"practical-example","chapter":"9 Missing data and multiple imputation","heading":"9.2.4 Practical example","text":"mice() function ask couple ingredients. First need define predictor matrix. predictor matrix want specify variables want include predictors missing values. dataset provided start section, use every variable. set predictor matrix, can use conveniently named make.predictorMatrix() function mice packageOf note, variable useful predictor missing values, done something like: predictor_matrix[, “variable want use predictor”] = 0Next, mice ask imputation method use per variable dataset. follow order variables dataset case: outcome, predictor1, predictor2, auxiliary. imputation method can choose various options including “pmm” (predictive mean matching numerical variables), “logreg” (logistic regression; binary variables), “polreg” (polytomous regression unordered factor variables three levels ), “polyr” (“proportional odds models ordered factors three levels ). addition, can use ““ variables missing values. full overview provided (click ).variables numerical example, therefore use “pmm” method variableNext, decide number imputed datasets. said strict rules. start 25 imputation 25% missing values total (25% predictor1 predictor2, 10% outcome, 0% auxiliary variable). Later , inspect whether results change notably setting higher number imputations.Alright, let’s run mice() function using ingredients. Note also set seed.original well 25 imputed complete datasets, now stored special type container speaks, mids object.conduct analysis imputed datasets, check convergence imputation algorithm. Convergence can visualized following way: iteration (.e., times imputation algorithm created imputed dataset), note mean standard deviation imputed variables. purpose, use something simple like plot() functionTo conclude whether imputation algorithm converged, can focus line overlap whether show similar extent variability. Additionally, also look whether range mean standard deviation imputed variables resembles mean/standard deviation observed variables. Let’s quickly check observed means standard deviations.Ok, let us also inspect plot. lines show overlap, variability (range mean standard deviation) seems “large”. lines “zigzag” expected appear follow pattern (e.g., strong decrease increase increasing number iteration), good. Comparing observed means/standard deviations imputed values, look ok except mean outcome -0.08 range mean imputed values -0.5 0.4. necessarily “bad” thing imputations reduced bias otherwise observed mean (since listwise deletion applied get average).\nnow don’t see notable indications non-convergence. Later repeat mice procedure different seeds see results similar. Next mean standard deviations, also zoom distribution imputed values compared observed ones. densityplot() function . Since want three distributions (outcome, predictor1, predictor2), use plot_grid() function cowplot package combine density plots one.Overall, deem “acceptable”. outcome variable shows least overlap observed imputed distribution, expected based mean, seem problematic based visual inspection. , can differences imputed observed variables without providing problem.","code":"\nlibrary(mice)\npredictor_matrix = make.predictorMatrix(mydata)\nimputation_method = c(\"pmm\", #outcome\n                      \"pmm\", # predictor1\n                      \"pmm\", # predictor2\n                      \"\" # auxiliary which does not have missing values\n                      )\nn_imputations = 25\nmice_data = mice(\n  data = mydata,\n  m = n_imputations,\n  seed = 97531,\n  predictorMatrix = predictor_matrix\n)\nplot(mice_data)\nlibrary(psych)\ndescribe(mydata[,c(\"outcome\", \"predictor1\", \"predictor2\")])[c(\"mean\",\"sd\")]\n#>             mean   sd\n#> outcome    -0.08 1.12\n#> predictor1 -0.01 1.06\n#> predictor2  0.01 1.05\nlibrary(cowplot)\ncowplot::plot_grid( densityplot(mice_data, ~outcome),\n                    densityplot(mice_data, ~predictor1),\n                    densityplot(mice_data, ~predictor2),\n                    ncol=2, nrow=2)"},{"path":"missing-data-and-multiple-imputation.html","id":"pooling-the-results","chapter":"9 Missing data and multiple imputation","heading":"9.2.4.1 Pooling the results","text":"finally ready run analysis model. least, case intend run general linear regression model. However, use types regression models logistic regression, need remove NA outcome model handle NA’s directly.intend run model handle missing values outcome, need “open” mice mids object reveal dataset containing original imputed data. need remove instances outcome missing. Finally need transform dataset back mids object. purpose “opening” original mids object, can use complete() function mice package. illustration purposes look something like . Note run code intend use general linear regression.Back case need remove missing values outcomes. now specify imputation model similar analysis model mind. want add quadratic terms analysis model also include imputation model. , want fit following model:Therefore,imputation least main effects predictor1 predictor2, interaction effect, outcome. Important note, imputation model allowed extra variables moment finally spoil purpose auxiliary variable. Auxiliary variables usually interest analysis per se variables may relate missingness missing variables. Therefore may aid approximate assumption MAR. especially consider add auxiliary variables pattern missingness resembles missing random state. course, later , always run mice without auxiliary variables check whether results remain similar. example add auxiliary variable imputation model.Now can pool together resultsTo deliver finishing touches, put results separate dataset compute lower upper bounds 95% confidence intervals estimated pooled coefficients.Now can check whether pooled results resemble obtain without multiple imputation.Overall, look notably similar. case, rethink every decision made till point. , outcome, obtained specific seed 97531.Now best check whether outcomes remain relatively robust across different runs mice","code":"\nlibrary(mice)\n\n# Open the mids object\nmice_data_long = complete(mice_data, action = \"long\", include = TRUE)\n\n# Remove NA in the OUTCOME variable (here \"outcome\")\nlibrary(dplyr)\nmice_data_long = mice_data_long %>% filter(!is.na(outcome))\n\n# Transform back to a mids object\nmice_data = as.mids(mice_data_long)\nlm(outcome ~ predictor1 * predictor2, data = mydata)\nmy_mice_model = with(mice_data, \n     lm( outcome ~ predictor1 * predictor2 + auxiliary )) # we have to use \"with\" since mice_data is a mids object\n\nsummary(my_mice_model)\n#> # A tibble: 125 × 6\n#>    term          estimate std.error statistic  p.value  nobs\n#>    <chr>            <dbl>     <dbl>     <dbl>    <dbl> <int>\n#>  1 (Intercept)   -0.110      0.0434    -2.53  1.17e- 2   500\n#>  2 predictor1     0.404      0.0412     9.82  6.54e-21   500\n#>  3 predictor2     0.296      0.0416     7.12  3.89e-12   500\n#>  4 auxiliary      0.0397     0.0420     0.945 3.45e- 1   500\n#>  5 predictor1:p…  0.0194     0.0422     0.460 6.46e- 1   500\n#>  6 (Intercept)   -0.0353     0.0428    -0.824 4.10e- 1   500\n#>  7 predictor1     0.446      0.0395    11.3   1.86e-26   500\n#>  8 predictor2     0.295      0.0398     7.41  5.69e-13   500\n#>  9 auxiliary     -0.0905     0.0413    -2.19  2.90e- 2   500\n#> 10 predictor1:p… -0.00667    0.0363    -0.184 8.54e- 1   500\n#> # ℹ 115 more rows\npooled_estimates = pool(my_mice_model)\npooled_results = data.frame(\n  summary(pooled_estimates)     \n                              ) %>%\n  mutate(CI_lower =  estimate - 1.96*(sqrt(pooled_estimates$pooled$ubar)),\n         CI_upper = estimate + 1.96*(sqrt(pooled_estimates$pooled$ubar)))\nmymodel_no_mice = lm( outcome ~ predictor1 * predictor2 + auxiliary ) # The model with automatically drop missing values so we do not need to do it ourselves\n\ndata.frame(\nestimate = mymodel_no_mice$coefficients,\nstd.error = summary(mymodel_no_mice)$coefficients[, \"Std. Error\"],\nstatistic = summary(mymodel_no_mice)$coefficients[, \"t value\"],\np.value = summary(mymodel_no_mice)$coefficients[, \"Pr(>|t|)\"],\nCI_lower = confint(mymodel_no_mice)[,1],\nCI_upper = confint(mymodel_no_mice)[,2]\n)\n#>                          estimate  std.error  statistic\n#> (Intercept)           -0.06612735 0.04308921 -1.5346612\n#> predictor1             0.46189195 0.04055634 11.3888965\n#> predictor2             0.29761672 0.04110791  7.2398900\n#> auxiliary             -0.02627134 0.04159248 -0.6316367\n#> predictor1:predictor2 -0.01285578 0.04171811 -0.3081581\n#>                                                  p.value\n#> (Intercept)           0.12550594727660110971889650954836\n#> predictor1            0.00000000000000000000000000754036\n#> predictor2            0.00000000000172646655648272597731\n#> auxiliary             0.52791587685890761783014113461832\n#> predictor1:predictor2 0.75809165072632311854761155700544\n#>                          CI_lower   CI_upper\n#> (Intercept)           -0.15078765 0.01853296\n#> predictor1             0.38220815 0.54157575\n#> predictor2             0.21684922 0.37838422\n#> auxiliary             -0.10799091 0.05544823\n#> predictor1:predictor2 -0.09482219 0.06911064"},{"path":"missing-data-and-multiple-imputation.html","id":"checking-the-robustness-of-the-results","chapter":"9 Missing data and multiple imputation","heading":"9.2.4.2 Checking the robustness of the results","text":"Like , may start wondering least two questions. extend similarity results used different seeds? Also, get different results increase number iterations (25)? Essentially, falls rerunning mice procedure given number times.Concerning extent similarity results, use set different seeds remove seeds altogether. example , remove seed () loop 100 runs mice procedure (practice, try higher value 500 ), store results (data frame object) called list variable.Good, now can retrieve estimate per dataset, per run, stored list, simply plot .bit variation estimations deemed robust. course, feel free check aspects similarity confidence intervals, .Regarding second question, number iterations, started 25 iterations average 25% missing values dataset (common strict rule). increase amount iterations.example , set seed back original value 97531 loop six different numbers iterations (.e., original 25, 30, 35, 40, 45, 50). save results list object plot estimates across datasets. code mostly similar one note now loop across numbers iterations. Additionally, made variable mycount used within () loop store imputed “outcome dataset”.Plot like ..","code":"\n# To store the results of the imputed datasets and to determine the number of runs\ncontainer_results=list()\nn_runs = 100 # In practice, try larger values (e.g., above 500)\n\nfor(i in 1:n_runs){\n  \n# Run the mice but without a seed  \nmice_data = mice(\n  data = mydata,\n  m = n_imputations,\n  predictorMatrix = predictor_matrix,\n)\n  \n\n# Fit the imputation models (Again, depending on your model, remove NA in the outcome first!)\nmy_mice_model = with(mice_data, \n                     lm( outcome ~ predictor1 * predictor2 + auxiliary )\n                     )\n\n\npooled_estimates = pool(my_mice_model)\n\n# Here instead in \"pooled_results\" like I did before, I will store the each dataset object to my outcome_container\ncontainer_results[[i]] =\n       data.frame(\n         summary(pooled_estimates)     \n       ) %>%\n         mutate(CI_lower =  estimate - 1.96*(sqrt(pooled_estimates$pooled$ubar)),\n                CI_upper = estimate + 1.96*(sqrt(pooled_estimates$pooled$ubar)))\n}\n# Combine all data frames in the list into one data frame\npooled_estimates_across_runs = bind_rows(container_results, .id = \"run\")\n\n# Plot the estimates across datasets\nlibrary(ggplot2)\nlibrary(plotly)\n\nggplotly(\npooled_estimates_across_runs %>% ggplot(aes(y=estimate, x = term, color=term)) +\n  geom_point() + xlab(\"\") +\n  theme(axis.text.x  = element_blank() )\n)\n# To store the results of the imputed datasets and to determine the number of runs\ncontainer_results=list()\nn_imputations = c(25, 30, 35, 40, 45, 50) \nmycount = 1 # since the for loop does not loop anymore through the values 1,2,3,... this will be used to store the \"outcome datasets\" at the end of the loop\n\n\nfor(i in seq_along(n_imputations)){\n  \n# Put the seed back to the original (if you want to report results based on this specific seed)\nmice_data = mice(\n  data = mydata,\n  m = n_imputations[i], # On the first run this will be 25, on the second, 30, and so on.\n  seed = 97531,\n  predictorMatrix = predictor_matrix,\n)\n  \n\n# Fit the imputation models (Again, depending on your model, remove NA in the outcome first!)\nmy_mice_model = with(mice_data, \n                     lm( outcome ~ predictor1 * predictor2 + auxiliary )\n                     )\n\n\npooled_estimates = pool(my_mice_model)\n\n\ncontainer_results[[mycount]] =\n       data.frame(\n         summary(pooled_estimates)     \n       ) %>%\n         mutate(CI_lower =  estimate - 1.96*(sqrt(pooled_estimates$pooled$ubar)),\n                CI_upper = estimate + 1.96*(sqrt(pooled_estimates$pooled$ubar)))\n\nmycount = mycount+1 # To update it so that in the next run, a new outcome dataset is stored to the list\n\n}\n# Plotting the estimates\nlibrary(ggplot2)\nlibrary(plotly)\n\nggplotly(\n  pooled_estimates_across_runs %>% ggplot(aes(y=estimate, x = term, color=term)) +\n    geom_point() + xlab(\"\") +\n    theme(axis.text.x  = element_blank() )\n)"}]
